<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.21">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>5&nbsp; Selección de variables, regularización y validación – Modelos Estadísticos para la Predicción</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./tema5.html" rel="next">
<link href="./tema3.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-ea1d7ac60288e0f1efdbc993fd8432ae.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-0687a6949ae11671cfb8b930681aab34.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No se han encontrado resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN" && texText && texText.data) {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./tema4.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables, regularización y validación</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modelos Estadísticos para la Predicción</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción a los modelos de regresión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal simple</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal múltiple</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ingeniería de características: transformaciones de variables e interacciones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables, regularización y validación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografía</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#proceso-completo-de-construcción-y-optimización-del-modelo" id="toc-proceso-completo-de-construcción-y-optimización-del-modelo" class="nav-link active" data-scroll-target="#proceso-completo-de-construcción-y-optimización-del-modelo"><span class="header-section-number">5.1</span> Proceso completo de construcción y optimización del modelo</a></li>
  <li><a href="#filtrado-basado-en-información-básica" id="toc-filtrado-basado-en-información-básica" class="nav-link" data-scroll-target="#filtrado-basado-en-información-básica"><span class="header-section-number">5.2</span> Filtrado basado en información básica</a></li>
  <li><a href="#criterios-de-bondad-de-ajuste" id="toc-criterios-de-bondad-de-ajuste" class="nav-link" data-scroll-target="#criterios-de-bondad-de-ajuste"><span class="header-section-number">5.3</span> Criterios de Bondad de Ajuste</a>
  <ul class="collapse">
  <li><a href="#criterio-de-información-de-akaike" id="toc-criterio-de-información-de-akaike" class="nav-link" data-scroll-target="#criterio-de-información-de-akaike"><span class="header-section-number">5.3.1</span> Criterio de Información de Akaike</a></li>
  <li><a href="#criterio-de-información-bayesiano" id="toc-criterio-de-información-bayesiano" class="nav-link" data-scroll-target="#criterio-de-información-bayesiano"><span class="header-section-number">5.3.2</span> Criterio de Información Bayesiano</a></li>
  <li><a href="#estadístico-cp-de-mallows" id="toc-estadístico-cp-de-mallows" class="nav-link" data-scroll-target="#estadístico-cp-de-mallows"><span class="header-section-number">5.3.3</span> Estadístico Cp de Mallows</a></li>
  <li><a href="#cuándo-usar-cada-criterio" id="toc-cuándo-usar-cada-criterio" class="nav-link" data-scroll-target="#cuándo-usar-cada-criterio"><span class="header-section-number">5.3.4</span> ¿Cuándo Usar Cada Criterio?</a></li>
  </ul></li>
  <li><a href="#métodos-de-selección-exhaustiva" id="toc-métodos-de-selección-exhaustiva" class="nav-link" data-scroll-target="#métodos-de-selección-exhaustiva"><span class="header-section-number">5.4</span> Métodos de selección exhaustiva</a></li>
  <li><a href="#métodos-automáticos-paso-a-paso" id="toc-métodos-automáticos-paso-a-paso" class="nav-link" data-scroll-target="#métodos-automáticos-paso-a-paso"><span class="header-section-number">5.5</span> Métodos automáticos paso a paso</a>
  <ul class="collapse">
  <li><a href="#selección-progresiva-forward-selection" id="toc-selección-progresiva-forward-selection" class="nav-link" data-scroll-target="#selección-progresiva-forward-selection"><span class="header-section-number">5.5.1</span> Selección progresiva (Forward Selection)</a></li>
  <li><a href="#eliminación-regresiva-backward-elimination" id="toc-eliminación-regresiva-backward-elimination" class="nav-link" data-scroll-target="#eliminación-regresiva-backward-elimination"><span class="header-section-number">5.5.2</span> Eliminación regresiva (Backward Elimination)</a></li>
  <li><a href="#selección-paso-a-paso-stepwise-regression" id="toc-selección-paso-a-paso-stepwise-regression" class="nav-link" data-scroll-target="#selección-paso-a-paso-stepwise-regression"><span class="header-section-number">5.5.3</span> Selección paso a paso (Stepwise Regression)</a></li>
  </ul></li>
  <li><a href="#métodos-basados-en-regularización" id="toc-métodos-basados-en-regularización" class="nav-link" data-scroll-target="#métodos-basados-en-regularización"><span class="header-section-number">5.6</span> Métodos basados en regularización</a>
  <ul class="collapse">
  <li><a href="#ridge-regression" id="toc-ridge-regression" class="nav-link" data-scroll-target="#ridge-regression"><span class="header-section-number">5.6.1</span> Ridge regression</a></li>
  <li><a href="#regresión-lasso" id="toc-regresión-lasso" class="nav-link" data-scroll-target="#regresión-lasso"><span class="header-section-number">5.6.2</span> Regresión Lasso</a></li>
  <li><a href="#elastic-net" id="toc-elastic-net" class="nav-link" data-scroll-target="#elastic-net"><span class="header-section-number">5.6.3</span> Elastic Net</a></li>
  <li><a href="#comparación-de-los-métodos-de-regularización" id="toc-comparación-de-los-métodos-de-regularización" class="nav-link" data-scroll-target="#comparación-de-los-métodos-de-regularización"><span class="header-section-number">5.6.4</span> Comparación de los métodos de Regularización</a></li>
  </ul></li>
  <li><a href="#validación-del-modelo" id="toc-validación-del-modelo" class="nav-link" data-scroll-target="#validación-del-modelo"><span class="header-section-number">5.7</span> Validación del Modelo</a>
  <ul class="collapse">
  <li><a href="#estrategias-de-validación" id="toc-estrategias-de-validación" class="nav-link" data-scroll-target="#estrategias-de-validación"><span class="header-section-number">5.7.1</span> Estrategias de Validación</a></li>
  <li><a href="#métricas-de-rendimiento" id="toc-métricas-de-rendimiento" class="nav-link" data-scroll-target="#métricas-de-rendimiento"><span class="header-section-number">5.7.2</span> Métricas de rendimiento</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-tema2" class="quarto-section-identifier"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Selección de variables, regularización y validación</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>En los modelos de regresión, especialmente cuando se trabaja con conjuntos de datos que incluyen un gran número de variables predictoras, es común enfrentarse al desafío ntficar qué variables son realmente relevantes para explicar la variable respuesta. La inclusión de demasiadas variables en un modelo puede llevar a problemas como el sobreajuste, pérdida de interpretabilidad y complejidad innecesaria, mientras que la exclusión de variables importantes puede resultar en modelos subóptimos.</p>
<p>Este tema aborda uno de los aspectos más críticos en la construcción de modelos de regresión: cómo seleccionar el subconjunto óptimo de variables predictoras y cómo validar la calidad del modelo resultante. Una vez realizado el análisis exploratorio y el ajuste inicial del modelo, surge la necesidad crítica de optimizar la selección de variables. Cuando se dispone de <span class="math inline">\(p\)</span> variables explicativas, es posible construir hasta <span class="math inline">\(2^p\)</span> modelos diferentes considerando todas las combinaciones posibles. Sin embargo, explorar de manera exhaustiva todos estos modelos puede ser computacionalmente inviable cuando <span class="math inline">\(p\)</span> es grande.</p>
<p>Para superar este desafío, en este tema nos enfocaremos en cinco enfoques principales:</p>
<ol type="1">
<li><p><strong>Filtrado basado en información básica</strong>: Eliminación preliminar de variables irrelevantes mediante criterios básicos (variabilidad, correlación, VIF)</p></li>
<li><p><strong>Criterios de bondad de ajuste</strong>: Métricas para comparar modelos con diferente número de variables (AIC, BIC, Cp de Mallows)</p></li>
<li><p><strong>Métodos de selección exhaustiva</strong>: Evaluación sistemática de todas las combinaciones posibles (Best Subset Selection)</p></li>
<li><p><strong>Métodos automáticos paso a paso</strong>: Selección iterativa mediante algoritmos forward, backward y stepwise</p></li>
<li><p><strong>Métodos basados en regularización</strong>: Técnicas que penalizan la complejidad del modelo (Ridge, Lasso, Elastic Net)</p></li>
<li><p><strong>Validación del modelo</strong>: Evaluación rigurosa de la capacidad predictiva mediante división train/test y validación cruzada</p></li>
</ol>
<p>Cada enfoque tiene sus propias ventajas y limitaciones, siendo apropiados para diferentes situaciones según el tamaño del dataset, el número de variables y los objetivos del análisis. El objetivo es presentar las técnicas más relevantes para la selección de variables y regularización, entender sus fundamentos teóricos, y aplicarlas a casos prácticos, culminando con métodos robustos de validación que aseguren la calidad y generalización del modelo final.</p>
<section id="proceso-completo-de-construcción-y-optimización-del-modelo" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="proceso-completo-de-construcción-y-optimización-del-modelo"><span class="header-section-number">5.1</span> Proceso completo de construcción y optimización del modelo</h2>
<p>La construcción de un modelo de regresión múltiple es un proceso sistemático que busca explicar la relación entre una variable respuesta (<span class="math inline">\(Y\)</span>) y múltiples variables predictoras (<span class="math inline">\(X_1, X_2, \dots, X_k\)</span>). Este proceso consta de varias etapas clave <span class="citation" data-cites="kutner2005applied">(<a href="#ref-kutner2005applied" role="doc-biblioref">Kutner et&nbsp;al. 2005</a>)</span>, que en este tema nos enfocaremos particularmente en las etapas de reducción de variables y validación:</p>
<ol type="1">
<li><strong>Definición del problema y variables de interés:</strong>
<ul>
<li>Identificar claramente el objetivo del análisis, ya sea realizar predicciones, evaluar relaciones o controlar por efectos de variables confusoras.</li>
<li>Seleccionar las variables predictoras potenciales en función de su relevancia teórica, conocimiento previo o exploración inicial de los datos.</li>
</ul></li>
<li><strong>Recogida de datos:</strong></li>
</ol>
<ul>
<li>La calidad de los datos recogidos influye directamente en la validez de los resultados y conclusiones obtenidas. El proceso de recogida de datos consiste en recopilar información de manera organizada y sistemática para responder a las preguntas de investigación planteadas. Dependiendo del diseño del estudio y los objetivos del análisis, se pueden emplear diferentes tipos de experimentos o métodos de recogida de datos.</li>
<li>Debemos asegurar las siguientes características sobre los datos.
<ul>
<li><strong>Fiabilidad:</strong> Asegurar que los datos sean consistentes y puedan reproducirse bajo condiciones similares.</li>
<li><strong>Validez:</strong> Garantizar que los datos recojan realmente la información necesaria para responder a las preguntas de investigación.</li>
<li><strong>Ética:</strong> Asegurar la privacidad y el consentimiento informado de los participantes.</li>
<li><strong>Control de Sesgos:</strong> Diseñar el estudio de manera que se minimicen los sesgos que puedan distorsionar los resultados.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Tipos de experimentos">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Tipos de experimentos
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La elección del tipo de experimento o método de recogida de datos dependerá de la naturaleza del problema a investigar, los recursos disponibles y las limitaciones del estudio. Una correcta planificación y ejecución de esta etapa sienta las bases para un análisis robusto y confiable.</p>
<ol type="1">
<li><strong>Experimentos controlados:</strong>
<ul>
<li>Los experimentos controlados son diseñados de manera que los investigadores manipulan deliberadamente una o más variables independientes (llamadas factores o variables controladas) para observar su efecto en la variable dependiente.</li>
<li>Incluyen la aleatorización de sujetos entre grupos (por ejemplo, grupos de control y tratamiento) para minimizar sesgos y asegurar comparabilidad.</li>
<li>En muchas ocasiones la información suplementaria no se puede incorporar en el diseño del experimento. A esas variables, no controladas, se les suel llamar covariables.</li>
<li><strong>Ejemplo:</strong> Un estudio clínico donde se prueba un nuevo medicamento y se compara su efecto con un placebo.</li>
</ul></li>
<li><strong>Estudios observacionales exploratorios:</strong>
<ul>
<li>En este enfoque, los datos se recogen sin intervenir ni manipular las condiciones. Los investigadores observan y registran los fenómenos tal como ocurren en la naturaleza.</li>
<li>Pueden clasificarse en:
<ul>
<li><strong>Estudios transversales:</strong> Los datos se recogen en un único punto temporal.</li>
<li><strong>Estudios longitudinales:</strong> Los datos se recogen durante un periodo para analizar cambios a lo largo del tiempo.</li>
</ul></li>
<li><strong>Ejemplo:</strong> Investigar los hábitos alimenticios y su asociación con enfermedades cardiovasculares en una población.</li>
</ul></li>
<li><strong>Estudios observacionales confirmatorios:</strong>
<ul>
<li>En este enfoque, los datos se recogen para testear (confirmar o no) hipótesis derivadas de estudios previos o de ideas que pueden tener los investigadores.</li>
<li>En este contexto, las variables que aparecen involucradas en la hipótesis que se quiere confirmar se denominan variables primarias, y las variables explicativas que se sabe inluyen en la respuesta se llaman variables de control (en Epidemiología nos referimos a ellas como factores de riesgo)</li>
<li><strong>Ejemplo:</strong> Un equipo de investigadores, basándose en estudios previos, plantea la hipótesis de que existe una relación positiva entre el hábito de fumar (variable explicativa principal) y la incidencia de cáncer de pulmón (variable respuesta). Para confirmar esta hipótesis, realizan un estudio observacional en el que recopilan datos de una población durante un periodo determinado. Dado que no es ético inducir a las personas a fumar para realizar un experimento controlado, este estudio se realiza de forma observacional. Los datos se analizan para evaluar la asociación entre las variables, permitiendo confirmar (o refutar) la hipótesis planteada con un diseño adecuado y controlando los posibles factores de confusión.</li>
</ul></li>
<li><strong>Encuestas y cuestionarios:</strong>
<ul>
<li>Las encuestas son una técnica común para recoger datos de manera estructurada sobre actitudes, opiniones, comportamientos o características demográficas.</li>
<li>Pueden aplicarse en formato presencial, en línea, por teléfono o mediante correo.</li>
<li><strong>Ejemplo:</strong> Una encuesta para medir el grado de satisfacción de los clientes con un servicio.</li>
</ul></li>
<li><strong>Experimentos naturales:</strong>
<ul>
<li>Se producen cuando un fenómeno natural o social actúa como una intervención en un entorno sin que los investigadores tengan control sobre el experimento.</li>
<li>Este tipo de estudio aprovecha eventos únicos para analizar sus impactos.</li>
<li><strong>Ejemplo:</strong> Estudiar los efectos económicos de una nueva política fiscal aplicada en una región específica.</li>
</ul></li>
<li><strong>Estudios de simulación:</strong>
<ul>
<li>Los datos se generan a través de modelos matemáticos o computacionales que representan un sistema real o hipotético.</li>
<li>Este método se usa cuando es difícil o costoso realizar experimentos reales.</li>
<li><strong>Ejemplo:</strong> Simular el comportamiento de un mercado financiero bajo diferentes escenarios económicos.</li>
</ul></li>
<li><strong>Recogida de datos secundarios:</strong>
<ul>
<li>En lugar de recoger datos nuevos, se utilizan datos ya existentes recopilados por terceros, como censos, registros administrativos o bases de datos públicas.</li>
<li>Aunque es eficiente en tiempo y costos, el investigador tiene menor control sobre la calidad y las características de los datos.</li>
<li><strong>Ejemplo:</strong> Analizar datos de encuestas nacionales para estudiar tendencias sociales.</li>
</ul></li>
</ol>
</div>
</div>
</div>
<ol start="3" type="1">
<li><strong>Análisis Exploratorio de Datos (EDA):</strong>
<ul>
<li>Inspeccionar los datos mediante análisis descriptivo y visual para identificar posibles problemas como valores atípicos, datos faltantes y multicolinealidad.</li>
<li>Escalar o transformar las variables si es necesario, especialmente si están en diferentes escalas o presentan distribuciones no lineales.</li>
</ul></li>
<li><strong>Ajuste del modelo:</strong>
<ul>
<li>Especificar el modelo de regresión múltiple en su forma general:<br>
<span class="math display">\[
Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \dots + \beta_pX_p + \varepsilon,
\]</span> donde <span class="math inline">\(\varepsilon\)</span> representa los errores aleatorios.</li>
<li>Estimar los coeficientes del modelo (<span class="math inline">\(\beta_0, \beta_1, \dots, \beta_p\)</span>) utilizando el método de mínimos cuadrados, que minimiza la suma de los errores al cuadrado.</li>
</ul></li>
<li><strong>Evaluación del modelo:</strong>
<ul>
<li>Analizar el ajuste general del modelo utilizando métricas como <span class="math inline">\(R^2\)</span> y <span class="math inline">\(R^2\)</span> ajustado, que miden la proporción de la variabilidad explicada.</li>
<li>Examinar la tabla ANOVA para evaluar la significancia global del modelo.</li>
<li>Realizar pruebas de hipótesis para los coeficientes individuales, verificando si las variables predictoras tienen un efecto significativo en la variable respuesta.</li>
</ul></li>
<li><strong>Diagnóstico del modelo:</strong>
<ul>
<li>Examinar los residuos para evaluar supuestos como la linealidad, homocedasticidad, normalidad de los errores y ausencia de autocorrelación.</li>
<li>Identificar observaciones atípicas, leverage y puntos de influencia utilizando herramientas como la distancia de Cook, DFBETAS y DFFITS.</li>
</ul></li>
<li><strong>Reducción de variables:</strong>
<ul>
<li>En análisis de regresión, especialmente cuando se trabaja con conjuntos de datos de alta dimensionalidad, es común enfrentar situaciones en las que el número de variables explicativas es muy grande. Esto puede llevar a problemas como el sobreajuste, dificultades en la interpretación del modelo y una mayor complejidad computacional. Por ello, reducir el número de variables explicativas, sin perder información relevante, se convierte en un paso crucial para construir modelos más eficientes y robustos.</li>
</ul></li>
<li><strong>Validación del modelo:</strong>
<ul>
<li>Evaluar el rendimientodel modelo con datos de validación o mediante técnicas como validación cruzada para garantizar su capacidad predictiva en nuevos conjuntos de datos.</li>
</ul></li>
</ol>
</section>
<section id="filtrado-basado-en-información-básica" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="filtrado-basado-en-información-básica"><span class="header-section-number">5.2</span> Filtrado basado en información básica</h2>
<p>Antes de aplicar métodos sofisticados de selección de variables, es fundamental realizar un filtrado preliminar basado en información básica. Este primer paso consiste en identificar y descartar variables que claramente no aportan información relevante al modelo, reduciendo significativamente el espacio de búsqueda y mejorando la eficiencia de los métodos posteriores <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>.</p>
<p>Los criterios principales para este filtrado incluyen:</p>
<p><strong>1. Variabilidad de las variables predictoras</strong></p>
<p>Variables con varianza muy baja o constantes proporcionan poca información discriminatoria. Se descartan variables donde:</p>
<p><span class="math display">\[\text{Var}(X_j) = \frac{1}{n-1}\sum_{i=1}^{n}(x_{ij} - \bar{x}_j)^2 &lt; \epsilon\]</span></p>
<p>para algún umbral pequeño <span class="math inline">\(\epsilon\)</span> (típicamente <span class="math inline">\(\epsilon = 0.01\)</span>).</p>
<p><strong>2. Correlación con la variable respuesta</strong></p>
<p>Variables con correlación muy baja con <span class="math inline">\(Y\)</span> pueden ser candidatas a eliminación. Se calcula:</p>
<p><span class="math display">\[r_{X_j,Y} = \frac{\sum_{i=1}^{n}(x_{ij} - \bar{x}_j)(y_i - \bar{y})}{\sqrt{\sum_{i=1}^{n}(x_{ij} - \bar{x}_j)^2\sum_{i=1}^{n}(y_i - \bar{y})^2}}\]</span></p>
<p>y típicamente se establece un umbral mínimo <span class="math inline">\(|r_{X_j,Y}| &gt; \delta\)</span> (ej: <span class="math inline">\(\delta = 0.1\)</span>).</p>
<p><strong>3. Multicolinealidad extrema</strong></p>
<p>Variables altamente correlacionadas entre sí pueden ser redundantes. Se calcula:</p>
<p><span class="math display">\[r_{X_j,X_k} = \frac{\text{Cov}(X_j, X_k)}{\sqrt{\text{Var}(X_j)\text{Var}(X_k)}}\]</span></p>
<p>Si <span class="math inline">\(|r_{X_j,X_k}| &gt; 0.95\)</span>, se considera eliminar una de las dos variables.</p>
<p><strong>4. Factor de Inflación de la Varianza (VIF)</strong></p>
<p>Para detectar multicolinealidad más compleja se calcula:</p>
<p><span class="math display">\[VIF_j = \frac{1}{1-R^2_j}\]</span></p>
<p>donde <span class="math inline">\(R^2_j\)</span> es el coeficiente de determinación de la regresión de <span class="math inline">\(X_j\)</span> sobre las demás variables predictoras. Valores <span class="math inline">\(VIF_j &gt; 10\)</span> indican multicolinealidad problemática.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo de filtrado inicial">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo de filtrado inicial
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>En este ejemplo aplicamos el proceso completo de filtrado basado en información a un conjunto de datos simulado con diferentes características.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configuración y generación de datos</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Generar datos con diferentes características</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> p), n, p)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span>p)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable constante (sin variabilidad)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable con muy baja variabilidad  </span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="dv">5</span> <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.01</span>)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Variables moderadamente correlacionadas</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">4</span>] <span class="ot">&lt;-</span> X[, <span class="dv">3</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>X[, <span class="dv">5</span>] <span class="ot">&lt;-</span> <span class="fl">0.7</span> <span class="sc">*</span> X[, <span class="dv">3</span>] <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="dv">0</span>, <span class="fl">0.6</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Variable respuesta con coeficientes conocidos</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="fl">1.5</span>, <span class="fl">1.2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.8</span>, <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">8</span>))</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta <span class="sc">+</span> <span class="fu">rnorm</span>(n)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y =</span> y, X)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(car))</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Análisis de variabilidad</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>varianzas <span class="ot">&lt;-</span> <span class="fu">apply</span>(X, <span class="dv">2</span>, var)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>vars_baja_var <span class="ot">&lt;-</span> <span class="fu">which</span>(varianzas <span class="sc">&lt;</span> <span class="fl">0.01</span>)</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Filtrar por correlación con Y</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>X_filtrada <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">length</span>(vars_baja_var) <span class="sc">&gt;</span> <span class="dv">0</span>) X[, <span class="sc">-</span>vars_baja_var] <span class="cf">else</span> X</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>correlaciones <span class="ot">&lt;-</span> <span class="fu">cor</span>(X_filtrada, y)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>vars_baja_corr_idx <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">abs</span>(correlaciones) <span class="sc">&lt;</span> <span class="fl">0.1</span>)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>vars_baja_corr <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">length</span>(vars_baja_corr_idx) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(<span class="fu">gsub</span>(<span class="st">"X"</span>, <span class="st">""</span>, <span class="fu">colnames</span>(X_filtrada)[vars_baja_corr_idx]))</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>()</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Identificar correlaciones altas entre predictores</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>cor_matrix <span class="ot">&lt;-</span> <span class="fu">cor</span>(X_filtrada)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>high_cor <span class="ot">&lt;-</span> <span class="fu">which</span>(<span class="fu">abs</span>(cor_matrix) <span class="sc">&gt;</span> <span class="fl">0.8</span> <span class="sc">&amp;</span> <span class="fu">abs</span>(cor_matrix) <span class="sc">&lt;</span> <span class="dv">1</span>, <span class="at">arr.ind =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Calcular VIF para variables restantes</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>vars_eliminar <span class="ot">&lt;-</span> <span class="fu">unique</span>(<span class="fu">c</span>(vars_baja_var, vars_baja_corr))</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>datos_final <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">length</span>(vars_eliminar) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  datos[, <span class="sc">-</span>(vars_eliminar <span class="sc">+</span> <span class="dv">1</span>)] <span class="co"># +1 porque datos incluye y en primera columna</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  datos</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>vif_valores <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">ncol</span>(datos_final) <span class="sc">&gt;</span> <span class="dv">2</span>) {</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>  modelo <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> ., <span class="at">data =</span> datos_final)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">vif</span>(modelo)</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>  <span class="cn">NULL</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Preparar resumen de resultados</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>resumen_vars_baja_var <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">length</span>(vars_baja_var) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste</span>(<span class="st">"X"</span>, vars_baja_var, <span class="at">collapse=</span><span class="st">", "</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Ninguna"</span></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a>resumen_vars_baja_corr <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">length</span>(vars_baja_corr) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste</span>(<span class="st">"X"</span>, vars_baja_corr, <span class="at">collapse=</span><span class="st">", "</span>)</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Ninguna"</span></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>resumen_high_cor <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="fu">nrow</span>(high_cor) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>  correlaciones_altas <span class="ot">&lt;-</span> <span class="fu">character</span>()</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(high_cor)) {</span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a>    var1 <span class="ot">&lt;-</span> <span class="fu">colnames</span>(X_filtrada)[high_cor[i,<span class="dv">1</span>]]</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a>    var2 <span class="ot">&lt;-</span> <span class="fu">colnames</span>(X_filtrada)[high_cor[i,<span class="dv">2</span>]]</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a>    corr_val <span class="ot">&lt;-</span> <span class="fu">round</span>(cor_matrix[high_cor[i,<span class="dv">1</span>], high_cor[i,<span class="dv">2</span>]], <span class="dv">3</span>)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>    correlaciones_altas <span class="ot">&lt;-</span> <span class="fu">c</span>(correlaciones_altas, <span class="fu">paste</span>(var1, <span class="st">"y"</span>, var2, <span class="st">":"</span>, corr_val))</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>  correlaciones_altas</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>  <span class="st">"Ninguna"</span></span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>vars_restantes <span class="ot">&lt;-</span> <span class="fu">ncol</span>(datos_final) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a>vars_originales <span class="ot">&lt;-</span> p</span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a>resumen_vif <span class="ot">&lt;-</span> <span class="cf">if</span>(<span class="sc">!</span><span class="fu">is.null</span>(vif_valores)) {</span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a>  vif_summary <span class="ot">&lt;-</span> <span class="fu">character</span>()</span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(vif_valores)) {</span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a>    estado <span class="ot">&lt;-</span> <span class="cf">if</span>(vif_valores[i] <span class="sc">&gt;</span> <span class="dv">10</span>) <span class="st">" (ALTO)"</span> <span class="cf">else</span> <span class="cf">if</span>(vif_valores[i] <span class="sc">&gt;</span> <span class="dv">5</span>) <span class="st">" (moderado)"</span> <span class="cf">else</span> <span class="st">""</span></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>    vif_summary <span class="ot">&lt;-</span> <span class="fu">c</span>(vif_summary, <span class="fu">paste</span>(<span class="fu">names</span>(vif_valores)[i], <span class="st">":"</span>, <span class="fu">round</span>(vif_valores[i], <span class="dv">2</span>), estado))</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a>  vif_summary</span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a>} <span class="cf">else</span> {</span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a>  <span class="st">"No calculado"</span></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>Resultados del filtrado basado en información:</strong></p>
<p><strong>1. Variables eliminadas por baja variabilidad:</strong> X 1, X 2</p>
<p><strong>2. Variables eliminadas por baja correlación con Y:</strong> X 8, X 9, X 10, X 11, X 12, X 13, X 14</p>
<p><strong>3. Correlaciones altas entre predictores (|r| &gt; 0.8):</strong> X4 y X3 : 0.846 , X3 y X4 : 0.846</p>
<p><strong>4. Variables restantes:</strong> 6 de 15 originales</p>
<p><strong>5. Factores VIF de variables finales:</strong> X3 : 4.87 , X4 : 3.56 , X5 : 2.26 , X6 : 1.06 , X7 : 1.03 , X15 : 1.07</p>
<p>Este proceso de filtrado redujo el conjunto original de 15 variables a 6 variables, eliminando efectivamente las variables con problemas de variabilidad y correlación identificados.</p>
</div>
</div>
</div>
<p>El proceso de filtrado se implementa secuencialmente: (1) eliminar variables constantes o con varianza cercana a cero, (2) eliminar variables con correlación muy baja con la variable respuesta, (3) identificar grupos de variables multicolineales y retener solo la más relevante de cada grupo, y (4) calcular VIF y eliminar variables con valores muy altos. Este filtrado inicial típicamente reduce el conjunto de variables candidatas, facilitando significativamente los pasos posteriores de selección.</p>
<p>Es importante considerar que este filtrado no es definitivo, ya que variables eliminadas en esta etapa pueden ser importantes en combinaciones específicas. Además, está basado en relaciones lineales y puede omitir relaciones no lineales importantes. Por tanto, requiere validación posterior del modelo resultante y los umbrales deben ajustarse según el dominio de aplicación específico.</p>
<p>¡Claro! El contenido que tienes es excelente y muy completo. Para hacerlo menos esquemático, lo he reescrito en un formato más narrativo, conectando las ideas en párrafos fluidos. La idea es transformar las listas y tablas en una explicación discursiva, como si lo estuvieras contando en una clase, lo que se adapta mejor al formato de un libro.</p>
<p>Aquí tienes la propuesta:</p>
</section>
<section id="criterios-de-bondad-de-ajuste" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="criterios-de-bondad-de-ajuste"><span class="header-section-number">5.3</span> Criterios de Bondad de Ajuste</h2>
<p>Una vez completado el filtrado preliminar de variables, nos enfrentamos a una de las tareas más importantes del modelado: seleccionar la combinación óptima de predictores. El objetivo es encontrar un equilibrio delicado. Un modelo con muy pocas variables puede ser demasiado simple y no capturar la relación real (<strong>subajuste</strong> o <em>underfitting</em>), mientras que un modelo con demasiadas variables puede ajustarse al ruido de la muestra y no generalizar bien a nuevos datos (<strong>sobreajuste</strong> u <em>overfitting</em>).</p>
<p>Para navegar este compromiso, utilizamos criterios de información que cuantifican la calidad de un modelo, equilibrando su capacidad explicativa con su complejidad. Estos nos permiten comparar modelos con diferente número de predictores de forma rigurosa y objetiva. Los tres criterios más influyentes en la estadística clásica son el Criterio de Información de Akaike (AIC), el Criterio de Información Bayesiano (BIC) y el estadístico Cp de Mallows.</p>
<section id="criterio-de-información-de-akaike" class="level3" data-number="5.3.1">
<h3 data-number="5.3.1" class="anchored" data-anchor-id="criterio-de-información-de-akaike"><span class="header-section-number">5.3.1</span> Criterio de Información de Akaike</h3>
<p>El <strong>Criterio de Información de Akaike (AIC)</strong>, desarrollado por Hirotugu Akaike, es una métrica fundamentada en la teoría de la información <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>. Su propósito es estimar la pérdida de información que ocurre cuando usamos un modelo para representar la realidad. El modelo que minimice esta pérdida de información será considerado el mejor.</p>
<p>La fórmula del AIC para un modelo de regresión lineal es:</p>
<p><span class="math display">\[AIC = n \ln\left(\frac{SSE}{n}\right) + 2(p+1)\]</span></p>
<p>En esta ecuación, <span class="math inline">\(n\)</span> es el tamaño de la muestra, <span class="math inline">\(SSE\)</span> es la Suma de Cuadrados del Error y <span class="math inline">\(p\)</span> es el número de variables predictoras. La fórmula equilibra dos fuerzas opuestas:</p>
<ol type="1">
<li><strong>Bondad de ajuste</strong>: El primer término, <span class="math inline">\(n \ln(SSE/n)\)</span>, está directamente relacionado con la función de log-verosimilitud del modelo. Disminuye a medida que el modelo se ajusta mejor a los datos (es decir, a medida que el SSE se reduce).</li>
<li><strong>Penalización por complejidad</strong>: El segundo término, <span class="math inline">\(2(p+1)\)</span>, actúa como un castigo. Aumenta en 2 unidades por cada parámetro adicional que se incluye en el modelo (p pendientes + 1 intercepto).</li>
</ol>
<p>En la práctica, calculamos el AIC para varios modelos candidatos y <strong>seleccionamos aquel con el valor de AIC más bajo</strong>. Este criterio es asintóticamente eficiente, lo que significa que, con muestras suficientemente grandes, tiende a seleccionar el modelo que minimiza el error de predicción esperado en nuevos datos.</p>
</section>
<section id="criterio-de-información-bayesiano" class="level3" data-number="5.3.2">
<h3 data-number="5.3.2" class="anchored" data-anchor-id="criterio-de-información-bayesiano"><span class="header-section-number">5.3.2</span> Criterio de Información Bayesiano</h3>
<p>El <strong>Criterio de Información Bayesiano (BIC)</strong>, propuesto por Gideon Schwarz, es un competidor directo del AIC, pero con fundamentos en la estadística bayesiana <span class="citation" data-cites="hastie2009elements">(<a href="#ref-hastie2009elements" role="doc-biblioref">Hastie et&nbsp;al. 2009</a>)</span>. Mientras que el AIC busca el mejor modelo para la predicción, el BIC está diseñado para encontrar el <strong>modelo más probable de ser el “verdadero”</strong> generador de los datos.</p>
<p>Su fórmula es muy similar a la del AIC, pero la penalización por complejidad es diferente y más severa:</p>
<p><span class="math display">\[BIC = n \ln\left(\frac{SSE}{n}\right) + (p+1) \ln(n)\]</span></p>
<p>La diferencia clave reside en el término de penalización. En lugar de <span class="math inline">\(2(p+1)\)</span>, el BIC utiliza <span class="math inline">\((p+1)\ln(n)\)</span>. Dado que el logaritmo natural de <span class="math inline">\(n\)</span> es mayor que 2 para cualquier muestra con más de 7 observaciones (<span class="math inline">\(e^2 \approx 7.4\)</span>), la penalización del BIC es casi siempre más fuerte que la del AIC. Esta penalización más estricta le confiere al BIC una tendencia hacia la <strong>parsimonia</strong>, favoreciendo modelos más simples. Una de sus propiedades teóricas más importantes es la <strong>consistencia</strong>: si el modelo verdadero se encuentra entre los candidatos, la probabilidad de que el BIC lo seleccione tiende a 1 a medida que el tamaño de la muestra crece.</p>
</section>
<section id="estadístico-cp-de-mallows" class="level3" data-number="5.3.3">
<h3 data-number="5.3.3" class="anchored" data-anchor-id="estadístico-cp-de-mallows"><span class="header-section-number">5.3.3</span> Estadístico Cp de Mallows</h3>
<p>A diferencia del AIC y el BIC, el <strong>estadístico Cp de Mallows</strong> no se basa en la teoría de la información ni en la estadística bayesiana, sino que aborda directamente el <strong>error cuadrático medio de predicción</strong> del modelo <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>. Su objetivo es encontrar un modelo que tenga un bajo sesgo y una baja varianza.</p>
<p>La fórmula para el estadístico Cp es:</p>
<p><span class="math display">\[C_p = \frac{SSE_p}{MSE_{full}} - n + 2(p+1)\]</span></p>
<p>Aquí, <span class="math inline">\(SSE_p\)</span> es la suma de cuadrados del error del modelo candidato con <span class="math inline">\(p\)</span> variables, y <span class="math inline">\(MSE_{full}\)</span> es el error cuadrático medio del <strong>modelo completo</strong> (el que incluye todas las variables predictoras disponibles), que se utiliza como una estimación insesgada de la varianza del error poblacional, <span class="math inline">\(\sigma^2\)</span>.</p>
<p>La interpretación del Cp es particularmente intuitiva. Si un modelo está bien especificado (es decir, no incluye un sesgo significativo), se espera que su valor de <span class="math inline">\(C_p\)</span> sea cercano al número de parámetros, <span class="math inline">\(p+1\)</span>.</p>
<p>Por lo tanto, la estrategia de selección consiste en <strong>elegir el modelo que tenga el valor de Cp más bajo</strong>. Este modelo representa el mejor equilibrio entre el sesgo y la varianza. Generalmente, observaremos dos cosas en un gráfico de Cp vs.&nbsp;p:</p>
<ul>
<li>Los modelos con pocas variables y <strong><span class="math inline">\(C_p\)</span> muy por encima de la línea <span class="math inline">\(p+1\)</span></strong> sufren de un sesgo elevado (subajuste).</li>
<li>El modelo con el <strong><span class="math inline">\(C_p\)</span> más bajo</strong> es el preferido. Normalmente, este valor mínimo también estará cerca de la línea <span class="math inline">\(p+1\)</span>, confirmando su buen ajuste.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Visualización del Cp de Mallows">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Visualización del Cp de Mallows
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Una de las aplicaciones más útiles del Cp de Mallows es su visualización gráfica para identificar el modelo óptimo. El siguiente ejemplo muestra cómo crear un gráfico de Cp que facilita la interpretación y selección del mejor modelo.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar librerías necesarias</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>({</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(leaps)     <span class="co"># Para best subset selection</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(ggplot2)   <span class="co"># Para gráficos</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">library</span>(dplyr)     <span class="co"># Para manipulación de datos</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Usar el dataset mtcars para el ejemplo</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Realizar best subset selection</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>best_subset <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(mpg <span class="sc">~</span> ., <span class="at">data =</span> mtcars, <span class="at">nvmax =</span> <span class="dv">10</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>subset_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(best_subset)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Extraer información relevante para el gráfico</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_variables =</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(subset_summary<span class="sc">$</span>cp),</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">Cp =</span> subset_summary<span class="sc">$</span>cp</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Identificar el mejor modelo según el criterio Cp</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co">#    La regla es simple: escoger el modelo con el menor valor de Cp.</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>mejor_cp_idx <span class="ot">&lt;-</span> <span class="fu">which.min</span>(subset_summary<span class="sc">$</span>cp)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>mejor_cp_valor <span class="ot">&lt;-</span> subset_summary<span class="sc">$</span>cp[mejor_cp_idx]</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Crear el gráfico del Cp de Mallows</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data, <span class="fu">aes</span>(<span class="at">x =</span> n_variables, <span class="at">y =</span> Cp)) <span class="sc">+</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Línea de referencia ideal (Cp = p+1)</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept =</span> <span class="dv">1</span>, <span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Puntos y línea de los valores Cp de los modelos</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"#0072B2"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"#0072B2"</span>) <span class="sc">+</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Resaltar el mejor punto (el que tiene el Cp mínimo)</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> mejor_cp_idx, <span class="at">y =</span> mejor_cp_valor), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">5</span>, <span class="at">shape =</span> <span class="dv">17</span>) <span class="sc">+</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Etiqueta para el mejor punto</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mejor_cp_idx, <span class="at">y =</span> mejor_cp_valor <span class="sc">+</span> <span class="fl">1.5</span>,</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Óptimo Cp</span><span class="sc">\n</span><span class="st">("</span>, mejor_cp_idx, <span class="st">"variables)"</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Criterio Cp de Mallows para Selección de Variables (mtcars)"</span>,</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Se busca el modelo con el valor de Cp más bajo"</span>,</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Número de Variables Predictoras (p)"</span>,</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Valor de Cp"</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">14</span>) <span class="sc">+</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>)) <span class="sc">+</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning in geom_point(aes(x = mejor_cp_idx, y = mejor_cp_valor), color = "red", : All aesthetics have length 1, but the data has 10 rows.
ℹ Please consider using `annotate()` or provide this layer with data containing
  a single row.</code></pre>
</div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="tema4_files/figure-html/cp-mallows-grafico-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Mostrar las variables del modelo seleccionado</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>variables_mejor_modelo_cp <span class="ot">&lt;-</span> <span class="fu">names</span>(<span class="fu">which</span>(subset_summary<span class="sc">$</span>which[mejor_cp_idx, <span class="sc">-</span><span class="dv">1</span>]))</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>El gráfico resultante nos permite diagnosticar visualmente la calidad de los modelos candidatos. La línea discontinua roja representa la referencia para un modelo sin sesgo (<span class="math inline">\(C_p = p+1\)</span>).</p>
<p>La estrategia de selección es clara: <strong>identificar el modelo que minimice el estadístico Cp</strong>. Este punto representa el mejor equilibrio teórico entre el sesgo del modelo (subajuste) y su varianza (sobreajuste). La línea roja nos ayuda a confirmar visualmente que el modelo elegido, además de ser el de menor Cp, tiene un sesgo bajo.</p>
<p>Como se observa, el estadístico Cp disminuye drásticamente al pasar de uno a dos predictores. El modelo con <strong>3 variables</strong> es el seleccionado como óptimo porque alcanza el valor de Cp más bajo de todos los candidatos, con un valor de <strong>0.1</strong>.</p>
<p>El análisis sugiere que el modelo más parsimonioso y con el mejor rendimiento predictivo se compone de las siguientes variables: <strong>wt, qsec, am</strong>. Añadir más predictores más allá de este punto óptimo no mejora el modelo; de hecho, el valor de Cp comienza a aumentar, lo que indica que estamos añadiendo una complejidad innecesaria y empezando a sobreajustar los datos.</p>
</div>
</div>
</div>
</section>
<section id="cuándo-usar-cada-criterio" class="level3" data-number="5.3.4">
<h3 data-number="5.3.4" class="anchored" data-anchor-id="cuándo-usar-cada-criterio"><span class="header-section-number">5.3.4</span> ¿Cuándo Usar Cada Criterio?</h3>
<p>La existencia de varios criterios plantea una pregunta natural: ¿cuál debemos usar? La respuesta depende en gran medida del objetivo final de nuestro análisis.</p>
<p>Si el <strong>objetivo principal es la predicción</strong>, el <strong>AIC</strong> suele ser la opción preferida. Su diseño para minimizar el error de predicción lo hace ideal en contextos de pronóstico, donde el rendimiento en datos nuevos es lo más importante. Su penalización más moderada permite incluir variables que, aunque no sean “verdaderas” en un sentido causal, ayudan a mejorar la precisión de las predicciones.</p>
<p>Por otro lado, si el <strong>objetivo es la explicación o la inferencia</strong> —es decir, identificar el modelo más parsimonioso que probablemente representa el verdadero proceso generador de los datos—, el <strong>BIC</strong> es la elección más sólida. Su penalización más fuerte protege de forma más robusta contra el sobreajuste y, en muestras grandes, su propiedad de consistencia le da una base teórica más fuerte para la selección del “modelo verdadero”.</p>
<p>El <strong>Cp de Mallows</strong> es especialmente valioso en un contexto más exploratorio, cuando queremos entender explícitamente el compromiso entre el sesgo y la varianza. Al graficar <span class="math inline">\(C_p\)</span> frente a <span class="math inline">\(p+1\)</span> para diferentes subconjuntos de modelos, podemos visualizar claramente el punto en el que añadir más variables deja de reducir el sesgo y solo empieza a inflar la varianza, ofreciendo una visión muy clara del “codo” de complejidad óptima.</p>
<p>Es común que estos criterios no coincidan en su selección. Cuando esto ocurre, no debe verse como un fracaso, sino como una indicación de que no existe un único modelo “mejor” de forma inequívoca. En tales casos, el juicio del analista es clave, y se pueden usar herramientas adicionales como la <strong>validación cruzada</strong> (<em>cross-validation</em>) para comparar el rendimiento predictivo de los modelos finalistas y tomar una decisión informada.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Importante</span>El Principio de Parsimonia en la Selección de Modelos
</div>
</div>
<div class="callout-body-container callout-body">
<p>El <strong>principio de parsimonia</strong>, también conocido como la “navaja de Occam”, es un concepto fundamental que subyace a todos los criterios de bondad de ajuste. Este principio establece que, entre modelos que explican igualmente bien un fenómeno, <strong>se debe preferir el más simple</strong>.</p>
</div>
</div>
</section>
</section>
<section id="métodos-de-selección-exhaustiva" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="métodos-de-selección-exhaustiva"><span class="header-section-number">5.4</span> Métodos de selección exhaustiva</h2>
<p>Los métodos de selección exhaustiva son un enfoque fundamental en la búsqueda de un subconjunto óptimo de variables predictoras en modelos de regresión. Este enfoque evalúa de manera sistemática diferentes combinaciones de variables para identificar cuál de ellas proporciona el mejor ajuste al modelo en función de un criterio predefinido, como el coeficiente de determinación ajustado (<span class="math inline">\(R^2\)</span> ajustado) o criterios de información como AIC o BIC.</p>
<p>A diferencia de los métodos automáticos, los métodos de selección exhaustiva no dependen de un proceso iterativo de adición o eliminación de variables. En cambio, buscan exhaustivamente (o mediante aproximaciones computacionalmente más eficientes) entre todas las posibles combinaciones de variables, lo que garantiza un análisis completo de las interacciones y relevancias potenciales.</p>
<p>El método más conocido dentro de este enfoque es la <strong>selección del mejor subconjunto (Best Subset Selection)</strong>, que evalúa todos los subconjuntos posibles de variables y selecciona el mejor para cada tamaño específico. Es el enfoque más completo pero también el más exigente computacionalmente. Para un conjunto de <span class="math inline">\(p\)</span> variables predictoras, este método construye todos los modelos posibles que incluyen <span class="math inline">\(k\)</span> variables, donde <span class="math inline">\(k = 1, 2, ..., p\)</span>, seleccionando el mejor modelo de cada tamaño según el criterio elegido.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo de selección exhaustiva">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo de selección exhaustiva
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo de Best Subset Selection maximizando R² ajustado</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(leaps))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Usando el dataset mtcars</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Realizar best subset selection</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>best_subset <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(mpg <span class="sc">~</span> ., <span class="at">data =</span> mtcars, <span class="at">nvmax =</span> <span class="dv">10</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Obtener estadísticas del mejor modelo según R² ajustado</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>subset_summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(best_subset)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>mejor_modelo_idx <span class="ot">&lt;-</span> <span class="fu">which.max</span>(subset_summary<span class="sc">$</span>adjr2)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>mejor_r2_adj <span class="ot">&lt;-</span> <span class="fu">max</span>(subset_summary<span class="sc">$</span>adjr2)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>total_variables <span class="ot">&lt;-</span> <span class="fu">ncol</span>(mtcars) <span class="sc">-</span> <span class="dv">1</span>  <span class="co"># Excluir variable respuesta</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>variables_seleccionadas <span class="ot">&lt;-</span> mejor_modelo_idx</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>El método de selección exhaustiva aplicado al conjunto de datos <code>mtcars</code> identifica el modelo óptimo que maximiza el R² ajustado. Este modelo alcanza un <strong>R² ajustado de 0.8375</strong>, utilizando <strong>5 variables</strong> del total de <strong>10 variables</strong> predictoras disponibles. Esta selección representa un equilibrio óptimo entre la capacidad explicativa del modelo y la penalización por complejidad, demostrando cómo la evaluación exhaustiva puede identificar el subconjunto de variables que mejor explica la variabilidad en el consumo de combustible.</p>
</div>
</div>
</div>
<p>Esta aproximación presenta importantes <strong>ventajas</strong>: garantiza encontrar el mejor subconjunto según el criterio elegido (optimalidad garantizada), examina todas las posibles combinaciones de variables ofreciendo una evaluación completa, y proporciona un estándar sólido para comparar otros métodos de selección. Sin embargo, también tiene <strong>limitaciones</strong> significativas: la complejidad computacional crece exponencialmente ya que con <span class="math inline">\(p\)</span> variables se generan <span class="math inline">\(2^p\)</span> modelos posibles, lo que hace que sea impracticable para <span class="math inline">\(p\)</span> grande (típicamente <span class="math inline">\(p &gt; 15-20\)</span>). Además, sin una validación cruzada adecuada, puede seleccionar modelos sobreajustados.</p>
<p>Estos métodos son especialmente útiles cuando el número de predictores no es demasiado grande, ya que el esfuerzo computacional crece exponencialmente con el número de variables. Aunque el costo computacional puede ser elevado en datasets amplios, los métodos de selección exhaustiva proporcionan una referencia sólida y transparente para evaluar qué variables son fundamentales en el modelo, siendo particularmente valiosos en estudios donde la interpretabilidad y la certeza sobre la selección de variables son prioritarias.</p>
<p>¡Perfecto! El texto que tienes es una excelente introducción. Ahora vamos a expandir cada uno de esos puntos para darles la profundidad teórica y práctica que necesitan en el libro, explicando el algoritmo de cada método, sus criterios de decisión y sus ventajas y limitaciones.</p>
<p>Aquí tienes una propuesta para desarrollar esa sección.</p>
</section>
<section id="métodos-automáticos-paso-a-paso" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="métodos-automáticos-paso-a-paso"><span class="header-section-number">5.5</span> Métodos automáticos paso a paso</h2>
<p>Los métodos automáticos de selección de variables, a menudo llamados métodos secuenciales o por pasos (<em>stepwise</em>), son algoritmos diseñados para explorar el espacio de posibles modelos de una manera computacionalmente eficiente. A diferencia del método de mejores subconjuntos (<em>best subset selection</em>), que evalúa todos los modelos posibles, estos enfoques siguen un camino restringido, añadiendo o quitando predictores de uno en uno.</p>
<p>El principio clave es construir un modelo de forma iterativa, tomando en cada paso una decisión “localmente óptima” basada en un criterio estadístico. Los criterios más comunes son el p-valor de un predictor, o el cambio que este produce en un indicador global como el <strong>AIC</strong>, el <strong>BIC</strong> o el <strong><span class="math inline">\(R^2\)</span> ajustado</strong>.</p>
<section id="selección-progresiva-forward-selection" class="level3" data-number="5.5.1">
<h3 data-number="5.5.1" class="anchored" data-anchor-id="selección-progresiva-forward-selection"><span class="header-section-number">5.5.1</span> Selección progresiva (Forward Selection)</h3>
<p>Esta estrategia es la más intuitiva: parte de la nada y construye el modelo pieza por pieza, añadiendo en cada paso el predictor que aporta la mayor mejora.</p>
<p><strong>El Algoritmo</strong></p>
<ol type="1">
<li><strong>Inicio</strong>: Se comienza con el <strong>modelo nulo</strong>, que solo contiene el intercepto (<span class="math inline">\(Y \sim 1\)</span>).</li>
<li><strong>Primer Paso</strong>: Se ajustan <span class="math inline">\(p\)</span> modelos de regresión simple, uno para cada una de las <span class="math inline">\(p\)</span> variables predictoras disponibles. Se elige la variable que mejor explica la respuesta (la que tiene el p-valor más bajo en su test t, o la que produce el AIC/BIC más bajo). Esta variable se convierte en el primer predictor del modelo.</li>
<li><strong>Pasos Siguientes</strong>: Se ajustan <span class="math inline">\(p-1\)</span> nuevos modelos, cada uno de los cuales contiene la(s) variable(s) ya seleccionada(s) más una de las variables restantes. De nuevo, se selecciona y se añade la variable que produce la mayor mejora en el criterio elegido.</li>
<li><strong>Finalización</strong>: El proceso se repite y se detiene cuando ninguna de las variables restantes mejora el modelo de forma significativa al ser añadida (por ejemplo, ninguna tiene un p-valor por debajo de un umbral predefinido, o el AIC/BIC del modelo deja de disminuir).</li>
</ol>
<p><strong>Ventajas y Limitaciones</strong></p>
<ul>
<li><strong>Ventaja</strong>: Es computacionalmente muy eficiente. Puede aplicarse en situaciones con un número de predictores muy grande, incluso cuando hay más predictores que observaciones (<span class="math inline">\(p &gt; n\)</span>).</li>
<li><strong>Limitación</strong>: Su principal debilidad es su <strong>“miopía”</strong>. Una variable seleccionada en una etapa temprana se queda en el modelo para siempre. Sin embargo, es posible que esa variable se vuelva redundante una vez que se añadan otros predictores. El método <em>forward</em> no puede rectificar decisiones pasadas, por lo que no garantiza encontrar el mejor modelo posible.</li>
</ul>
</section>
<section id="eliminación-regresiva-backward-elimination" class="level3" data-number="5.5.2">
<h3 data-number="5.5.2" class="anchored" data-anchor-id="eliminación-regresiva-backward-elimination"><span class="header-section-number">5.5.2</span> Eliminación regresiva (Backward Elimination)</h3>
<p>Esta estrategia adopta el enfoque opuesto: empieza con todo y va eliminando lo que no es útil, como un escultor que retira el mármol sobrante.</p>
<p><strong>El Algoritmo</strong></p>
<ol type="1">
<li><strong>Inicio</strong>: Se comienza con el <strong>modelo completo</strong>, que incluye todas las <span class="math inline">\(p\)</span> variables predictoras disponibles (<span class="math inline">\(Y \sim X_1 + X_2 + \dots + X_p\)</span>).</li>
<li><strong>Primer Paso</strong>: Se ajusta el modelo completo y se examina la significancia de cada predictor. Se identifica la variable <strong>menos significativa</strong>, es decir, aquella con el p-valor más alto en su test t (o la que, al ser eliminada, produce la menor disminución en la calidad del modelo según AIC/BIC).</li>
<li><strong>Pasos Siguientes</strong>: Si el p-valor de esa variable supera un umbral de permanencia (p.&nbsp;ej., <span class="math inline">\(\alpha_{out} = 0.10\)</span>), se elimina del modelo. A continuación, se vuelve a ajustar el modelo con las <span class="math inline">\(p-1\)</span> variables restantes.</li>
<li><strong>Finalización</strong>: El proceso de identificar y eliminar la variable menos significativa se repite hasta que todas las variables que quedan en el modelo son estadísticamente significativas (es decir, todas tienen un p-valor por debajo del umbral de permanencia).</li>
</ol>
<p><strong>Ventajas y Limitaciones</strong></p>
<ul>
<li><strong>Ventaja</strong>: Generalmente se considera superior al método <em>forward</em> porque empieza evaluando el efecto de cada variable en presencia de todas las demás. Esto proporciona un contexto inicial más completo.</li>
<li><strong>Limitación</strong>: No se puede utilizar si el número de predictores es mayor que el número de observaciones (<span class="math inline">\(p &gt; n\)</span>), ya que es imposible ajustar el modelo completo inicial. Además, al igual que el método <em>forward</em>, una vez que una variable es eliminada, no puede volver a entrar, lo que podría llevar a eliminar por error una variable que es importante en combinación con un subconjunto más pequeño de predictores.</li>
</ul>
</section>
<section id="selección-paso-a-paso-stepwise-regression" class="level3" data-number="5.5.3">
<h3 data-number="5.5.3" class="anchored" data-anchor-id="selección-paso-a-paso-stepwise-regression"><span class="header-section-number">5.5.3</span> Selección paso a paso (Stepwise Regression)</h3>
<p>Este método es un híbrido que intenta combinar lo mejor de las dos estrategias anteriores, permitiendo un proceso de “prueba y error” más flexible.</p>
<p><strong>El Algoritmo</strong></p>
<p>La selección <em>stepwise</em> es esencialmente una selección <em>forward</em> con un añadido crucial: en cada paso, después de añadir una nueva variable, se realiza una <strong>verificación hacia atrás</strong> para comprobar si alguna de las variables que ya estaban en el modelo se ha vuelto redundante.</p>
<ol type="1">
<li><strong>Paso Adelante (Forward)</strong>: Al igual que en la selección progresiva, se añade la variable que más mejora el modelo.</li>
<li><strong>Paso Atrás (Backward)</strong>: Después de añadir esa variable, se examinan <strong>todas las variables ya incluidas</strong> en el modelo. Si alguna de ellas ha perdido su significancia (su p-valor ha aumentado por encima de un umbral de eliminación), se elimina.</li>
<li><strong>Repetición</strong>: El proceso continúa, alternando pasos hacia adelante y hacia atrás, hasta que se alcanza un punto de equilibrio en el que ninguna variable puede ser añadida ni eliminada según los umbrales establecidos.</li>
</ol>
<p><strong>Ventajas y Limitaciones</strong></p>
<ul>
<li><strong>Ventaja</strong>: Es más robusto que los métodos <em>forward</em> o <em>backward</em> puros, ya que puede corregir decisiones anteriores. Una variable que fue importante al principio puede ser eliminada más tarde si otra la hace redundante.</li>
<li><strong>Limitación</strong>: A pesar de su flexibilidad, sigue siendo un algoritmo “codicioso” (<em>greedy</em>) que no explora todo el espacio de modelos. Por tanto, tampoco garantiza encontrar el mejor modelo global.</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled" title="Advertencia sobre los métodos automáticos">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Advertencia</span>Advertencia sobre los métodos automáticos
</div>
</div>
<div class="callout-body-container callout-body">
<p>Aunque estos métodos son herramientas útiles para un primer cribado de variables, deben usarse con extrema cautela. Su naturaleza automática puede llevar a conclusiones erróneas si no se supervisan con criterio.</p>
<ol type="1">
<li><strong>No garantizan el mejor modelo</strong>: Al seguir un camino fijo, pueden pasar por alto el subconjunto de variables verdaderamente óptimo.</li>
<li><strong>Invalidez de los p-valores</strong>: Los p-valores, errores estándar e intervalos de confianza del modelo final están <strong>sesgados</strong> y son excesivamente optimistas. El proceso de selección ha “elegido a los ganadores” de antemano, y la teoría de la inferencia estándar no se aplica a un modelo que ha sido seleccionado de esta manera.</li>
<li><strong>Inestabilidad</strong>: Los resultados pueden ser muy sensibles a pequeñas variaciones en los datos. Añadir o quitar unas pocas observaciones puede cambiar drásticamente el modelo seleccionado.</li>
</ol>
<p>Por estas razones, los métodos automáticos deben considerarse como <strong>herramientas exploratorias</strong> para generar modelos candidatos, no como un procedimiento definitivo. La selección final siempre debe estar guiada por el conocimiento del dominio, la teoría subyacente y un diagnóstico riguroso.</p>
</div>
</div>
</section>
</section>
<section id="métodos-basados-en-regularización" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="métodos-basados-en-regularización"><span class="header-section-number">5.6</span> Métodos basados en regularización</h2>
<p>En los modelos de regresión, especialmente cuando se trabaja con un gran número de variables predictoras o con datos multicolineales, los métodos tradicionales de selección de variables pueden resultar ineficaces o inestables. En estos casos, los métodos basados en regularización surgen como una alternativa poderosa que no solo selecciona variables, sino que también mejora la estabilidad y la precisión del modelo.</p>
<p>La regularización consiste en introducir una penalización en la función de ajuste del modelo, lo que tiene dos efectos principales: controlar el sobreajuste al reducir la complejidad del modelo y forzar la selección de un subconjunto más parsimonioso de predictores. Estas penalizaciones ajustan los coeficientes de las variables predictoras, favoreciendo soluciones más simples y robustas <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>.</p>
<p>Entre los métodos de regularización más destacados se encuentran:</p>
<ul>
<li><strong>Ridge Regression:</strong> Aplica una penalización proporcional al cuadrado de los coeficientes, lo que permite manejar problemas de multicolinealidad pero no conduce a la eliminación completa de variables.</li>
<li><strong>Lasso (Least Absolute Shrinkage and Selection Operator):</strong> Introduce una penalización basada en el valor absoluto de los coeficientes, lo que no solo reduce su magnitud, sino que también puede anularlos completamente, realizando una selección automática de variables.</li>
<li><strong>Elastic Net:</strong> Combina las penalizaciones de Ridge y Lasso, ofreciendo mayor flexibilidad en situaciones donde hay una gran correlación entre los predictores.</li>
</ul>
<p>Estos métodos son especialmente útiles en problemas donde el número de variables predictoras excede el número de observaciones, o cuando se desea un modelo más interpretable. En esta sección, exploraremos en detalle los fundamentos teóricos, la implementación práctica y las aplicaciones de cada uno de estos métodos, destacando sus ventajas en escenarios complejos y desafiantes.</p>
<section id="ridge-regression" class="level3" data-number="5.6.1">
<h3 data-number="5.6.1" class="anchored" data-anchor-id="ridge-regression"><span class="header-section-number">5.6.1</span> Ridge regression</h3>
<p>La regresión Ridge introduce una penalización en la estimación de los coeficientes de regresión, lo que ayuda a reducir la varianza del modelo y mejora su capacidad predictiva en presencia de datos altamente correlacionados o con muchas variables <span class="citation" data-cites="marquardt1975ridge">(<a href="#ref-marquardt1975ridge" role="doc-biblioref">Marquardt y Snee 1975</a>)</span>. El modelo de regresión Ridge es una extensión de la regresión lineal estándar. Con datos observados, escribimos:</p>
<p><span class="math display">\[
\mathbf{y}= \mathbf{X} \, \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(\mathbf{y}\)</span> es el vector de respuesta observado de dimensión <span class="math inline">\(n \times 1\)</span>.</li>
<li><span class="math inline">\(\mathbf{X}\)</span> es la matriz de diseño observada de dimensión <span class="math inline">\(n \times (p+1)\)</span> (la primera columna suele ser de unos para el intercepto).</li>
<li><span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \beta_1, \dots, \beta_p)^T\)</span> es el vector de coeficientes.</li>
<li><span class="math inline">\(\boldsymbol{\varepsilon}\)</span> es el vector de errores.</li>
</ul>
<p>En mínimos cuadrados ordinarios (OLS), los coeficientes se estiman minimizando la suma de los errores al cuadrado:</p>
<p><span class="math display">\[
SSE = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \|
\mathbf{y} - \mathbf{X} \, \boldsymbol{\beta} \|^2.
\]</span></p>
<p>Sin embargo, cuando hay multicolinealidad, la matriz <span class="math inline">\(\mathbf{X}^T \mathbf{X}\)</span> puede ser casi singular, generando coeficientes inestables. Para evitar esto, la regresión Ridge añade un <strong>término de penalización</strong> <span class="math inline">\(\lambda\)</span>, de la siguiente manera (sin penalizar el intercepto <span class="math inline">\(\beta_0\)</span>):</p>
<p><span class="math display">\[
SSE_{ridge} = \| \mathbf{y} - \mathbf{X} \, \boldsymbol{\beta} \|^2 + \lambda \sum_{j=1}^{p} \beta_j^2.
\]</span></p>
<p>Este término adicional, es un <strong>término de penalización</strong> (<span class="math inline">\(L_2=\sum \beta_j^2\)</span>) impone una restricción sobre los coeficientes, evitando que tomen valores excesivamente grandes. La estimación de <span class="math inline">\(\boldsymbol{\beta}\)</span> en Ridge se obtiene resolviendo:</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}}_{\text{ridge}} = (\mathbf{X}^T \mathbf{X} + \lambda \, \mathbf{P})^{-1}
\mathbf{X}^T \mathbf{y}.
\]</span></p>
<p>donde <span class="math inline">\(\mathbf{P}\)</span> es diagonal con <span class="math inline">\(P_{11}=0\)</span> (no penalizamos el intercepto) y <span class="math inline">\(P_{jj}=1\)</span> para <span class="math inline">\(j=2,\dots,p+1\)</span>, y <span class="math inline">\(\lambda \geq 0\)</span> controla la cantidad de penalización aplicada. (Cuando no hay intercepto o se reparametriza, a menudo se escribe con <span class="math inline">\(I\)</span> para simplificar.)</p>
<p><strong>Interpretación del parámetro</strong> <span class="math inline">\(\lambda\)</span></p>
<ul>
<li>Si <span class="math inline">\(\lambda = 0\)</span>, el modelo Ridge es equivalente a la regresión lineal tradicional (OLS).</li>
<li>A medida que <span class="math inline">\(\lambda\)</span> aumenta, los coeficientes <span class="math inline">\(\beta_j\)</span> (pendientes) se reducen en magnitud, lo que ayuda a controlar la varianza del modelo y a prevenir el sobreajuste.</li>
<li>Si <span class="math inline">\(\lambda\)</span> es demasiado grande, los coeficientes se acercan a cero y el modelo puede perder interpretabilidad.</li>
</ul>
<p>La elección óptima de <span class="math inline">\(\lambda\)</span> se determina generalmente mediante <strong>validación cruzada</strong>.</p>
<div class="callout callout-style-default callout-caution callout-titled" title="Aviso">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Precaución</span>Aviso
</div>
</div>
<div class="callout-body-container callout-body">
<p>Los detalles de la validación cruzada son tratados en la asignatura de Minería de Datos.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="Propiedades Clave">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Propiedades Clave
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>Manejo de la multicolinealidad:</strong> La regularización reduce la sensibilidad del modelo cuando los predictores están altamente correlacionados.</p></li>
<li><p><strong>Menor varianza en las predicciones:</strong> El modelo Ridge tiende a ser más estable en comparación con OLS, lo que mejora la capacidad de generalización en conjuntos de datos nuevos.</p></li>
<li><p><strong>No realiza selección de variables:</strong> A diferencia de Lasso, Ridge <strong>no anula coeficientes</strong>, sino que reduce su magnitud. Esto es útil cuando se sospecha que todas las variables tienen algún grado de importancia en el modelo.</p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar librerías</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(glmnet))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos simulados</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(<span class="dv">100</span> <span class="sc">*</span> <span class="dv">10</span>), <span class="dv">100</span>, <span class="dv">10</span>)  <span class="co"># 100 observaciones, 10 predictores</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>Y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> <span class="fu">rnorm</span>(<span class="dv">10</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)  <span class="co"># Variable de respuesta con ruido</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo Ridge</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>modelo_ridge <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">0</span>)  <span class="co"># alpha = 0 indica regresión Ridge</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Seleccionar lambda óptimo con validación cruzada</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>cv_ridge <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>lambda_optimo <span class="ot">&lt;-</span> cv_ridge<span class="sc">$</span>lambda.min  <span class="co"># Mejor valor de lambda</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(lambda_optimo)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2583753</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo final con lambda óptimo</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>modelo_ridge_final <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> lambda_optimo)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>modelo_ridge_final</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:  glmnet(x = X, y = Y, alpha = 0, lambda = lambda_optimo) 

  Df  %Dev Lambda
1 10 93.55 0.2584</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparación modelo clásico</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>modelo_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(Y<span class="sc">~</span>X)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar coeficientes</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>output<span class="ot">=</span><span class="fu">cbind</span>(<span class="fu">round</span>(<span class="fu">coef</span>(modelo_ridge_final),<span class="dv">3</span>),</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>            <span class="fu">round</span>(<span class="fu">coef</span>(modelo_lm),<span class="dv">3</span>))</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(output)<span class="ot">=</span><span class="fu">c</span>(<span class="st">"RIDGE"</span>,<span class="st">"OLS"</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>output</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 2 sparse Matrix of class "dgCMatrix"
             RIDGE    OLS
(Intercept)  0.118  0.132
V1          -0.874 -0.995
V2          -1.019 -1.131
V3           0.040  0.039
V4           0.002  0.001
V5          -2.500 -2.703
V6           1.001  1.104
V7           0.247  0.274
V8           2.125  2.244
V9           0.635  0.658
V10         -0.390 -0.427</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>La regresión Ridge es una técnica poderosa para mejorar la estabilidad de los modelos de regresión en presencia de multicolinealidad. A diferencia de OLS, que puede generar coeficientes inestables, Ridge introduce una penalización que reduce la magnitud de los coeficientes, evitando valores extremos. Aunque Ridge no realiza selección de variables, su capacidad para reducir la varianza y mejorar la capacidad predictiva lo convierte en una herramienta esencial en el análisis de datos modernos.</p>
<p>En la siguiente sección, exploraremos la <strong>regresión Lasso</strong>, que extiende este concepto permitiendo la eliminación de variables irrelevantes del modelo.</p>
</section>
<section id="regresión-lasso" class="level3" data-number="5.6.2">
<h3 data-number="5.6.2" class="anchored" data-anchor-id="regresión-lasso"><span class="header-section-number">5.6.2</span> Regresión Lasso</h3>
<p>Cuando se tiene un conjunto de predictores con posibles redundancias o ruido, Lasso permite identificar cuáles son las variables más relevantes para el modelo, lo que facilita la interpretación y reduce la complejidad del análisis.</p>
<p>Al igual que en Ridge, el modelo de regresión Lasso se define sobre datos observados mediante la minimización <span class="citation" data-cites="ranstam2018lasso">(<a href="#ref-ranstam2018lasso" role="doc-biblioref">Ranstam y Cook 2018</a>)</span>: <span class="math display">\[
SSE_{\text{lasso}} = \| \mathbf{y} - \mathbf{X} \, \boldsymbol{\beta} \|^2 + \lambda \sum_{j=1}^{p} |\beta_j|
\]</span></p>
<p>donde el <strong>término de penalización</strong> (<span class="math inline">\(L_1=\sum |\beta_j|\)</span>) no penaliza el intercepto <span class="math inline">\(\beta_0\)</span> y hace que algunos coeficientes de pendiente se reduzcan exactamente a <strong>cero</strong>, eliminando variables del modelo.</p>
<p>La diferencia clave con <strong>Ridge Regressión</strong>, visto anteriormente, es que Ridge reduce la magnitud de los coeficientes pero no los anula, mientras que <strong>Lasso puede eliminar variables por completo</strong>.</p>
<p><strong>Interpretación del parámetro</strong> <span class="math inline">\(\lambda\)</span></p>
<ul>
<li>Si <span class="math inline">\(\lambda = 0\)</span>, el modelo es equivalente a la regresión lineal tradicional (OLS).</li>
<li>A medida que <span class="math inline">\(\lambda\)</span> aumenta, más coeficientes de pendiente se reducen a cero, lo que equivale a realizar <strong>selección de variables</strong>.</li>
<li>Si <span class="math inline">\(\lambda\)</span> es demasiado grande, se eliminan demasiadas variables, lo que puede resultar en un modelo subóptimo.</li>
</ul>
<p>Al igual que en el método <em>Ridge</em>, la selección óptima de <span class="math inline">\(\lambda\)</span> se realiza generalmente mediante <strong>validación cruzada</strong>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Propiedades Clave">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Propiedades Clave
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><strong>Selección de variables automática:</strong> Lasso no solo regulariza, sino que también selecciona las variables más importantes eliminando aquellas menos relevantes.</li>
<li><strong>Manejo de la multicolinealidad:</strong> Puede mejorar la interpretación del modelo cuando hay muchas variables correlacionadas.</li>
<li><strong>Simplicidad y interpretabilidad:</strong> Un modelo con menos variables es más fácil de interpretar y aplicar en la práctica.</li>
<li><strong>Reduce el sobreajuste:</strong> La penalización <span class="math inline">\(L_1\)</span> evita que el modelo se ajuste demasiado a los datos de entrenamiento, mejorando su capacidad predictiva en datos nuevos.</li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo Lasso</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>modelo_lasso <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">1</span>)  <span class="co"># alpha = 1 indica regresión Lasso</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Seleccionar lambda óptimo con validación cruzada</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>cv_lasso <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>lambda_optimo <span class="ot">&lt;-</span> cv_lasso<span class="sc">$</span>lambda.min  <span class="co"># Mejor valor de lambda</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(lambda_optimo)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.03260326</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo final con lambda óptimo</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>modelo_lasso_final <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> lambda_optimo)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar coeficientes</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>output<span class="ot">=</span><span class="fu">cbind</span>(<span class="fu">round</span>(<span class="fu">coef</span>(modelo_lasso_final),<span class="dv">3</span>),output)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(output)<span class="ot">=</span><span class="fu">c</span>(<span class="st">"LASSO"</span>,<span class="st">"RIDGE"</span>,<span class="st">"OLS"</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>output</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 3 sparse Matrix of class "dgCMatrix"
             LASSO  RIDGE    OLS
(Intercept)  0.131  0.118  0.132
V1          -0.950 -0.874 -0.995
V2          -1.078 -1.019 -1.131
V3           0.006  0.040  0.039
V4           .      0.002  0.001
V5          -2.652 -2.500 -2.703
V6           1.058  1.001  1.104
V7           0.235  0.247  0.274
V8           2.213  2.125  2.244
V9           0.629  0.635  0.658
V10         -0.392 -0.390 -0.427</code></pre>
</div>
</div>
</div>
</div>
</div>
<p><strong>Consideraciones Importantes</strong></p>
<p>La regresión Lasso es una poderosa técnica de regularización que no solo mejora la estabilidad del modelo en presencia de muchas variables predictoras, sino que también realiza una selección automática de las más relevantes. Su capacidad para reducir coeficientes a cero la convierte en una herramienta esencial en el análisis de datos de alta dimensión.</p>
<ul>
<li><strong>Lasso puede eliminar demasiadas variables si</strong> <span class="math inline">\(\lambda\)</span> es demasiado grande, lo que puede llevar a la pérdida de información importante.</li>
<li><strong>No maneja bien grupos de predictores altamente correlacionados</strong>, ya que selecciona solo uno de ellos y elimina los demás.</li>
<li><strong>Elastic Net</strong>, que combina Ridge y Lasso, puede ser una mejor opción cuando hay <strong>multicolinealidad fuerte</strong> en los datos.</li>
</ul>
<p>En la siguiente sección, exploraremos <strong>Elastic Net</strong>, una técnica híbrida que combina las ventajas de Ridge y Lasso para mejorar la selección de variables en presencia de predictores altamente correlacionados.</p>
</section>
<section id="elastic-net" class="level3" data-number="5.6.3">
<h3 data-number="5.6.3" class="anchored" data-anchor-id="elastic-net"><span class="header-section-number">5.6.3</span> Elastic Net</h3>
<p>La regresión <strong>Elastic Net</strong> es una técnica de regularización que combina las propiedades de <strong>Ridge</strong> y <strong>Lasso</strong>, abordando algunas de sus limitaciones individuales <span class="citation" data-cites="zou2005regularization">(<a href="#ref-zou2005regularization" role="doc-biblioref">Zou y Hastie 2005</a>)</span>. Mientras que Ridge es útil para manejar la multicolinealidad sin eliminar variables y Lasso selecciona un subconjunto de predictores, Elastic Net equilibra ambos enfoques permitiendo la selección de variables en presencia de alta correlación entre los predictores.</p>
<p>Este método es particularmente efectivo cuando el número de predictores es grande y existe <strong>multicolinealidad</strong>, ya que permite controlar simultáneamente la <strong>reducción de la magnitud de los coeficientes</strong> y la <strong>eliminación de variables irrelevantes</strong>.</p>
<p>Elastic Net introduce una penalización que combina los términos de Ridge (<span class="math inline">\(L_2\)</span>) y Lasso (<span class="math inline">\(L_1\)</span>), sobre datos observados:</p>
<p><span class="math display">\[
SSE_{\text{Elastic Net}} = \| \mathbf{y} - \mathbf{X} \, \boldsymbol{\beta} \|^2 + \lambda_1 \sum_{j=1}^{p} |\beta_j| + \lambda_2 \sum_{j=1}^{p} \beta_j^2 \]</span></p>
<p>donde:</p>
<ul>
<li><span class="math inline">\(\lambda_1\)</span> (asociado a Lasso) controla la cantidad de coeficientes que se reducen a <strong>cero</strong>.</li>
<li><span class="math inline">\(\lambda_2\)</span> (asociado a Ridge) controla la <strong>reducción de magnitud</strong> de los coeficientes sin anularlos.</li>
<li><span class="math inline">\(\alpha\)</span> es un parámetro adicional que pondera la combinación entre Lasso y Ridge, con:
<ul>
<li><span class="math inline">\(\alpha = 1\)</span> → Elastic Net se comporta como Lasso.</li>
<li><span class="math inline">\(\alpha = 0\)</span> → Elastic Net se comporta como Ridge.</li>
<li><span class="math inline">\(0 &lt; \alpha &lt; 1\)</span> → Elastic Net combina ambos métodos.</li>
</ul></li>
</ul>
<p>La estimación de los coeficientes en Elastic Net se obtiene resolviendo (habitualmente sin penalizar el intercepto):</p>
<p><span class="math display">\[
\hat{\boldsymbol{\beta}}_{\text{EN}} = \arg \min_{\boldsymbol{\beta}} \left( \| \mathbf{y} - \mathbf{X} \, \boldsymbol{\beta} \|^2 + \lambda \left( \alpha \sum_{j=1}^{p} |\beta_j| + (1 - \alpha) \sum_{j=1}^{p} \beta_j^2 \right) \right)
\]</span></p>
<div class="callout callout-style-default callout-note callout-titled" title="Propiedades Clave">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Propiedades Clave
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p><strong>Manejo de la Multicolinealidad:</strong> A diferencia de Lasso, que selecciona solo una de las variables correlacionadas y elimina las demás, Elastic Net distribuye la penalización entre todas las variables correlacionadas, evitando una selección arbitraria.</p></li>
<li><p><strong>Selección de variables más estable:</strong> La combinación de Lasso y Ridge permite una selección más robusta, manteniendo información relevante del modelo sin eliminar predictores clave.</p></li>
<li><p><strong>Mejora del rendimiento predictivo:</strong> Al utilizar validación cruzada para seleccionar los hiperparámetros <span class="math inline">\(\lambda_1\)</span>, <span class="math inline">\(\lambda_2\)</span> y <span class="math inline">\(\alpha\)</span>, se optimiza la capacidad del modelo para generalizar a nuevos datos.</p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo Elastic Net</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>modelo_elastic_net <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="fl">0.5</span>)  <span class="co"># Alpha = 0.5 (50% Ridge, 50% Lasso)</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Seleccionar lambda óptimo con validación cruzada</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>cv_elastic_net <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="fl">0.5</span>)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>lambda_optimo <span class="ot">&lt;-</span> cv_elastic_net<span class="sc">$</span>lambda.min  <span class="co"># Mejor valor de lambda</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(lambda_optimo)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.0213522</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar modelo final con lambda óptimo</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>modelo_elastic_final <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(X, Y, <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">lambda =</span> lambda_optimo)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Mostrar coeficientes</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>output<span class="ot">=</span><span class="fu">cbind</span>(<span class="fu">round</span>(<span class="fu">coef</span>(modelo_elastic_final),<span class="dv">3</span>),output)</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(output)<span class="ot">=</span><span class="fu">c</span>(<span class="st">"ELASTIC"</span>,<span class="st">"LASSO"</span>,<span class="st">"RIDGE"</span>,<span class="st">"OLS"</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>output</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>11 x 4 sparse Matrix of class "dgCMatrix"
            ELASTIC  LASSO  RIDGE    OLS
(Intercept)   0.131  0.131  0.118  0.132
V1           -0.975 -0.950 -0.874 -0.995
V2           -1.108 -1.078 -1.019 -1.131
V3            0.028  0.006  0.040  0.039
V4            .      .      0.002  0.001
V5           -2.677 -2.652 -2.500 -2.703
V6            1.084  1.058  1.001  1.104
V7            0.260  0.235  0.247  0.274
V8            2.229  2.213  2.125  2.244
V9            0.647  0.629  0.635  0.658
V10          -0.414 -0.392 -0.390 -0.427</code></pre>
</div>
</div>
</div>
</div>
</div>
<p>Para determinar el mejor valor de <span class="math inline">\(\alpha\)</span>, se usa <strong>validación cruzada</strong> probando distintos valores entre <span class="math inline">\(0\)</span> y 1. Algunas estrategias comunes incluyen:</p>
<ul>
<li><strong>Si hay muchas variables irrelevantes</strong>, se recomienda <span class="math inline">\(\alpha\)</span> cercano a 1 (Lasso).</li>
<li><strong>Si hay fuerte multicolinealidad</strong>, se recomienda <span class="math inline">\(\alpha\)</span> cercano a 0 (Ridge).</li>
<li><strong>Si se desea un balance entre selección y estabilidad</strong>, se suele usar <span class="math inline">\(\alpha = 0.5\)</span>.</li>
</ul>
<p>La regresión Elastic Net combina lo mejor de Ridge y Lasso, ofreciendo un método de regularización robusto para modelos con muchas variables predictoras y posible multicolinealidad. Su capacidad para seleccionar variables sin eliminar información clave lo convierte en una opción ideal para modelos complejos y de alta dimensionalidad.</p>
</section>
<section id="comparación-de-los-métodos-de-regularización" class="level3" data-number="5.6.4">
<h3 data-number="5.6.4" class="anchored" data-anchor-id="comparación-de-los-métodos-de-regularización"><span class="header-section-number">5.6.4</span> Comparación de los métodos de Regularización</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Método</th>
<th>Penalización</th>
<th>Efecto sobre los coeficientes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>OLS</strong></td>
<td>Ninguna</td>
<td>Sin restricción, puede haber multicolinealidad</td>
</tr>
<tr class="even">
<td><strong>Ridge</strong></td>
<td><span class="math inline">\(L_2\)</span></td>
<td>Reduce la magnitud de los coeficientes, pero no los anula</td>
</tr>
<tr class="odd">
<td><strong>Lasso</strong></td>
<td><span class="math inline">\(L_1\)</span></td>
<td>Puede anular coeficientes, permitiendo selección de variables</td>
</tr>
<tr class="even">
<td><strong>Elastic Net</strong></td>
<td><span class="math inline">\(L_1 + L_2\)</span></td>
<td>Combinación de Ridge y Lasso</td>
</tr>
</tbody>
</table>
<hr>
<p>Lasso es especialmente útil cuando se sospecha que muchas variables son irrelevantes, mientras que Ridge es preferido cuando se espera que todas las variables aporten información al modelo.</p>
<p>Elastic Net es ideal cuando hay <strong>muchas variables correlacionadas</strong> y se desea un modelo <strong>estable y parsimonioso</strong>.</p>
<ul>
<li><p>Elastic Net mejora la estabilidad del modelo en comparación con Lasso, especialmente cuando hay variables predictoras altamente correlacionadas.</p></li>
<li><p>Es más flexible que Ridge y Lasso individualmente, permitiendo un ajuste más fino a distintos tipos de problemas.</p></li>
<li><p>Requiere la selección de hiperparámetros (<span class="math inline">\(\lambda\)</span> y <span class="math inline">\(\alpha\)</span>), por lo que debe usarse validación cruzada para encontrar la combinación óptima.</p></li>
</ul>
</section>
</section>
<section id="validación-del-modelo" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="validación-del-modelo"><span class="header-section-number">5.7</span> Validación del Modelo</h2>
<p>Hemos ajustado un modelo, interpretado sus coeficientes y evaluado su significancia estadística. Pero, ¿cómo podemos estar seguros de que funcionará bien en el futuro, con datos que nunca ha visto? Esta es la pregunta fundamental que la <strong>validación del modelo</strong> busca responder.</p>
<p>Imagina que estás preparando un examen. Si solo memorizas las respuestas de los exámenes de años anteriores (tus <strong>datos de entrenamiento</strong>), puede que saques una nota perfecta en ellos. Sin embargo, cuando te enfrentes al examen real con preguntas nuevas (los <strong>datos de prueba</strong>), es probable que tu rendimiento sea decepcionante. Esto, en esencia, es el <strong>sobreajuste</strong> (<em>overfitting</em>): un modelo que se aprende los datos de entrenamiento “de memoria”, incluyendo su ruido y peculiaridades, pero que pierde su capacidad de <strong>generalizar</strong> a nuevas observaciones.</p>
<p>La validación es el proceso de simular este “examen final” para obtener una estimación honesta del rendimiento predictivo de nuestro modelo en el mundo real <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>. Se compone de dos elementos clave: las <strong>estrategias de validación</strong>, que nos dicen cómo simular el examen, y las <strong>métricas de evaluación</strong>, que nos dicen cómo calificarlo.</p>
<section id="estrategias-de-validación" class="level3" data-number="5.7.1">
<h3 data-number="5.7.1" class="anchored" data-anchor-id="estrategias-de-validación"><span class="header-section-number">5.7.1</span> Estrategias de Validación</h3>
<p>Para evaluar la capacidad de generalización, necesitamos probar el modelo en datos que no se usaron para entrenarlo. Las siguientes estrategias nos permiten hacer precisamente eso.</p>
<div class="callout callout-style-default callout-warning callout-titled" title="El primer paso no negociable: La partición inicial">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Advertencia</span>El primer paso no negociable: La partición inicial
</div>
</div>
<div class="callout-body-container callout-body">
<p>Antes de escribir una sola línea de código para ajustar un modelo, seleccionar variables o ejecutar una validación cruzada, el procedimiento <strong>siempre</strong> debe comenzar con una única acción:</p>
<p><strong>Dividir el conjunto de datos completo en dos partes y guardar una de ellas bajo llave.</strong></p>
<ol type="1">
<li><strong>Datos de modelado (p.&nbsp;ej., 80% del total):</strong> Este es el conjunto de datos con el que trabajarás. Lo usarás para todas tus tareas de construcción y evaluación de modelos: entrenar, comparar diferentes conjuntos de variables, y ejecutar estrategias como la validación cruzada.</li>
<li><strong>Conjunto de prueba Final (p.&nbsp;ej., 20% restante):</strong> Este conjunto de datos debe ser guardado y <strong>no ser utilizado bajo ninguna circunstancia</strong> durante el proceso de modelado. Es tu “examen final sorpresa”, tu única oportunidad de obtener una estimación verdaderamente honesta y no sesgada del rendimiento del modelo que has seleccionado como el campeón definitivo.</li>
</ol>
<p>La validación cruzada y la división simple train/test que veremos a continuación son técnicas que se aplican <strong>dentro</strong> de los “datos de modelado”.</p>
</div>
</div>
<section id="el-conjunto-de-entrenamiento-y-test-traintest-split" class="level4" data-number="5.7.1.1">
<h4 data-number="5.7.1.1" class="anchored" data-anchor-id="el-conjunto-de-entrenamiento-y-test-traintest-split"><span class="header-section-number">5.7.1.1</span> El Conjunto de entrenamiento y test (Train/Test Split)</h4>
<p>La estrategia más directa es tomar nuestros “Datos de Modelado” (el 80% inicial) y volver a dividirlos, creando un único “examen” para el proceso de construcción del modelo <span class="citation" data-cites="hastie2009elements">(<a href="#ref-hastie2009elements" role="doc-biblioref">Hastie et&nbsp;al. 2009</a>)</span>:</p>
<ol type="1">
<li><strong>Conjunto de entrenamiento (<em>Training Set</em>)</strong>: Usualmente, el 70-80% de los datos. El modelo se construye y se ajusta usando únicamente esta porción. Es aquí donde el modelo “aprende”.</li>
<li><strong>Conjunto de test (<em>Test Set</em>)</strong>: El 20-30% restante. Estos datos se mantienen “ocultos” durante el entrenamiento. Una vez que el modelo está finalizado, lo usamos para predecir la variable respuesta en este conjunto. La comparación entre las predicciones (<span class="math inline">\(\hat{y}\)</span>) y los valores reales (<span class="math inline">\(y\)</span>) nos da una medida no sesgada de su rendimiento.</li>
</ol>
<p>Aunque es simple y computacionalmente barata, esta técnica tiene una debilidad importante: los resultados pueden depender mucho de la división aleatoria específica que se haya hecho. Si por mala suerte en el conjunto de prueba caen observaciones muy atípicas, nuestra evaluación del modelo será excesivamente pesimista. Si caen puntos muy fáciles de predecir, será demasiado optimista. Esta alta variabilidad es un problema, especialmente con muestras de datos pequeñas.</p>
</section>
<section id="validación-cruzada-cross-validation" class="level4" data-number="5.7.1.2">
<h4 data-number="5.7.1.2" class="anchored" data-anchor-id="validación-cruzada-cross-validation"><span class="header-section-number">5.7.1.2</span> Validación cruzada (Cross-Validation)</h4>
<p>La <strong>validación cruzada</strong> es la solución a la variabilidad de la división simple y se aplica, de nuevo, <strong>sobre el conjunto total de “datos de modelado”</strong>. En lugar de hacer un único “examen final”, la validación cruzada promedia los resultados de múltiples mini-exámenes, proporcionando una estimación del error mucho más estable y fiable <span class="citation" data-cites="james2013introduction">(<a href="#ref-james2013introduction" role="doc-biblioref">James et&nbsp;al. 2013</a>)</span>.</p>
<p>El método más común es la <strong>validación cruzada de k-particiones (<em>k-fold cross-validation</em>)</strong>. Su nombre describe el proceso: los datos se dividen en <em>k</em> particiones y se “cruzan” los roles de entrenamiento y validación.</p>
<p>El resultado final de este procedimiento es el <strong>error de validación cruzada</strong>, que se calcula promediando los errores obtenidos en cada una de las <em>k</em> particiones. Esto nos da una única métrica de rendimiento para el modelo.</p>
<p><span class="math display">\[CV_{(k)} = \frac{1}{k}\sum_{i=1}^{k} \text{Métrica}_i\]</span></p>
<p>donde <span class="math inline">\(\text{Métrica}_i\)</span> es la métrica de error (como RMSE o MAE) calculada en la i-ésima iteración. La elección de <em>k</em> suele ser 5 o 10, ya que se ha demostrado que estos valores ofrecen un buen equilibrio entre el sesgo y la varianza de la estimación del error.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Procedimiento de k-particiones">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Nota</span>Procedimiento de k-particiones
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>División</strong>: Dividir aleatoriamente los datos en <em>k</em> <strong>particiones</strong> de tamaño similar.</li>
<li><strong>Iteración</strong>: Para cada partición <span class="math inline">\(i = 1, 2, ..., k\)</span>:
<ul>
<li>Usar la partición <span class="math inline">\(i\)</span> como conjunto de test.</li>
<li>Usar las restantes <span class="math inline">\(k-1\)</span> particiones como conjunto de entrenamiento.</li>
<li>Ajustar el modelo y calcular las métricas de desempeño en el conjunto de test.</li>
</ul></li>
<li><strong>Promedio</strong>: Calcular el promedio de las métricas a través de las <em>k</em> iteraciones.</li>
</ol>
</div>
</div>
<p>Un caso extremo de este método es la <strong>validación cruzada “dejando uno fuera” (LOOCV)</strong>, donde <em>k</em> es igual al número de observaciones, <em>n</em>. En cada iteración, se entrena el modelo con <em>n-1</em> datos y se prueba en el único punto restante. Aunque es computacionalmente muy costoso, en regresión lineal existe una afortunada fórmula matemática que nos permite calcular el error LOOCV con la misma rapidez que un solo ajuste:</p>
<p><span class="math display">\[CV_{(n)} = \frac{1}{n}\sum_{i=1}^{n}\left(\frac{y_i - \hat{y}_i}{1-h_{ii}}\right)^2\]</span></p>
<p>donde <span class="math inline">\(h_{ii}\)</span> es el apalancamiento (<em>leverage</em>) de la i-ésima observación.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Guía para seleccionar estrategia de validación">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Importante</span>Guía para seleccionar estrategia de validación
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Usa Train/Test cuando:</strong></p>
<ul>
<li>El dataset es grande (n &gt; 1000)</li>
<li>Los recursos computacionales son limitados<br>
</li>
<li>Se requiere una evaluación rápida</li>
</ul>
<p><strong>Usa validación cruzada k-fold cuando:</strong></p>
<ul>
<li>El dataset es de tamaño moderado (n &lt; 1000)</li>
<li>Se requiere una estimación más estable del desempeño</li>
<li>Se dispone de recursos computacionales adecuados</li>
</ul>
<p><strong>Usa LOOCV cuando:</strong></p>
<ul>
<li>El dataset es pequeño (n &lt; 100)</li>
<li>Se requiere la estimación menos sesgada posible</li>
<li>El tiempo computacional no es una restricción crítica</li>
</ul>
</div>
</div>
</section>
</section>
<section id="métricas-de-rendimiento" class="level3" data-number="5.7.2">
<h3 data-number="5.7.2" class="anchored" data-anchor-id="métricas-de-rendimiento"><span class="header-section-number">5.7.2</span> Métricas de rendimiento</h3>
<p>Una vez que usamos una estrategia de validación para generar predicciones sobre datos no vistos, necesitamos una “nota” para cuantificar qué tan buenos fueron esos pronósticos. Aquí es donde entran las métricas de error.</p>
<section id="raíz-del-error-cuadrático-medio" class="level4" data-number="5.7.2.1">
<h4 data-number="5.7.2.1" class="anchored" data-anchor-id="raíz-del-error-cuadrático-medio"><span class="header-section-number">5.7.2.1</span> Raíz del error cuadrático medio</h4>
<p>La métrica más utilizada es la <strong>raíz del error cuadrático medio (RMSE)</strong>. Es como una desviación típica de los residuos, y nos da una idea de la magnitud promedio de los errores de predicción.</p>
<p><span class="math display">\[RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}\]</span></p>
<p>La característica clave del RMSE es que, al elevar los errores al cuadrado, <strong>penaliza de forma desproporcionada los errores grandes</strong>. Un solo error de predicción de 10 unidades contribuye al RMSE mucho más que 10 errores de 1 unidad. Esto lo hace muy sensible a valores atípicos. Su gran ventaja es que se expresa en las mismas unidades que la variable respuesta, facilitando su interpretación.</p>
</section>
<section id="error-absoluto-medio" class="level4" data-number="5.7.2.2">
<h4 data-number="5.7.2.2" class="anchored" data-anchor-id="error-absoluto-medio"><span class="header-section-number">5.7.2.2</span> Error absoluto medio</h4>
<p>Una alternativa popular es el <strong>error absoluto medio (MAE)</strong>, que simplemente promedia el valor absoluto de los errores.</p>
<p><span class="math display">\[MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y}_i|\]</span></p>
<p>A diferencia del RMSE, el MAE no eleva los errores al cuadrado, por lo que <strong>trata todos los errores de forma proporcional a su magnitud</strong>. Un error de 10 unidades es simplemente el doble de malo que un error de 5. Esto hace que el MAE sea <strong>más robusto frente a valores atípicos</strong> y, para muchos, más fácil de interpretar como “el error promedio” que cometemos en nuestras predicciones.</p>
<p>En resumen, la validación nos obliga a confrontar nuestro modelo con la realidad de datos nuevos. Usando una estrategia robusta como la <strong>validación cruzada</strong> para calcular una métrica interpretable como el <strong>RMSE</strong> o el <strong>MAE</strong>, podemos obtener una estimación fiable de su rendimiento predictivo y construir modelos en los que realmente podamos confiar. Claro, aquí tienes ese contenido reorganizado y resumido dentro de un recuadro (<code>callout</code>), ideal para destacar esta idea clave en tu libro.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Interpretando el Error">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Importante</span>Interpretando el Error
</div>
</div>
<div class="callout-body-container callout-body">
<p>La comparación entre el error del modelo en los datos que ha visto (entrenamiento) y en datos que no ha visto (validación) es la herramienta de diagnóstico más importante para entender el ajuste del modelo.</p>
<p>La regla general es que el error de entrenamiento siempre será más bajo (más optimista) que el de test. La clave está en analizar la <strong>diferencia</strong> entre ambos.</p>
<p><strong>Sobreajuste (Overfitting)</strong></p>
<ul>
<li><strong>Síntoma</strong>: Error de entrenamiento <strong>bajo</strong> + Error de test <strong>mucho más alto</strong>.</li>
<li><strong>Diagnóstico</strong>: El modelo ha “memorizado” el ruido de los datos de entrenamiento y no es capaz de generalizar a nuevos datos.</li>
<li><strong>Solución</strong>: Simplificar el modelo (usar menos variables, aplicar regularización como Ridge o Lasso).</li>
</ul>
<p><strong>Subajuste (Underfitting)</strong></p>
<ul>
<li><strong>Síntoma</strong>: Error de entrenamiento <strong>alto</strong> + Error de test <strong>alto y similar</strong>.</li>
<li><strong>Diagnóstico</strong>: El modelo es demasiado simple y no tiene la capacidad de capturar la estructura subyacente de los datos.</li>
<li><strong>Solución</strong>: Aumentar la complejidad del modelo (añadir más variables, incluir interacciones o términos no lineales).</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="La maldición del sobreajuste">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>La maldición del sobreajuste
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Para ilustrar por qué la validación es indispensable, realizaremos un experimento controlado. Crearemos un conjunto de datos donde <strong>conocemos la verdad</strong>: sabemos exactamente qué variables influyen en la respuesta y cuáles son puro ruido. Luego, compararemos dos modelos:</p>
<ol type="1">
<li><strong>Modelo Completo</strong>: Un modelo que incluye todas las variables disponibles, tanto las útiles como las de ruido.</li>
<li><strong>Modelo Correcto</strong>: Un modelo que incluye únicamente las variables que realmente tienen un efecto sobre la respuesta.</li>
</ol>
<p>El objetivo es ver cuál de los dos modelos predice mejor en datos “no vistos”, utilizando la validación cruzada para simular este escenario.</p>
<p><strong>1. Simulación de Datos</strong></p>
<p>Creamos un dataset con 100 observaciones. La variable <code>y</code> dependerá de <code>X1</code>, <code>X2</code> y <code>X3</code>. Las variables <code>X4</code> a <code>X10</code> no tendrán ninguna relación real con <code>y</code>; serán <strong>predictores de ruido</strong>.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cargar la librería 'caret', que simplifica enormemente el proceso de validación</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">suppressPackageStartupMessages</span>(<span class="fu">library</span>(caret))</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Para reproducibilidad</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Crear datos de ejemplo</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 3 predictores verdaderos y 7 de ruido</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rnorm</span>(n <span class="sc">*</span> <span class="dv">10</span>), n, <span class="dv">10</span>)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(X) <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">"X"</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># La respuesta 'y' depende SOLO de X1, X2 y X3</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>beta_true <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.5</span>, <span class="sc">-</span><span class="fl">1.5</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>) </span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> X <span class="sc">%*%</span> beta_true <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Combinar en un data frame</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">y =</span> y, X)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>indices_modelado <span class="ot">&lt;-</span> <span class="fu">createDataPartition</span>(datos<span class="sc">$</span>y, <span class="at">p =</span> <span class="fl">0.8</span>, <span class="at">list =</span> <span class="cn">FALSE</span>)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>datos_modelado <span class="ot">&lt;-</span> datos[indices_modelado, ]</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>datos_prueba_final <span class="ot">&lt;-</span> datos[<span class="sc">-</span>indices_modelado, ]</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>2. Ajuste y Evaluación de Modelos con Validación Cruzada</strong></p>
<p>Usaremos la función <code>train()</code> del paquete <code>caret</code>, que es una herramienta increíblemente potente para ajustar y validar modelos. Configuraremos una <strong>validación cruzada de 10 particiones (10-fold CV)</strong> para estimar el error de predicción (RMSE) de nuestros dos modelos.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Configurar el método de validación cruzada de 10 particiones</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>control_cv <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">"cv"</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar y validar el MODELO COMPLETO (incluye predictores de ruido)</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>modelo_completo <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> ., </span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> datos_modelado, </span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> control_cv</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustar y validar el MODELO CORRECTO (solo los predictores relevantes)</span></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>modelo_correcto <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> X1 <span class="sc">+</span> X2 <span class="sc">+</span> X3, </span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> datos_modelado, </span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"lm"</span>,</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> control_cv</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparar los resultados de la validación cruzada de ambos modelos</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>resultados_cv <span class="ot">&lt;-</span> <span class="fu">resamples</span>(<span class="fu">list</span>(<span class="at">COMPLETO =</span> modelo_completo, <span class="at">CORRECTO =</span> modelo_correcto))</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>resumen_cv <span class="ot">&lt;-</span> <span class="fu">summary</span>(resultados_cv)</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>resumen_cv</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
summary.resamples(object = resultados_cv)

Models: COMPLETO, CORRECTO 
Number of resamples: 10 

MAE 
              Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's
COMPLETO 0.8638906 1.284897 1.585880 1.685953 1.895840 2.783321    0
CORRECTO 0.7192667 1.279226 1.602489 1.687326 2.283342 2.477780    0

RMSE 
              Min.  1st Qu.   Median     Mean  3rd Qu.     Max. NA's
COMPLETO 1.0722692 1.592663 2.105678 2.116903 2.523848 3.119017    0
CORRECTO 0.9052294 1.474694 1.934304 2.020464 2.480041 3.124041    0

Rsquared 
              Min.   1st Qu.    Median      Mean   3rd Qu.      Max. NA's
COMPLETO 0.5917775 0.7793610 0.8556182 0.8189137 0.8882997 0.9505874    0
CORRECTO 0.5019737 0.7988599 0.8513481 0.8017851 0.9048191 0.9385882    0</code></pre>
</div>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraer métricas RMSE para uso en el texto</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>rmse_correcto <span class="ot">&lt;-</span> <span class="fu">round</span>(resumen_cv<span class="sc">$</span>statistics<span class="sc">$</span>RMSE[<span class="st">"CORRECTO"</span>, <span class="st">"Mean"</span>], <span class="dv">3</span>)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>rmse_completo <span class="ot">&lt;-</span> <span class="fu">round</span>(resumen_cv<span class="sc">$</span>statistics<span class="sc">$</span>RMSE[<span class="st">"COMPLETO"</span>, <span class="st">"Mean"</span>], <span class="dv">3</span>)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p><strong>3. Análisis de Resultados</strong></p>
<p>Al comparar el <strong>RMSE</strong> promedio obtenido en la validación cruzada, la conclusión es clara: el <strong>Modelo Correcto</strong> (2.02) es consistentemente <strong>mejor</strong> (menor error) que el <strong>Modelo Completo</strong> (2.117).</p>
<p>El <strong>Modelo Completo</strong> sufre de <strong>sobreajuste</strong>. Al incluir las 7 variables de ruido, se esfuerza por encontrar patrones en datos puramente aleatorios. “Aprende” estas relaciones falsas en los datos de entrenamiento, pero falla al predecir en datos nuevos. El <strong>Modelo Correcto</strong>, al ser más parsimonioso, captura la estructura fundamental y generaliza mejor.</p>
<p>Este ejemplo demuestra la lección más importante del modelado: <strong>un buen ajuste en los datos de entrenamiento no garantiza un buen rendimiento predictivo</strong>. La validación es el único método fiable para estimar la verdadera calidad de un modelo.</p>
<p><strong>4. El Veredicto Final en el Conjunto de Prueba</strong></p>
<p>La validación cruzada nos ha servido como un juez imparcial para comparar nuestros modelos candidatos y seleccionar el <code>Modelo Correcto</code> como el claro ganador. Ahora, para obtener una estimación final y no sesgada de su rendimiento en el mundo real, tomamos ese modelo elegido y lo enfrentamos a los <code>datos_prueba_final</code>, el conjunto de datos que ha permanecido intacto durante todo el proceso.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usamos el modelo ganador (modelo_correcto) para predecir sobre los datos de prueba</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>predicciones_finales <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_correcto, <span class="at">newdata =</span> datos_prueba_final)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculamos el RMSE final comparando las predicciones con los valores reales de prueba</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>rmse_final <span class="ot">&lt;-</span> <span class="fu">RMSE</span>(predicciones_finales, datos_prueba_final<span class="sc">$</span>y)</span></code></pre></div><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Al evaluar nuestro modelo final, obtenemos un RMSE en el conjunto de prueba de <strong>1.966</strong>.</p>
<p>Este valor es nuestra estimación más honesta del error de predicción que podemos esperar de nuestro modelo al enfrentarse a nuevos datos. Es crucial compararlo con el error que estimamos durante la validación cruzada (2.02). El hecho de que ambos valores sean muy similares confirma que nuestro proceso de validación fue robusto y que no hemos sobreajustado el modelo al conjunto de datos de modelado. Este RMSE final es el que reportaríamos como la medida definitiva del rendimiento predictivo de nuestro modelo.</p>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-hastie2009elements" class="csl-entry" role="listitem">
Hastie, Trevor, Robert Tibshirani, Jerome H Friedman, y Jerome H Friedman. 2009. <em>The elements of statistical learning: data mining, inference, and prediction</em>. Vol. 2. Springer.
</div>
<div id="ref-james2013introduction" class="csl-entry" role="listitem">
James, Gareth, Daniela Witten, Trevor Hastie, Robert Tibshirani, et&nbsp;al. 2013. <em>An introduction to statistical learning</em>. Vol. 112. Springer.
</div>
<div id="ref-kutner2005applied" class="csl-entry" role="listitem">
Kutner, Michael H, Christopher J Nachtsheim, John Neter, y William Li. 2005. <em>Applied linear statistical models</em>. McGraw-hill.
</div>
<div id="ref-marquardt1975ridge" class="csl-entry" role="listitem">
Marquardt, Donald W, y Ronald D Snee. 1975. <span>«Ridge regression in practice»</span>. <em>The American Statistician</em> 29 (1): 3-20.
</div>
<div id="ref-ranstam2018lasso" class="csl-entry" role="listitem">
Ranstam, Jonas, y Jonathan A Cook. 2018. <span>«LASSO regression»</span>. <em>Journal of British Surgery</em> 105 (10): 1348-48.
</div>
<div id="ref-zou2005regularization" class="csl-entry" role="listitem">
Zou, Hui, y Trevor Hastie. 2005. <span>«Regularization and variable selection via the elastic net»</span>. <em>Journal of the Royal Statistical Society Series B: Statistical Methodology</em> 67 (2): 301-20.
</div>
</div>
</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./tema3.html" class="pagination-link" aria-label="Ingeniería de características: transformaciones de variables e interacciones">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Ingeniería de características: transformaciones de variables e interacciones</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./tema5.html" class="pagination-link" aria-label="Modelos de regresión generalizada">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>