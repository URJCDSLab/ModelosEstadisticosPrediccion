---
title: "Modelos de Regresión Generalizada"
subtitle: "Modelos Estadísticos para la Predicción"
author: "Prof. Dr. José Luis Romero"
date: today
format:
  revealjs:
    theme: default
    incremental: true
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: img/logos/uma.png
    css: styles.css
    footer: "Modelos Estadísticos para la Predicción - Tema 5"
execute:
  echo: true
  warning: false
  message: false
---

## Contenidos

::: {.nonincremental}
1. **Introducción a los GLM**
2. **Componentes de un GLM**
3. **Estimación de parámetros**
4. **Bondad de ajuste**
5. **Diagnosis de GLMs**
6. **Regresión logística**
7. **Regresión de Poisson**
8. **Otros GLMs**
:::

## 1. Introducción a los GLM

### ¿Por qué necesitamos GLM?

- La regresión lineal asume:
  - Variable dependiente **continua**
  - Distribución **normal**
  - Varianza **constante** (homocedasticidad)
  
- Problemas del mundo real:
  - Variable dependiente **binaria** (enfermo/sano)
  - Datos de **conteo** (número de accidentes)
  - Variables **positivas** y sesgadas (costos, tiempos)

## Comparación de modelos

:::: {.columns}

::: {.column width="50%}
### Regresión Lineal
$$Y = \beta_0 + \beta_1 X_1 + \epsilon$$

- Variable dependiente: Normal
- Relación: Lineal directa
- Varianza: Constante
:::

::: {.column width="50%}
### GLM
$$g(\mu) = \beta_0 + \beta_1 X_1$$

- Variable dependiente: Familia exponencial
- Relación: Función de enlace
- Varianza: Función de la media
:::

::::

## Tipos principales de GLM

::: {.nonincremental}
| **Modelo** | **Variable** | **Aplicación** |
|:-----------|:-------------|:---------------|
| **Logística** | Binaria | Diagnóstico médico, marketing |
| **Poisson** | Conteos | Accidentes, llamadas |
| **Binomial Negativa** | Conteos con sobredispersión | Visitas médicas |
| **Gamma** | Continua positiva | Costos, tiempos |
:::

## 2. Componentes de un GLM

### Tres elementos fundamentales

1. **Componente Aleatorio**
   - Distribución de la variable dependiente
   - Familia exponencial (normal, binomial, Poisson, gamma)

2. **Componente Sistemático**
   - Predictor lineal: $\eta = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$

3. **Función de Enlace**
   - Conecta la media con el predictor lineal: $g(\mu) = \eta$

## Familia Exponencial

::: {.nonincremental}
Forma unificada para todas las distribuciones:

$$f(y; \theta, \phi) = \exp\left\{\frac{y\theta - b(\theta)}{a(\phi)} + c(y, \phi)\right\}$$
:::

**Propiedades clave:**
- $E(Y) = \mu = b'(\theta)$
- $\text{Var}(Y) = a(\phi) V(\mu)$
- $V(\mu)$ es la función de varianza específica

## Funciones de Enlace

::: {.nonincremental}
| **Enlace** | **$g(\mu)$** | **Modelo** | **$V(\mu)$** |
|:-----------|:-------------|:-----------|:-------------|
| Identidad | $\mu$ | Normal | 1 |
| Logit | $\log\left(\frac{\mu}{1-\mu}\right)$ | Logística | $\mu(1-\mu)$ |
| Log | $\log(\mu)$ | Poisson | $\mu$ |
| Inverso | $1/\mu$ | Gamma | $\mu^2$ |
:::

## ¿Por qué funciones de enlace?

:::: {.columns}

::: {.column width="50%}
**Sin función de enlace:**
- Probabilidades > 1 o < 0
- Conteos negativos
- Valores negativos para variables positivas
:::

::: {.column width="50%}
**Con función de enlace:**
- Garantiza restricciones del dominio
- Linealidad en escala transformada
- Interpretación matemática elegante
:::

::::

## 3. Estimación de parámetros

### Máxima Verosimilitud vs. Mínimos Cuadrados

- **Mínimos cuadrados** requieren:
  - Normalidad
  - Homocedasticidad
  
- **Máxima verosimilitud** permite:
  - Cualquier distribución de la familia exponencial
  - Heterocedasticidad natural
  - Marco teórico unificado

## Función de Verosimilitud

::: {.nonincremental}
Para $n$ observaciones independientes:

$$L(\boldsymbol{\beta}) = \prod_{i=1}^{n} f(y_i; \theta_i, \phi)$$

**Log-verosimilitud:**
$$\ell(\boldsymbol{\beta}) = \sum_{i=1}^{n} \log f(y_i; \theta_i, \phi)$$
:::

**Objetivo:** Encontrar $\boldsymbol{\beta}$ que maximice $\ell(\boldsymbol{\beta})$

## Algoritmo IRLS

**Iteratively Reweighted Least Squares**

1. **Inicializar** $\boldsymbol{\beta}^{(0)}$
2. **En cada iteración $t$:**
   - Calcular predictor lineal: $\eta_i^{(t)} = \mathbf{x}_i^T \boldsymbol{\beta}^{(t)}$
   - Calcular media: $\mu_i^{(t)} = g^{-1}(\eta_i^{(t)})$
   - Calcular pesos: $w_i^{(t)} = \frac{1}{\text{Var}(\mu_i^{(t)})} \left(\frac{d\mu_i}{d\eta_i}\right)^2$
   - Actualizar: $\boldsymbol{\beta}^{(t+1)} = (X^T \mathbf{W}^{(t)} X)^{-1} X^T \mathbf{W}^{(t)} \mathbf{z}^{(t)}$
3. **Repetir** hasta convergencia

## Propiedades de los Estimadores MV

**1. Consistencia:**
$$\hat{\boldsymbol{\beta}} \xrightarrow{p} \boldsymbol{\beta} \text{ cuando } n \to \infty$$

**2. Normalidad asintótica:**
$$\sqrt{n}(\hat{\boldsymbol{\beta}} - \boldsymbol{\beta}) \xrightarrow{d} N(\mathbf{0}, \mathbf{I}^{-1}(\boldsymbol{\beta}))$$

**3. Eficiencia:**
- Alcanzan la cota de Cramér-Rao
- Menor varianza asintótica posible

## Errores Estándar

::: {.nonincremental}
**Matriz de información:**
$$\mathbf{I}(\hat{\boldsymbol{\beta}}) \approx X^T \mathbf{W} X$$

**Errores estándar:**
$$\text{SE}(\hat{\beta}_j) = \sqrt{[\mathbf{I}^{-1}(\hat{\boldsymbol{\beta}})]_{jj}}$$
:::

**Usos:**
- Intervalos de confianza: $\hat{\beta}_j \pm z_{\alpha/2} \cdot \text{SE}(\hat{\beta}_j)$
- Tests de hipótesis: $z_j = \frac{\hat{\beta}_j}{\text{SE}(\hat{\beta}_j)}$

## 4. Bondad de Ajuste

### La Deviance: Concepto Central

::: {.nonincremental}
**Idea:** Comparar nuestro modelo con el "modelo perfecto"

$$D = 2 \sum_{i=1}^{n} \left[ \ell(y_i; y_i) - \ell(y_i; \hat{\mu}_i) \right]$$
:::

- **Modelo Saturado:** Predicción perfecta (tantos parámetros como observaciones)
- **Modelo Propuesto:** Nuestro modelo con $p$ parámetros
- **Factor 2:** Para distribución $\chi^2$ aproximada

## Interpretación de la Deviance

- **Deviance = 0:** Ajuste perfecto
- **Deviance baja:** Buen ajuste
- **Deviance alta:** Mal ajuste
- **Uso principal:** Comparación relativa entre modelos

## Test de Razón de Verosimilitudes

::: {.nonincremental}
**Para modelos anidados:**
$$LRT = D_{\text{reducido}} - D_{\text{completo}} \sim \chi^2_{df}$$
:::

**Aplicaciones:**
- Significancia global del modelo
- Selección de variables
- Comparación de especificaciones

## 5. Diagnosis de GLMs

### Tres preguntas clave

1. **¿La forma del modelo es correcta?**
   - Linealidad y función de enlace apropiada

2. **¿La distribución elegida es correcta?**
   - Relación media-varianza adecuada

3. **¿Hay observaciones influyentes?**
   - Puntos que distorsionan el modelo

## Tipos de Residuos

:::: {.columns}

::: {.column width="50%}
**Residuos Deviance (recomendados):**
$$d_i = \text{sign}(y_i - \hat{\mu}_i) \sqrt{2[l_i(y_i) - l_i(\hat{\mu}_i)]}$$

**Residuos Pearson:**
$$r_i = \frac{y_i - \hat{\mu}_i}{\sqrt{V(\hat{\mu}_i)}}$$
:::

::: {.column width="50%}
**Ventajas residuos deviance:**
- Distribución ≈ normal
- Media ≈ 0
- Varianza ≈ constante
- Ideales para gráficos
:::

::::

## Gráficos diagnósticos

- **Residuos vs valores ajustados:** Detecta patrones no lineales
- **Residuos vs predictores:** Verifica especificación correcta
- **Q-Q plot de residuos:** Evalúa normalidad aproximada
- **Residuos vs leverage:** Identifica puntos influyentes

## Sobredispersión

::: {.nonincremental}
**Estadístico de dispersión:**
$$\hat{\phi} = \frac{X^2_{\text{Pearson}}}{n-p} = \frac{\sum r_i^2}{n-p}$$
:::

- $\hat{\phi} \approx 1$: Dispersión apropiada
- $\hat{\phi} > 1$: **Sobredispersión** (problema serio en Poisson)
- $\hat{\phi} < 1$: Subdispersión (raro)

## 6. Regresión Logística

### Modelo

::: {.nonincremental}
**Función logística:**
$$P(Y = 1 | X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X_1 + \dots + \beta_p X_p)}}$$
:::

**Función de enlace logit:**
$$\text{logit}(p) = \log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$$

## La Curva Sigmoide

```{r}
#| echo: false
#| fig-width: 8
#| fig-height: 5

# Crear datos para la curva sigmoide
x <- seq(-6, 6, 0.1)
p <- 1 / (1 + exp(-x))

plot(x, p, type = "l", lwd = 3, col = "blue",
     xlab = "Predictor lineal (η)", ylab = "Probabilidad P(Y=1)",
     main = "Función Logística (Sigmoide)",
     cex.lab = 1.2, cex.main = 1.3)
grid()
abline(h = 0.5, lty = 2, col = "red")
abline(v = 0, lty = 2, col = "red")
```

## Interpretación: Odds Ratios

::: {.nonincremental}
**Odds:**
$$\text{odds} = \frac{p}{1-p}$$

**Odds Ratio:**
$$\text{OR} = e^{\beta}$$
:::

**Interpretación:**
- OR > 1: Incremento en probabilidad
- OR < 1: Disminución en probabilidad
- OR = 1: Sin efecto

## Ejemplo de Odds Ratio

Si $\beta_{\text{BMI}} = 0.08$:

$$\text{OR} = e^{0.08} = 1.083$$

**Significa:** Por cada unidad adicional de BMI, las odds de diabetes aumentan un 8.3%

## Validación del modelo logístico

### Matriz de Confusión

::: {.nonincremental}
|   | **Predicho** |   |
|:---|:---:|:---:|
| **Real** | **0** | **1** |
| **0** | VN | FP |
| **1** | FN | VP |
:::

**Métricas:**
- **Precisión:** $\frac{VP + VN}{\text{Total}}$
- **Sensibilidad:** $\frac{VP}{VP + FN}$
- **Especificidad:** $\frac{VN}{VN + FP}$

## Curva ROC y AUC

:::: {.columns}

::: {.column width="50%"}
**Curva ROC:**
- Sensibilidad vs (1 - Especificidad)
- Para todos los umbrales posibles
- Independiente del umbral elegido
:::

::: {.column width="50%"}
**AUC (Área bajo la curva):**
- 0.9-1.0: Excelente
- 0.8-0.9: Buena
- 0.7-0.8: Aceptable
- 0.6-0.7: Pobre
- 0.5-0.6: Sin capacidad discriminativa
:::

::::

## 7. Regresión de Poisson

### Modelo

::: {.nonincremental}
**Distribución:**
$$P(Y = y) = \frac{e^{-\lambda} \lambda^y}{y!}$$

**Modelo:**
$$\log(\lambda) = \beta_0 + \beta_1 X_1 + \dots + \beta_p X_p$$
:::

**Supuesto clave:** $E(Y) = \text{Var}(Y) = \lambda$ (equidispersión)

## Interpretación: IRR

::: {.nonincremental}
**Incidence Rate Ratio:**
$$\text{IRR} = e^{\beta_j}$$
:::

**Interpretación:**
- IRR > 1: Aumento en la tasa de eventos
- IRR < 1: Disminución en la tasa de eventos
- IRR = 1: Sin efecto

**Factor multiplicativo** sobre la tasa esperada

## Problema: Sobredispersión

**Detección:**
$$\hat{\phi} = \frac{\text{Deviance residual}}{n-p}$$

- $\hat{\phi} \approx 1$: ✓ Modelo Poisson apropiado
- $\hat{\phi} > 1.5$: ⚠️ Sobredispersión significativa
- **Consecuencia:** Errores estándar subestimados
- **Solución:** Regresión Binomial Negativa

## 8. Otros GLMs

### Binomial Negativa

**Extensión de Poisson para sobredispersión:**

$$\text{Var}(Y) = \lambda + \alpha \lambda^2$$

**Parámetro $\theta$ (theta):**
- $\theta$ grande (>100): Poca sobredispersión ≈ Poisson
- $\theta$ pequeño (<10): Mucha sobredispersión

## Modelos para datos continuos positivos

:::: {.columns}

::: {.column width="50%"}
### Regresión Gamma
- Datos positivos y asimétricos
- $\text{Var}(Y) \propto \mu^2$
- Ejemplos: costos, tiempos
- Enlace: $\log(\mu)$
:::

::: {.column width="50%"}
### Inversa Gaussiana
- Asimetría muy pronunciada
- Tiempos hasta eventos
- Enlace: $\frac{1}{\mu^2}$
- Aplicaciones: tiempos de falla
:::

::::

## Guía para selección de GLMs

::: {.nonincremental}
**Variable binaria (0/1, Sí/No)** → **Regresión Logística**

**Conteos de eventos** → **Regresión de Poisson**
- Si hay sobredispersión → **Binomial Negativa**

**Variable continua positiva y sesgada** → **Regresión Gamma**

**Tiempos hasta eventos** → **Inversa Gaussiana**
:::

## Resumen

### GLMs proporcionan:

- **Flexibilidad** para diferentes tipos de datos
- **Marco unificado** (familia exponencial)
- **Interpretación clara** de coeficientes
- **Herramientas robustas** de diagnóstico

### Elementos clave:

- Función de enlace apropiada
- Diagnóstico de supuestos
- Validación predictiva

## Preguntas y Discusión

::: {.nonincremental}
**Referencias principales:**

- Nelder, J. A., & Wedderburn, R. W. (1972). Generalized linear models. *Journal of the Royal Statistical Society: Series A*, 135(3), 370-384.
- McCullagh, P., & Nelder, J. A. (1989). *Generalized linear models* (2nd ed.). Chapman and Hall/CRC.
- Hosmer, D. W., & Lemeshow, S. (2013). *Applied logistic regression* (3rd ed.). Wiley.
:::
- $\theta$ pequeño (<10): Mucha sobredispersión
- **Criterio:** Comparar AIC con Poisson
:::

## Regresión Gamma

**Para variables continuas positivas y sesgadas:**

:::: {.columns}

::: {.column width="50%"}
**Características:**
- Solo valores positivos
- Distribución asimétrica
- $\text{Var}(Y) \propto \mu^2$
:::

::: {.column width="50%"}
**Aplicaciones:**
- Costos médicos
- Tiempos de espera
- Ingresos
- Reclamaciones de seguros
:::

::::

**Enlace común:** $\log(\mu) = \beta_0 + \beta_1 X_1 + \dots$

## Regresión Inversa Gaussiana

**Para tiempos hasta eventos:**

:::: {.columns}

::: {.column width="50%"}
**Características:**
- Asimetría muy pronunciada
- Varianza decrece rápidamente
- Tiempos de respuesta
:::

::: {.column width="50%"}
**Enlace común:**
$$\frac{1}{\mu^2} = \beta_0 + \beta_1 X_1 + \dots$$

**Aplicaciones:**
- Tiempos hasta falla
- Procesos industriales
:::

::::

## ¿Qué GLM usar? - Guía Práctica

::: {.incremental}
**Variable binaria (0/1, Sí/No)** → **Regresión Logística**

**Conteos de eventos** → **Regresión de Poisson**
- Si hay sobredispersión → **Binomial Negativa**

**Variable continua positiva y sesgada** → **Regresión Gamma**

**Tiempos hasta eventos** → **Inversa Gaussiana**
:::

# Resumen y Conclusiones

## GLMs: Una Extensión Poderosa

::: {.incremental}
**Ventajas principales:**
- **Flexibilidad:** Múltiples tipos de datos
- **Marco unificado:** Familia exponencial
- **Interpretación:** Coeficientes tienen sentido práctico
- **Robustez:** Estimación por máxima verosimilitud

**Elementos clave:**
- Función de enlace apropiada
- Diagnóstico de supuestos
- Validación predictiva
:::

## Flujo de Trabajo Recomendado

::: {.incremental}
1. **Identificar** tipo de variable dependiente
2. **Elegir** GLM apropiado
3. **Ajustar** modelo inicial
4. **Diagnosticar** residuos y supuestos
5. **Validar** capacidad predictiva
6. **Comparar** con modelos alternativos
7. **Interpretar** coeficientes en contexto
:::

## Herramientas de Diagnóstico Esenciales

::: {.incremental}
- **Residuos deviance** para gráficos
- **Estadístico de dispersión** para sobredispersión
- **AIC/BIC** para comparación de modelos
- **Curva ROC** para modelos de clasificación
- **RMSE/MAE** para modelos de conteo
- **Validación cruzada** siempre
:::

---

## ¡Gracias por su atención!

### Preguntas y Discusión

::: {.fragment}
**Próxima clase:** Aplicaciones avanzadas y casos de estudio
:::
