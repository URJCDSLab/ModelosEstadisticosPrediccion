---
title: "Modelos de Regresión Generalizada"
author: "Víctor Aceña - Isaac Martín"
institute: "DSLAB"
date: last-modified
format: 
  beamer: 
    template: dslab_fixed.beamer.tex
    slide-level: 1
    section-titles: false
knitr:
  opts_chunk:
    fig.width: 6
    fig.height: 4
    fig.align: "center"
    dev: "pdf"
    out.width: "70%"
execute:
  echo: false
# Validación Cruzada:**
```{r cross-validation, echo=TRUE}
library(caret)

# Crear dataframe para validación cruzada
datos_cv <- data.frame(y_bin = y_bin, x1 = x1)

# Validación cruzada para modelo logístico
ctrl <- trainControl(method = "cv", number = 10, classProbs = TRUE)
cv_results <- train(factor(y_bin) ~ x1, data = datos_cv, method = "glm", 
                   family = binomial, trControl = ctrl)
cv_results$results$Accuracy
``` false
  message: false
  cache: false
---

# Introducción a los Modelos Lineales Generalizados

**La regresión lineal tradicional tiene limitaciones importantes cuando la variable dependiente no es continua y normal**

**Problemas frecuentes en el mundo real:**

- Variables dependientes **binarias** (éxito/fracaso, enfermo/sano)
- Datos de **conteo** (número de accidentes, llamadas, eventos)
- Variables **continuas positivas** y sesgadas (tiempos, costos, ingresos)
- **Heterocedasticidad** relacionada con la media

**Los Modelos Lineales Generalizados (GLM) extienden la regresión lineal para manejar estos casos**

# ¿Qué son los GLM?

**Los GLM son una generalización flexible de la regresión lineal que permite:**

- Trabajar con **distribuciones de la familia exponencial** (binomial, Poisson, gamma, etc.)
- Utilizar **funciones de enlace** para transformar la relación lineal
- Modelar la **varianza** como función de la media
- Mantener la **interpretabilidad** de los coeficientes

**Ventajas clave:**

- **Flexibilidad** para diferentes tipos de datos
- **Marco unificado** para múltiples modelos
- **Inferencia estadística** robusta
- **Interpretación** intuitiva de resultados

# Los Tres Componentes de un GLM

**Todo GLM se define por tres componentes esenciales:**

## 1. Componente Aleatorio
- **Distribución** de la variable dependiente $Y$
- Debe pertenecer a la **familia exponencial**
- Ejemplos: Normal, Binomial, Poisson, Gamma, Binomial Negativa

## 2. Componente Sistemático  
- **Predictor lineal**: $\eta = \beta_0 + \beta_1 x_1 + \ldots + \beta_p x_p$
- Combina las variables explicativas **linealmente**

## 3. Función de Enlace
- **Conecta** la media de $Y$ con el predictor lineal
- $g(\mu) = \eta$, donde $\mu = E[Y]$ y $g$ es la función de enlace

# Familia Exponencial

**La familia exponencial incluye distribuciones con la forma:**

$$f(y; \theta, \phi) = \exp\left\{\frac{y\theta - b(\theta)}{a(\phi)} + c(y, \phi)\right\}$$

**Distribuciones más comunes:**

- **Normal**: $\theta = \mu$, $b(\theta) = \theta^2/2$
- **Binomial**: $\theta = \log\left(\frac{\pi}{1-\pi}\right)$, $b(\theta) = \log(1 + e^\theta)$  
- **Poisson**: $\theta = \log(\lambda)$, $b(\theta) = e^\theta$
- **Gamma**: $\theta = -1/\mu$, $b(\theta) = -\log(-\theta)$

**Propiedades importantes:**
- $E[Y] = b'(\theta)$
- $\text{Var}(Y) = b''(\theta) \cdot a(\phi)$

# Funciones de Enlace Principales

**La función de enlace determina cómo se relaciona la media con el predictor lineal**

| **Distribución** | **Enlace Canónico** | **Función** | **Enlace Inverso** |
|------------------|---------------------|-------------|-------------------|
| Normal | Identidad | $\eta = \mu$ | $\mu = \eta$ |
| Binomial | Logit | $\eta = \log\left(\frac{\pi}{1-\pi}\right)$ | $\pi = \frac{e^\eta}{1+e^\eta}$ |
| Poisson | Log | $\eta = \log(\lambda)$ | $\lambda = e^\eta$ |
| Gamma | Inverso | $\eta = -1/\mu$ | $\mu = -1/\eta$ |

**Otros enlaces útiles:**
- **Probit**: $\eta = \Phi^{-1}(\pi)$ para datos binarios
- **Log-log complementario**: $\eta = \log(-\log(1-\pi))$

# Estimación por Máxima Verosimilitud

**Los GLM utilizan máxima verosimilitud para estimar parámetros**

**Algoritmo de Newton-Raphson (IRLS):**

1. **Inicializar** $\beta^{(0)}$
2. **Iterar** hasta convergencia:
   - Calcular $\eta^{(t)} = X\beta^{(t)}$
   - Obtener $\mu^{(t)} = g^{-1}(\eta^{(t)})$
   - Construir matriz de pesos $W^{(t)}$
   - Actualizar: $\beta^{(t+1)} = (X^T W^{(t)} X)^{-1} X^T W^{(t)} z^{(t)}$

**Variable de trabajo:** $z = \eta + (y - \mu) \frac{d\eta}{d\mu}$

**Matriz de pesos:** $W = \text{diag}\left[\frac{(\frac{d\mu}{d\eta})^2}{\text{Var}(Y)}\right]$

# Medidas de Bondad de Ajuste

**Deviance (Desvianza):**
$$D = 2[\ell(\hat{\theta}_{\text{saturado}}) - \ell(\hat{\theta}_{\text{modelo}})]$$

**Deviance Residual:**
$$D_i = \text{sign}(y_i - \hat{\mu}_i) \sqrt{d_i}$$

**Criterios de Información:**
- **AIC**: $-2\ell + 2p$
- **BIC**: $-2\ell + p \log(n)$

**Pseudo R²:**
$$R^2 = 1 - \frac{D_{\text{modelo}}}{D_{\text{nulo}}}$$

# Diagnóstico de GLMs

**Residuos Principales:**

- **Residuos de Pearson**: $r_P = \frac{y - \hat{\mu}}{\sqrt{\text{Var}(\hat{\mu})}}$
- **Residuos Deviance**: $r_D = \text{sign}(y - \hat{\mu})\sqrt{d_i}$
- **Residuos Estandarizados**: $r_s = \frac{r}{\sqrt{1-h_i}}$

**Gráficos de Diagnóstico:**
- Residuos vs valores ajustados
- Q-Q plot de residuos
- Residuos vs leverage
- Distancia de Cook

**Pruebas Específicas:**
- Test de sobredispersión
- Test de bondad de ajuste de Hosmer-Lemeshow

# Regresión Logística

**Para variables dependientes binarias ($Y \in \{0,1\}$)**

**Modelo:**
- Distribución: $Y \sim \text{Binomial}(1, \pi)$
- Función de enlace: $\text{logit}(\pi) = \log\left(\frac{\pi}{1-\pi}\right) = \beta_0 + \beta_1 x_1 + \ldots$

**Interpretación:**
$$\pi = \frac{e^{\beta_0 + \beta_1 x_1 + \ldots}}{1 + e^{\beta_0 + \beta_1 x_1 + \ldots}}$$

**Odds Ratio:** $\text{OR} = e^{\beta_i}$
- $\text{OR} > 1$: La variable aumenta las probabilidades
- $\text{OR} < 1$: La variable disminuye las probabilidades
- $\text{OR} = 1$: Sin efecto

# Ejemplo: Regresión Logística

```{r logistic-example, echo=TRUE}
# Datos simulados: probabilidad de aprobar vs horas de estudio
set.seed(123)
horas <- runif(100, 0, 10)
logit_p <- -2 + 0.5 * horas
prob_aprobar <- plogis(logit_p)
aprobar <- rbinom(100, 1, prob_aprobar)

# Ajustar modelo logístico
modelo_logit <- glm(aprobar ~ horas, family = binomial(link = "logit"))
summary(modelo_logit)
```

# Interpretación del Modelo Logístico

```{r logistic-interpretation, echo=TRUE}
# Coeficientes e interpretación
coef(modelo_logit)

# Odds ratio
exp(coef(modelo_logit))

# Probabilidad predicha para 5 horas de estudio
predict(modelo_logit, newdata = data.frame(horas = 5), type = "response")

# Intervalo de confianza para OR
exp(confint(modelo_logit))
```

**Por cada hora adicional de estudio, las odds de aprobar se multiplican por** `r round(exp(coef(modelo_logit)[2]), 2)`

# Visualización de Regresión Logística

```{r logistic-plot, fig.height=3}
library(ggplot2)

# Crear datos para la curva suave
horas_pred <- seq(0, 10, 0.1)
prob_pred <- predict(modelo_logit, 
                    newdata = data.frame(horas = horas_pred), 
                    type = "response")

# Gráfico
ggplot() +
  geom_point(aes(x = horas, y = aprobar), alpha = 0.6) +
  geom_line(aes(x = horas_pred, y = prob_pred), color = "red", size = 1) +
  labs(title = "Regresión Logística: Probabilidad de Aprobar",
       x = "Horas de Estudio", y = "Probabilidad de Aprobar") +
  theme_minimal()
```

# Regresión de Poisson

**Para datos de conteo ($Y \in \{0,1,2,\ldots\}$)**

**Modelo:**
- Distribución: $Y \sim \text{Poisson}(\lambda)$
- Función de enlace: $\log(\lambda) = \beta_0 + \beta_1 x_1 + \ldots$

**Interpretación:**
$$\lambda = e^{\beta_0 + \beta_1 x_1 + \ldots}$$

**Interpretación de coeficientes:**
- $e^{\beta_i}$ es el **factor multiplicativo** en la media
- Un aumento unitario en $x_i$ multiplica $\lambda$ por $e^{\beta_i}$

**Supuestos:**
- $E[Y] = \text{Var}(Y) = \lambda$ (equidispersión)

# Ejemplo: Regresión de Poisson

```{r poisson-example, echo=TRUE}
# Datos simulados: número de accidentes vs tráfico
set.seed(456)
trafico <- runif(100, 1, 5)
log_lambda <- 0.5 + 0.3 * trafico
accidentes <- rpois(100, exp(log_lambda))

# Ajustar modelo de Poisson
modelo_poisson <- glm(accidentes ~ trafico, family = poisson(link = "log"))
summary(modelo_poisson)
```

# Interpretación del Modelo de Poisson

```{r poisson-interpretation, echo=TRUE}
# Coeficientes
coef(modelo_poisson)

# Factor multiplicativo
exp(coef(modelo_poisson))

# Número esperado de accidentes para tráfico = 3
predict(modelo_poisson, newdata = data.frame(trafico = 3), type = "response")

# IC para el factor multiplicativo
exp(confint(modelo_poisson))
```

**Por cada unidad adicional de tráfico, el número esperado de accidentes se multiplica por** `r round(exp(coef(modelo_poisson)[2]), 2)`

# Sobredispersión en Modelos de Poisson

**Problema común:** $\text{Var}(Y) > E[Y]$ (sobredispersión)

**Detección:**
```{r overdispersion, echo=TRUE}
# Estadístico de dispersión
dispersion <- sum(residuals(modelo_poisson, type = "pearson")^2) / df.residual(modelo_poisson)
dispersion
```

**Soluciones para sobredispersión:**
- **Quasi-Poisson**: Permite $\text{Var}(Y) = \phi \lambda$
- **Binomial Negativa**: Distribución alternativa con parámetro de dispersión
- **Modelos Zero-Inflated**: Para exceso de ceros

# Quasi-Poisson y Binomial Negativa

```{r overdispersion-solutions, echo=TRUE}
# Modelo Quasi-Poisson
modelo_quasi <- glm(accidentes ~ trafico, family = quasipoisson(link = "log"))

# Modelo Binomial Negativa
library(MASS)
modelo_nb <- glm.nb(accidentes ~ trafico)

# Comparar AIC
AIC(modelo_poisson, modelo_nb)
```

**El parámetro de dispersión en quasi-Poisson:** `r round(summary(modelo_quasi)$dispersion, 2)`

# Otros GLMs Importantes

**Modelo Gamma:**
- Variables **continuas positivas** y sesgadas
- $Y \sim \text{Gamma}(\text{shape}, \text{rate})$
- Enlace: Inverso, Log, Identidad

**Modelo Binomial Negativa:**
- Datos de **conteo con sobredispersión**
- Parámetro adicional de dispersión

**Modelo Beta:**
- Variables en el intervalo $(0,1)$
- Proporciones, porcentajes

**Modelos Zero-Inflated:**
- Datos de conteo con **exceso de ceros**
- Combina proceso binario + Poisson/Binomial Negativa

# Comparación de Modelos GLM

```{r model-comparison, echo=TRUE}
# Crear datos con diferentes características
set.seed(789)
n <- 200

# Datos binarios
x1 <- rnorm(n)
prob <- plogis(-1 + 2*x1)
y_bin <- rbinom(n, 1, prob)

# Datos de conteo
x2 <- runif(n, 0, 3)
lambda <- exp(0.5 + 0.8*x2)
y_count <- rpois(n, lambda)

# Datos continuos positivos
x3 <- rnorm(n)
shape <- 2; rate <- exp(-0.5 - 0.5*x3)
y_gamma <- rgamma(n, shape = shape, rate = rate)
```

# Selección del GLM Apropiado

```{r glm-selection, echo=TRUE}
# Ajustar diferentes modelos
mod_logit <- glm(y_bin ~ x1, family = binomial)
mod_poisson <- glm(y_count ~ x2, family = poisson)
mod_gamma <- glm(y_gamma ~ x3, family = Gamma(link = "log"))

# Comparar AIC
c("Logístico" = AIC(mod_logit),
  "Poisson" = AIC(mod_poisson), 
  "Gamma" = AIC(mod_gamma))
```

**Criterios de selección:**
- **Tipo de variable dependiente**
- **Distribución de los datos**
- **Relación media-varianza**
- **Criterios de información** (AIC, BIC)

# Diagnóstico Integral de GLMs

```{r glm-diagnostics, fig.height=2.5, echo=TRUE}
# Ejemplo con modelo logístico
par(mfrow = c(1, 2))

# Residuos vs valores ajustados
plot(fitted(mod_logit), residuals(mod_logit, type = "deviance"),
     xlab = "Valores Ajustados", ylab = "Residuos Deviance",
     main = "Residuos vs Ajustados")
abline(h = 0, col = "red")

# Q-Q plot
qqnorm(residuals(mod_logit, type = "deviance"))
qqline(residuals(mod_logit, type = "deviance"), col = "red")
```

# Herramientas de Validación

**Validación Cruzada:**
```{r cross-validation, echo=TRUE}
library(caret)

# Validación cruzada para modelo logístico
ctrl <- trainControl(method = "cv", number = 10, classProbs = TRUE)
cv_results <- train(factor(y_bin) ~ x1, method = "glm", 
                   family = binomial, trControl = ctrl)
cv_results$results$Accuracy
```

**Curva ROC (para clasificación):**
```{r roc-curve, echo=TRUE}
library(pROC)
prob_pred <- predict(mod_logit, type = "response")
roc_curve <- roc(y_bin, prob_pred)
auc(roc_curve)
```

# Casos de Uso Prácticos

**Regresión Logística:**
- Diagnóstico médico (enfermo/sano)
- Marketing (compra/no compra)
- Finanzas (default/no default)

**Regresión de Poisson:**
- Número de llamadas por hora
- Accidentes de tráfico
- Visitas a un sitio web

**Modelo Gamma:**
- Tiempo hasta fallo
- Costos de seguros
- Ingresos por ventas

**Selección basada en la naturaleza de los datos y objetivos del análisis**

# Ventajas y Limitaciones de GLMs

**Ventajas:**

- **Marco unificado** para múltiples tipos de datos
- **Interpretabilidad** mantenida
- **Inferencia estadística** robusta
- **Flexibilidad** en funciones de enlace
- **Eficiencia computacional**

**Limitaciones:**

- **Relación lineal** en el predictor transformado
- **Distribuciones limitadas** a familia exponencial
- **Sobredispersión** en algunos casos
- **Outliers** pueden ser influyentes
- **Interacciones** requieren especificación manual

# Extensiones Modernas de GLMs

**GLMs con Efectos Mixtos (GLMM):**
- Incorporan **efectos aleatorios**
- Datos **longitudinales** y **jerárquicos**

**Modelos Aditivos Generalizados (GAM):**
- **Suavizado no paramétrico**
- Relaciones **no lineales**

**Regularización:**
- **Lasso**, **Ridge**, **Elastic Net**
- Selección automática de variables

**GLMs Bayesianos:**
- Incorporan **incertidumbre a priori**
- **Intervalos creíbles**

# Implementación en R

**Función principal:** `glm()`

```{r r-implementation, echo=TRUE, eval=FALSE}
# Sintaxis general
modelo <- glm(formula, family = familia(link = "enlace"), data = datos)

# Familias principales
family = binomial(link = "logit")      # Regresión logística
family = poisson(link = "log")         # Regresión de Poisson  
family = Gamma(link = "log")           # Modelo Gamma
family = gaussian(link = "identity")   # Regresión lineal

# Predicciones
predict(modelo, newdata = nuevos_datos, type = "response")

# Diagnóstico
plot(modelo)  # Gráficos de diagnóstico automáticos
```

# Resumen y Buenas Prácticas

**Pasos para un análisis GLM exitoso:**

1. **Explorar** los datos y identificar la distribución apropiada
2. **Seleccionar** la familia y función de enlace
3. **Ajustar** el modelo usando máxima verosimilitud
4. **Evaluar** la bondad de ajuste (deviance, AIC, pseudo R²)
5. **Diagnosticar** residuos y detectar observaciones influyentes
6. **Interpretar** coeficientes en la escala apropiada
7. **Validar** usando datos independientes o validación cruzada

**Recuerda:** Los GLMs son una herramienta poderosa pero requieren comprensión de sus supuestos y limitaciones

# ¡Gracias por su atención!

**Preguntas y Discusión**

**Recursos adicionales:**
- McCullagh, P. & Nelder, J.A. (1989). *Generalized Linear Models*
- Dobson, A.J. & Barnett, A.G. (2018). *An Introduction to Generalized Linear Models*
- Wood, S.N. (2017). *Generalized Additive Models: An Introduction with R*

**Próximos pasos:**
- Práctica con datos reales
- Exploración de extensiones (GAMs, GLMMs)
- Aplicaciones específicas por disciplina
