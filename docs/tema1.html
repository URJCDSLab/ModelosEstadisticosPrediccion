<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; El modelo de regresión lineal simple – Modelos Estadísticos para la Predicción</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./tema2.html" rel="next">
<link href="./tema0.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-1b90310288666db1f83ae9fc236520cd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./tema1.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal simple</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modelos Estadísticos para la Predicción</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema0.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción a los modelos de regresión</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal simple</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos de selección de variables y problemas de regularización</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Modelos no lineales. Transformación de variables. Ingeniería de características.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Modelos de regresión generalizada</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./tema5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Otros modelos de regresión: Modelos Aditivos Generalizados (GAMs)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografía</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#exploración-inicial-visualización-y-cuantificación-de-la-relación" id="toc-exploración-inicial-visualización-y-cuantificación-de-la-relación" class="nav-link active" data-scroll-target="#exploración-inicial-visualización-y-cuantificación-de-la-relación"><span class="header-section-number">2.1</span> Exploración inicial: visualización y cuantificación de la relación</a>
  <ul class="collapse">
  <li><a href="#visualización-el-gráfico-de-dispersión" id="toc-visualización-el-gráfico-de-dispersión" class="nav-link" data-scroll-target="#visualización-el-gráfico-de-dispersión"><span class="header-section-number">2.1.1</span> Visualización: el gráfico de dispersión</a></li>
  <li><a href="#cuantificación-de-la-asociación-covarianza-y-correlación" id="toc-cuantificación-de-la-asociación-covarianza-y-correlación" class="nav-link" data-scroll-target="#cuantificación-de-la-asociación-covarianza-y-correlación"><span class="header-section-number">2.1.2</span> Cuantificación de la asociación: covarianza y correlación</a></li>
  </ul></li>
  <li><a href="#formulación-teórica-del-modelo" id="toc-formulación-teórica-del-modelo" class="nav-link" data-scroll-target="#formulación-teórica-del-modelo"><span class="header-section-number">2.2</span> Formulación teórica del modelo</a>
  <ul class="collapse">
  <li><a href="#el-modelo-poblacional-y-sus-componentes" id="toc-el-modelo-poblacional-y-sus-componentes" class="nav-link" data-scroll-target="#el-modelo-poblacional-y-sus-componentes"><span class="header-section-number">2.2.1</span> El modelo poblacional y sus componentes</a></li>
  <li><a href="#los-supuestos-del-modelo-lineal-clásico-gauss-markov" id="toc-los-supuestos-del-modelo-lineal-clásico-gauss-markov" class="nav-link" data-scroll-target="#los-supuestos-del-modelo-lineal-clásico-gauss-markov"><span class="header-section-number">2.2.2</span> Los supuestos del modelo lineal clásico (Gauss-Markov)</a></li>
  </ul></li>
  <li><a href="#estimación-de-los-parámetros" id="toc-estimación-de-los-parámetros" class="nav-link" data-scroll-target="#estimación-de-los-parámetros"><span class="header-section-number">2.3</span> Estimación de los parámetros</a>
  <ul class="collapse">
  <li><a href="#el-criterio-de-mínimos-cuadrados" id="toc-el-criterio-de-mínimos-cuadrados" class="nav-link" data-scroll-target="#el-criterio-de-mínimos-cuadrados"><span class="header-section-number">2.3.1</span> El criterio de mínimos cuadrados</a></li>
  <li><a href="#derivación-matemática-de-los-estimadores" id="toc-derivación-matemática-de-los-estimadores" class="nav-link" data-scroll-target="#derivación-matemática-de-los-estimadores"><span class="header-section-number">2.3.2</span> Derivación matemática de los estimadores</a></li>
  </ul></li>
  <li><a href="#inferencia-y-bondad-de-ajuste" id="toc-inferencia-y-bondad-de-ajuste" class="nav-link" data-scroll-target="#inferencia-y-bondad-de-ajuste"><span class="header-section-number">2.4</span> Inferencia y bondad de ajuste</a>
  <ul class="collapse">
  <li><a href="#propiedades-de-los-estimadores-de-mco" id="toc-propiedades-de-los-estimadores-de-mco" class="nav-link" data-scroll-target="#propiedades-de-los-estimadores-de-mco"><span class="header-section-number">2.4.1</span> Propiedades de los estimadores de MCO</a></li>
  <li><a href="#estimación-de-la-varianza-del-error" id="toc-estimación-de-la-varianza-del-error" class="nav-link" data-scroll-target="#estimación-de-la-varianza-del-error"><span class="header-section-number">2.4.2</span> Estimación de la varianza del error</a></li>
  <li><a href="#análisis-de-la-varianza-anova-para-la-significancia-de-la-regresión" id="toc-análisis-de-la-varianza-anova-para-la-significancia-de-la-regresión" class="nav-link" data-scroll-target="#análisis-de-la-varianza-anova-para-la-significancia-de-la-regresión"><span class="header-section-number">2.4.3</span> Análisis de la Varianza (ANOVA) para la significancia de la regresión</a></li>
  <li><a href="#bondad-del-ajuste-coeficiente-de-determinación" id="toc-bondad-del-ajuste-coeficiente-de-determinación" class="nav-link" data-scroll-target="#bondad-del-ajuste-coeficiente-de-determinación"><span class="header-section-number">2.4.4</span> Bondad del ajuste: coeficiente de determinación</a></li>
  <li><a href="#inferencia-sobre-los-coeficientes" id="toc-inferencia-sobre-los-coeficientes" class="nav-link" data-scroll-target="#inferencia-sobre-los-coeficientes"><span class="header-section-number">2.4.5</span> Inferencia sobre los coeficientes</a></li>
  </ul></li>
  <li><a href="#predicción-de-nuevas-observaciones" id="toc-predicción-de-nuevas-observaciones" class="nav-link" data-scroll-target="#predicción-de-nuevas-observaciones"><span class="header-section-number">2.5</span> Predicción de nuevas observaciones</a>
  <ul class="collapse">
  <li><a href="#intervalo-de-confianza-para-la-respuesta-media" id="toc-intervalo-de-confianza-para-la-respuesta-media" class="nav-link" data-scroll-target="#intervalo-de-confianza-para-la-respuesta-media"><span class="header-section-number">2.5.1</span> Intervalo de confianza para la respuesta media</a></li>
  <li><a href="#intervalo-de-predicción-para-una-respuesta-individual" id="toc-intervalo-de-predicción-para-una-respuesta-individual" class="nav-link" data-scroll-target="#intervalo-de-predicción-para-una-respuesta-individual"><span class="header-section-number">2.5.2</span> Intervalo de predicción para una respuesta individual</a></li>
  </ul></li>
  <li><a href="#diagnóstico-del-modelo" id="toc-diagnóstico-del-modelo" class="nav-link" data-scroll-target="#diagnóstico-del-modelo"><span class="header-section-number">2.6</span> Diagnóstico del Modelo</a>
  <ul class="collapse">
  <li><a href="#linealidad" id="toc-linealidad" class="nav-link" data-scroll-target="#linealidad"><span class="header-section-number">2.6.1</span> Linealidad</a></li>
  <li><a href="#homocedasticidad" id="toc-homocedasticidad" class="nav-link" data-scroll-target="#homocedasticidad"><span class="header-section-number">2.6.2</span> Homocedasticidad</a></li>
  <li><a href="#normalidad-de-los-errores" id="toc-normalidad-de-los-errores" class="nav-link" data-scroll-target="#normalidad-de-los-errores"><span class="header-section-number">2.6.3</span> 3. Normalidad de los Errores</a></li>
  <li><a href="#independencia-de-los-errores" id="toc-independencia-de-los-errores" class="nav-link" data-scroll-target="#independencia-de-los-errores"><span class="header-section-number">2.6.4</span> 4. Independencia de los Errores</a></li>
  <li><a href="#identificación-de-observaciones-influyentes-y-atípicas" id="toc-identificación-de-observaciones-influyentes-y-atípicas" class="nav-link" data-scroll-target="#identificación-de-observaciones-influyentes-y-atípicas"><span class="header-section-number">2.6.5</span> 5. Identificación de Observaciones Influyentes y Atípicas</a></li>
  <li><a href="#aplicación-práctica-en-r" id="toc-aplicación-práctica-en-r" class="nav-link" data-scroll-target="#aplicación-práctica-en-r"><span class="header-section-number">2.6.6</span> Aplicación Práctica en R</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-regresion-lineal-simple" class="quarto-section-identifier"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">El modelo de regresión lineal simple</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>La regresión lineal constituye uno de los pilares fundamentales de la modelización estadística. Es, a menudo, el primer y más importante modelo predictivo que se aprende, no solo por su simplicidad e interpretabilidad, sino porque los conceptos que exploraremos aquí son la base sobre la que se construyen técnicas mucho más avanzadas, como el <strong>modelo de regresión lineal múltiple</strong>, los <strong>modelos lineales generalizados (GLM)</strong> o incluso conceptos utilizados en algoritmos de <em>machine learning</em> <span class="citation" data-cites="draper1998applied">(<a href="references.html#ref-draper1998applied" role="doc-biblioref">Draper 1998</a>)</span>.</p>
<p>En este capítulo, daremos el primer y más crucial paso en nuestro viaje por el modelado predictivo: el estudio del <strong>modelo de regresión lineal simple</strong>. Para ello, seguiremos el ciclo de vida completo de un proyecto de modelado: comenzaremos con la exploración visual y cuantitativa de los datos, formalizaremos después nuestras observaciones mediante el lenguaje matemático del modelo y sus supuestos, aprenderemos a estimar sus parámetros, realizaremos inferencias sobre ellos y, finalmente, diagnosticaremos la validez de nuestro modelo.</p>
<p>La comprensión profunda que desarrollaremos aquí es esencial, ya que los principios de estimación, inferencia y diagnóstico que aprenderemos son directamente escalables al <strong>modelo de regresión lineal múltiple</strong>, que exploraremos en el siguiente capítulo.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Objetivos de aprendizaje">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Objetivos de aprendizaje
</div>
</div>
<div class="callout-body-container callout-body">
<p>Al finalizar este capítulo, serás capaz de:</p>
<ol type="1">
<li><strong>Comprender y aplicar</strong> el proceso de modelización estadística para un problema con una única variable predictora.</li>
<li><strong>Identificar y medir la correlación lineal</strong> entre dos variables como paso previo al modelado.</li>
<li><strong>Describir la formulación matemática</strong> del modelo de regresión lineal simple e interpretar el significado práctico de sus parámetros.</li>
<li><strong>Estimar los coeficientes</strong> del modelo mediante el método de mínimos cuadrados ordinarios (MCO) y entender su derivación matemática y propiedades.</li>
<li><strong>Realizar inferencias sobre los parámetros</strong> del modelo y evaluar su bondad de ajuste mediante el análisis de la varianza y el coeficiente de determinación R².</li>
<li><strong>Diagnosticar la adecuación del modelo</strong>, evaluando visual y analíticamente si se cumplen los supuestos del modelo lineal.</li>
</ol>
</div>
</div>
<section id="exploración-inicial-visualización-y-cuantificación-de-la-relación" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="exploración-inicial-visualización-y-cuantificación-de-la-relación"><span class="header-section-number">2.1</span> Exploración inicial: visualización y cuantificación de la relación</h2>
<p>Antes de sumergirnos en la teoría de la regresión, debemos hacer lo que todo buen analista hace primero: <strong>observar y cuantificar la relación en los datos</strong>. Este paso exploratorio es fundamental para formular hipótesis y justificar la elección de un modelo lineal.</p>
<section id="visualización-el-gráfico-de-dispersión" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="visualización-el-gráfico-de-dispersión"><span class="header-section-number">2.1.1</span> Visualización: el gráfico de dispersión</h3>
<p>La herramienta más potente para examinar la relación entre dos variables continuas es el <strong>gráfico de dispersión</strong> (<em>scatterplot</em>). Nos permite intuir visualmente la <strong>forma</strong>, la <strong>dirección</strong> y la <strong>fuerza</strong> de la relación. Una inspección visual es siempre el punto de partida.</p>
</section>
<section id="cuantificación-de-la-asociación-covarianza-y-correlación" class="level3" data-number="2.1.2">
<h3 data-number="2.1.2" class="anchored" data-anchor-id="cuantificación-de-la-asociación-covarianza-y-correlación"><span class="header-section-number">2.1.2</span> Cuantificación de la asociación: covarianza y correlación</h3>
<p>Una vez que la visualización sugiere una tendencia, necesitamos métricas para cuantificarla.</p>
<section id="covarianza" class="level4" data-number="2.1.2.1">
<h4 data-number="2.1.2.1" class="anchored" data-anchor-id="covarianza"><span class="header-section-number">2.1.2.1</span> Covarianza</h4>
<p>La <strong>covarianza</strong> es una medida de la variabilidad conjunta de dos variables aleatorias, <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. Nos indica la dirección de la relación lineal. La covarianza muestral, calculada a partir de nuestras observaciones <span class="math inline">\((x_i, y_i)\)</span>, es:</p>
<p><span class="math display">\[
\text{Cov}(x, y) = s_{xy} = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{n-1}
\]</span></p>
<p>El principal inconveniente de la covarianza es que su magnitud depende de las unidades de las variables, lo que la hace difícil de interpretar.</p>
</section>
<section id="coeficiente-de-correlación-de-pearson" class="level4" data-number="2.1.2.2">
<h4 data-number="2.1.2.2" class="anchored" data-anchor-id="coeficiente-de-correlación-de-pearson"><span class="header-section-number">2.1.2.2</span> Coeficiente de correlación de Pearson</h4>
<p>Para solucionar el problema de la escala, estandarizamos la covarianza, dividiéndola por el producto de las desviaciones típicas de cada variable. El resultado es el <strong>coeficiente de correlación de Pearson (<span class="math inline">\(r\)</span>)</strong>:</p>
<p><span class="math display">\[
r = r_{xy} = \frac{s_{xy}}{s_x s_y}
\]</span></p>
<p>Este coeficiente es <strong>adimensional</strong> y siempre varía entre <strong>-1 y 1</strong>, lo que permite una interpretación universal de la fuerza de la asociación <em>lineal</em>.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo práctico: Horas de estudio vs. Calificaciones">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo práctico: Horas de estudio vs.&nbsp;Calificaciones
</div>
</div>
<div class="callout-body-container callout-body">
<p>Vamos a plantear un problema que nos acompañará durante todo el capítulo: queremos saber si el tiempo de estudio semanal influye en las calificaciones finales.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>) <span class="co"># Para reproducibilidad</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulación de datos</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">Tiempo_Estudio =</span> <span class="fu">round</span>(<span class="fu">runif</span>(<span class="dv">100</span>, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">40</span>), <span class="dv">1</span>)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>datos<span class="sc">$</span>Calificaciones <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">5</span> <span class="sc">+</span> <span class="fl">0.1</span> <span class="sc">*</span> datos<span class="sc">$</span>Tiempo_Estudio <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.5</span>), <span class="dv">2</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualización</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(datos, <span class="fu">aes</span>(<span class="at">x =</span> Tiempo_Estudio, <span class="at">y =</span> Calificaciones)) <span class="sc">+</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"#0072B2"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Relación entre Tiempo de Estudio y Calificaciones"</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Tiempo de Estudio (horas/semana)"</span>,</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Calificaciones (promedio)"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Cuantificación (los objetos se guardan para usarlos en el texto)</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>covarianza <span class="ot">&lt;-</span> <span class="fu">cov</span>(datos<span class="sc">$</span>Tiempo_Estudio, datos<span class="sc">$</span>Calificaciones)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>correlacion <span class="ot">&lt;-</span> <span class="fu">cor</span>(datos<span class="sc">$</span>Tiempo_Estudio, datos<span class="sc">$</span>Calificaciones)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-exploracion-inicial-full" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-exploracion-inicial-full-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-exploracion-inicial-full-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-exploracion-inicial-full-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.1: Relación entre tiempo de estudio y calificaciones.
</figcaption>
</figure>
</div>
</div>
</div>
<p>El gráfico muestra una clara tendencia lineal positiva. La covarianza toma un valor de 9.82, y el coeficiente de correlación de Pearson es de 0.9. Ambos valores confirman que la asociación lineal es, además de positiva, muy fuerte. Esta evidencia visual y numérica nos da una base sólida para proponer un modelo de regresión lineal.</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled" title="¡Correlación no implica causalidad!">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
¡Correlación no implica causalidad!
</div>
</div>
<div class="callout-body-container callout-body">
<p>El haber encontrado una fuerte correlación positiva entre el tiempo de estudio y las calificaciones (0.9) no nos autoriza a concluir que <em>una cosa causa la otra</em>. La regresión lineal puede demostrar que las variables se mueven juntas y nos permite predecir una a partir de la otra, pero no explica el porqué de la relación.</p>
<p>Podría existir una tercera variable oculta (p.&nbsp;ej., el interés del alumno en la materia) que influya tanto en las horas de estudio como en las calificaciones. Establecer causalidad requiere un diseño experimental riguroso (asignando aleatoriamente a los estudiantes a diferentes tiempos de estudio), no solo un análisis observacional.</p>
</div>
</div>
</section>
</section>
</section>
<section id="formulación-teórica-del-modelo" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="formulación-teórica-del-modelo"><span class="header-section-number">2.2</span> Formulación teórica del modelo</h2>
<p>Una vez que la exploración sugiere una relación lineal, el siguiente paso es formalizarla matemáticamente. Aquí es donde definimos la estructura teórica del modelo y los supuestos bajo los cuales operará.</p>
<section id="el-modelo-poblacional-y-sus-componentes" class="level3" data-number="2.2.1">
<h3 data-number="2.2.1" class="anchored" data-anchor-id="el-modelo-poblacional-y-sus-componentes"><span class="header-section-number">2.2.1</span> El modelo poblacional y sus componentes</h3>
<p>El <strong>modelo poblacional</strong> postula que la relación verdadera entre la variable respuesta <span class="math inline">\(Y\)</span> y la predictora <span class="math inline">\(X\)</span> sigue una línea recta, aunque contaminada por cierta aleatoriedad. Para cualquier individuo <span class="math inline">\(i\)</span> de la población, esta relación se describe como:</p>
<p><span class="math display">\[
Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i
\]</span></p>
<p>En esta ecuación, <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> son los <strong>parámetros poblacionales</strong> (el intercepto y la pendiente verdaderos pero desconocidos), y <span class="math inline">\(\varepsilon_i\)</span> es el <strong>error aleatorio</strong>, un componente fundamental que captura todas las fuentes de variabilidad que el modelo no puede explicar por sí solo. Específicamente, este término incluye:</p>
<ul>
<li><strong>Variables omitidas:</strong> Factores que también afectan a las calificaciones (como la calidad del sueño, la motivación del estudiante o su conocimiento previo) y que no están en el modelo.</li>
<li><strong>Error de medida:</strong> Pequeñas imprecisiones al medir las variables (p.&nbsp;ej., un estudiante podría reportar 20 horas de estudio cuando en realidad fueron 19.5).</li>
<li><strong>Aleatoriedad inherente:</strong> La variabilidad puramente estocástica o impredecible en el comportamiento humano.</li>
</ul>
<p>Como nunca observamos la población entera, nuestro trabajo consiste en usar una muestra para estimar el <strong>modelo muestral</strong>:</p>
<p><span class="math display">\[
\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_i
\]</span></p>
<p>Aquí, los “gorros” (<span class="math inline">\(\hat{\cdot}\)</span>) denotan <strong>estimaciones</strong> calculadas a partir de la muestra. La diferencia entre el valor real y el predicho, <span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>, se conoce como <strong>residuo</strong>.</p>
</section>
<section id="los-supuestos-del-modelo-lineal-clásico-gauss-markov" class="level3" data-number="2.2.2">
<h3 data-number="2.2.2" class="anchored" data-anchor-id="los-supuestos-del-modelo-lineal-clásico-gauss-markov"><span class="header-section-number">2.2.2</span> Los supuestos del modelo lineal clásico (Gauss-Markov)</h3>
<p>Para que el puente entre nuestro modelo muestral y la realidad poblacional sea sólido, debemos asumir que los errores teóricos <span class="math inline">\(\varepsilon_i\)</span> se comportan de una manera predecible y ordenada.</p>
<ol type="1">
<li><strong>Linealidad</strong>: La relación entre <span class="math inline">\(X\)</span> y el valor esperado de <span class="math inline">\(Y\)</span> es, en promedio, una línea recta: <span class="math inline">\(E[Y_i | X_i] = \beta_0 + \beta_1 X_i\)</span>.</li>
<li><strong>Independencia de los errores</strong>: El error de una observación no está correlacionado con el error de ninguna otra: <span class="math inline">\(\text{Cov}(\varepsilon_i, \varepsilon_j) = 0\)</span> para <span class="math inline">\(i \neq j\)</span>.</li>
<li><strong>Homocedasticidad</strong>: La varianza del error es constante (<span class="math inline">\(\sigma^2\)</span>) para todos los valores de <span class="math inline">\(X\)</span>: <span class="math inline">\(Var(\varepsilon_i | X_i) = \sigma^2\)</span>. Esto significa que la dispersión de los datos alrededor de la línea de regresión es la misma a lo largo de todos los valores de la variable predictora. La violación de este supuesto se conoce como <strong>heterocedasticidad</strong>, donde la dispersión de los errores cambia (p.&nbsp;ej., aumenta a medida que <span class="math inline">\(X\)</span> crece).</li>
</ol>
<p>Cuando el objetivo no es sólo estimar la recta, sino inferir con ella, entonces se asume una hipótesis más: la normalidad de la variable respuesta, o lo que es lo mismo, del error aleatorio:</p>
<ol start="4" type="1">
<li><strong>Normalidad de los errores</strong>: Para la inferencia, se asume que los errores siguen una distribución Normal con media cero y varianza <span class="math inline">\(\sigma^2\)</span>: <span class="math inline">\(\varepsilon_i \sim N(0, \sigma^2)\)</span>.</li>
</ol>
<p>Estos supuestos son esenciales para garantizar la validez de las estimaciones y conclusiones derivadas del modelo.</p>
</section>
</section>
<section id="estimación-de-los-parámetros" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="estimación-de-los-parámetros"><span class="header-section-number">2.3</span> Estimación de los parámetros</h2>
<p>Necesitamos un método para encontrar la “mejor” recta de ajuste. El <strong>Método de Mínimos Cuadrados Ordinarios (MCO/OLS)</strong> nos proporciona este criterio.</p>
<section id="el-criterio-de-mínimos-cuadrados" class="level3" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="el-criterio-de-mínimos-cuadrados"><span class="header-section-number">2.3.1</span> El criterio de mínimos cuadrados</h3>
<p>MCO busca la recta que minimice la <strong>Suma de los Cuadrados del Error (SSE)</strong>, es decir, la suma de las distancias verticales al cuadrado entre los puntos observados y la recta de regresión:</p>
<p><span class="math display">\[
\text{SSE}(\beta_0, \beta_1) = \sum_{i=1}^{n} e_i^2 = \sum_{i=1}^{n} (y_i-\hat{y})^2 = \sum_{i=1}^{n} (y_i - (\beta_0 + \beta_1 x_i))^2
\]</span></p>
</section>
<section id="derivación-matemática-de-los-estimadores" class="level3" data-number="2.3.2">
<h3 data-number="2.3.2" class="anchored" data-anchor-id="derivación-matemática-de-los-estimadores"><span class="header-section-number">2.3.2</span> Derivación matemática de los estimadores</h3>
<p>Para encontrar los valores de <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> que minimizan esta función, recurrimos al cálculo. Tratamos la SSE como una función de dos variables y calculamos sus derivadas parciales, igualándolas a cero para encontrar el mínimo.</p>
<p><span class="math display">\[
\frac{\partial \text{SSE}}{\partial \beta_0} = -2 \sum_{i=1}^{n} (y_i - \beta_0 - \beta_1 x_i) = 0
\]</span></p>
<p><span class="math display">\[
\frac{\partial \text{SSE}}{\partial \beta_1} = -2 \sum_{i=1}^{n} x_i (y_i - \beta_0 - \beta_1 x_i) = 0
\]</span></p>
<p>La resolución de este sistema de dos ecuaciones (conocidas como las <strong>ecuaciones normales</strong>) nos proporciona las fórmulas para los estimadores de MCO:</p>
<p><span class="math display">\[
\hat{\beta}_1 = \frac{\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n}(x_i - \bar{x})^2} = \frac{s_{xy}}{s_{xx}}
\]</span> <span class="math display">\[ \hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}
\]</span></p>
<section id="interpretación-práctica-de-los-coeficientes" class="level4" data-number="2.3.2.1">
<h4 data-number="2.3.2.1" class="anchored" data-anchor-id="interpretación-práctica-de-los-coeficientes"><span class="header-section-number">2.3.2.1</span> Interpretación práctica de los coeficientes</h4>
<p>Una vez estimados, los coeficientes tienen una interpretación muy concreta y útil:</p>
<ul>
<li><p><strong>Pendiente (<span class="math inline">\(\hat{\beta}_1\)</span>):</strong> Representa el cambio promedio estimado en la variable respuesta <span class="math inline">\(Y\)</span> por cada <strong>aumento de una unidad</strong> en la variable predictora <span class="math inline">\(X\)</span>. En nuestro ejemplo, sería el número de puntos que se espera que aumente la calificación final por cada hora adicional de estudio semanal.</p></li>
<li><p><strong>Intercepto (<span class="math inline">\(\hat{\beta}_0\)</span>):</strong> Es el valor promedio estimado de la variable respuesta <span class="math inline">\(Y\)</span> cuando la variable predictora <span class="math inline">\(X\)</span> es igual a cero. La interpretación del intercepto solo tiene sentido práctico si <span class="math inline">\(X=0\)</span> es un valor plausible y se encuentra dentro del rango de nuestros datos. De lo contrario (como en nuestro ejemplo, donde nadie estudia 0 horas), a menudo se considera simplemente un ancla matemática para la recta de regresión.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Minimización de SSE">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Minimización de SSE
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La obtención de los estimadores de mínimos cuadrados para la regresión lineal simple se basa en minimizar la suma de los cuadrados de los residuos (<span class="math inline">\(SSE\)</span>). Aquí está el proceso paso a paso:</p>
<p>Para minimizar <span class="math inline">\(SSE\)</span>, derivamos parcialmente con respecto a <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span> y resolvemos el sistema de ecuaciones.</p>
<ol type="1">
<li><strong>Primera derivada con respecto a</strong> <span class="math inline">\(\beta_0\)</span>:</li>
</ol>
<p><span class="math display">\[
    \frac{\partial SSE}{\partial \beta_0} = -2\sum_{i=1}^n
    \left(y_i - (\beta_0 + \beta_1 x_i)\right).
  \]</span></p>
<pre><code>Igualando a cero: </code></pre>
<p><span class="math display">\[
    \sum_{i=1}^n \left(y_i - \beta_0 - \beta_1
    x_i\right) = 0.
  \]</span></p>
<pre><code>Reordenando: </code></pre>
<p><span class="math display">\[
    n\beta_0 + \beta_1 \sum_{i=1}^n x_i = \sum_{i=1}^n y_i. \tag{1}
  \]</span></p>
<ol start="2" type="1">
<li><strong>Primera derivada con respecto a</strong> <span class="math inline">\(\beta_1\)</span>:</li>
</ol>
<p><span class="math display">\[
    \frac{\partial SSE}{\partial \beta_1} = -2\sum_{i=1}^n x_i
    \left(y_i - (\beta_0 + \beta_1 x_i)\right).
    \]</span></p>
<pre><code>Igualando a cero: </code></pre>
<p><span class="math display">\[
    \sum_{i=1}^n x_i \left(y_i - \beta_0 -
    \beta_1 x_i\right) = 0.
   \]</span></p>
<pre><code>Reordenando: </code></pre>
<p><span class="math display">\[
    \beta_0 \sum_{i=1}^n x_i + \beta_1 \sum_{i=1}^n x_i^2 = \sum_{i=1}^n x_i y_i. \tag{2}
   \]</span></p>
<p><strong>Resolución del Sistema de Ecuaciones</strong></p>
<p>El sistema está dado por las ecuaciones (1) y (2):</p>
<ol type="1">
<li><span class="math inline">\(n\beta_0 + \beta_1 \sum_{i=1}^n x_i = \sum_{i=1}^n y_i.\)</span><br>
</li>
<li><span class="math inline">\(\beta_0 \sum_{i=1}^n x_i + \beta_1 \sum_{i=1}^n x_i^2 = \sum_{i=1}^n x_i y_i.\)</span></li>
</ol>
<p>Resolviendo para <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>:</p>
<ol type="1">
<li><p>De la primera ecuación, despejamos <span class="math inline">\(\beta_0\)</span>:<br>
<span class="math display">\[
\beta_0 = \frac{\sum_{i=1}^n y_i - \beta_1 \sum_{i=1}^n x_i}{n}. \tag{3}
\]</span></p></li>
<li><p>Sustituimos <span class="math inline">\(\beta_0\)</span> en la segunda ecuación:<br>
<span class="math display">\[
\frac{\sum_{i=1}^n y_i - \beta_1 \sum_{i=1}^n x_i}{n} \sum_{i=1}^n x_i + \beta_1 \sum_{i=1}^n x_i^2 = \sum_{i=1}^n x_i y_i.
\]</span></p>
<p>Simplificando:<br>
<span class="math display">\[
\beta_1 \left(\sum_{i=1}^n x_i^2 - \frac{(\sum_{i=1}^n x_i)^2}{n}\right) = \sum_{i=1}^n x_i y_i - \frac{\sum_{i=1}^n x_i \sum_{i=1}^n y_i}{n}.
\]</span></p></li>
<li><p>Expresamos <span class="math inline">\(\beta_1\)</span>:<br>
<span class="math display">\[
\beta_1 = \frac{\sum_{i=1}^n x_i y_i - \frac{\sum_{i=1}^n x_i \sum_{i=1}^n y_i}{n}}{\sum_{i=1}^n x_i^2 - \frac{(\sum_{i=1}^n x_i)^2}{n}}.
\]</span> Esta es la fórmula para <span class="math inline">\(\beta_1\)</span>, que puede reescribirse como:<br>
<span class="math display">\[
\beta_1 = \frac{\text{Cov}(x, y)}{\text{Var}(x)},
\]</span> donde <span class="math inline">\(\text{Cov}(x, y)\)</span> y <span class="math inline">\(\text{Var}(x)\)</span> son la covarianza y la varianza muestral de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>.</p></li>
<li><p>Finalmente, sustituimos <span class="math inline">\(\beta_1\)</span> en la ecuación (3) para obtener <span class="math inline">\(\beta_0\)</span>:<br>
<span class="math display">\[
\beta_0 = \bar{y} - \beta_1 \bar{x},
\]</span> donde <span class="math inline">\(\bar{x}\)</span> y <span class="math inline">\(\bar{y}\)</span> son las medias de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>.</p></li>
</ol>
</div>
</div>
</div>
<p>Bajo los supuestos del modelo, el <strong>Teorema de Gauss-Markov</strong> demuestra que estos estimadores son los <strong>Mejores Estimadores Lineales Insesgados (MELI / BLUE)</strong>.</p>
</section>
</section>
</section>
<section id="inferencia-y-bondad-de-ajuste" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="inferencia-y-bondad-de-ajuste"><span class="header-section-number">2.4</span> Inferencia y bondad de ajuste</h2>
<p>Una vez hemos estimado los parámetros del modelo, nuestro trabajo apenas ha comenzado. Ahora debemos pasar de la descripción a la inferencia. Necesitamos un conjunto de herramientas que nos permitan responder a preguntas cruciales: ¿Son nuestros coeficientes estimados, <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span>, meras casualidades de nuestra muestra o reflejan una relación real en la población? ¿Qué tan bueno es nuestro modelo para explicar la variabilidad de la variable respuesta? Esta sección se dedica a responder estas preguntas.</p>
<section id="propiedades-de-los-estimadores-de-mco" class="level3" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="propiedades-de-los-estimadores-de-mco"><span class="header-section-number">2.4.1</span> Propiedades de los estimadores de MCO</h3>
<p>Antes de realizar inferencias, es fundamental entender las propiedades teóricas de los estimadores que hemos calculado.</p>
<ul>
<li><p><strong>Insesgadez</strong>: Los estimadores de MCO son insesgados. Esto significa que si pudiéramos repetir nuestro muestreo muchísimas veces y calcular los estimadores en cada muestra, el promedio de todas nuestras estimaciones de <span class="math inline">\(\hat{\beta}_0\)</span> y <span class="math inline">\(\hat{\beta}_1\)</span> convergería a los verdaderos valores poblacionales <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>. Matemáticamente: <span class="math display">\[
  E[\hat{\beta}_0] = \beta_0 \quad \text{y} \quad E[\hat{\beta}_1] = \beta_1
  \]</span></p></li>
<li><p><strong>Varianza de los estimadores</strong>: Las fórmulas para la varianza de nuestros estimadores cuantifican su precisión. Una varianza pequeña implica que el estimador es más estable a través de diferentes muestras. <span class="math display">\[
  Var(\hat{\beta}_1) = \frac{\sigma^2}{\sum_{i=1}^{n}(x_i - \bar{x})^2} = \frac{\sigma^2}{S_{xx}}
  \]</span> <span class="math display">\[
  Var(\hat{\beta}_0) = \sigma^2 \left[ \frac{1}{n} + \frac{\bar{x}^2}{S_{xx}} \right]
  \]</span> Donde <span class="math inline">\(\sigma^2\)</span> es la varianza (desconocida) del término de error <span class="math inline">\(\varepsilon\)</span>.</p></li>
<li><p><strong>Teorema de Gauss-Markov</strong>: Este es uno de los resultados más importantes de la teoría de la regresión. Establece que, bajo los supuestos de linealidad, independencia y homocedasticidad (no se requiere normalidad), los estimadores de MCO son los <strong>Mejores Estimadores Lineales Insesgados</strong> (MELI, o BLUE en inglés). Esto significa que, de entre toda la clase de estimadores que son lineales e insesgados, los de MCO son los que tienen la menor varianza posible.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled" title="Propiedades adicionales para las predicciones y para los residuos">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Propiedades adicionales para las predicciones y para los residuos
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p>La suma de los residuos es cero: <span class="math display">\[
  \sum_{i=1}^n e_i=\sum_{i=1}^n(y_i-\hat{y_i})=0
  \]</span></p></li>
<li><p>La suma de los valores observados es igual a la suma de los valores ajustados: <span class="math display">\[
  \sum_{i=1}^n y_i=\sum_{i=1}^n \hat{y_i}
  \]</span></p></li>
<li><p>La suma de los residuos ponderados por los regresores es cero: <span class="math display">\[
  \sum_{i=1}^n x_ie_i=0
  \]</span></p></li>
<li><p>La suma de los residuos ponderados por las predicciones es cero: <span class="math display">\[
  \sum_{i=1}^n \hat{y_i}e_i=0
  \]</span></p></li>
<li><p>La recta de regresión contiene el punto <span class="math inline">\((\bar{x},\bar{y})\)</span>:</p></li>
</ul>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Para los datos de calificaciones y tiempo de estudio, estos son los estimadores de los parámetros del modelo de regresión:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Ajustamos el modelo lineal</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>modelo_estudio <span class="ot">&lt;-</span> <span class="fu">lm</span>(Calificaciones <span class="sc">~</span> Tiempo_Estudio, <span class="at">data =</span> datos)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Obtenemos el resumen completo del modelo</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_estudio)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Calificaciones ~ Tiempo_Estudio, data = datos)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.11465 -0.30262 -0.00942  0.29509  1.10533 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     5.00118    0.11977   41.76   &lt;2e-16 ***
Tiempo_Estudio  0.09875    0.00488   20.23   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.4842 on 98 degrees of freedom
Multiple R-squared:  0.8069,    Adjusted R-squared:  0.8049 
F-statistic: 409.5 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="estimación-de-la-varianza-del-error" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="estimación-de-la-varianza-del-error"><span class="header-section-number">2.4.2</span> Estimación de la varianza del error</h3>
<p>Las fórmulas de la varianza de los estimadores dependen de <span class="math inline">\(\sigma^2\)</span>, la varianza del error poblacional, que es desconocida. Por lo tanto, necesitamos estimarla a partir de nuestros datos. Un estimador insesgado de <span class="math inline">\(\sigma^2\)</span> es la <strong>Media Cuadrática del Error (MSE)</strong>:</p>
<p><span class="math display">\[
\hat{\sigma}^2 = \text{MSE} = \frac{\text{SSE}}{n-2} = \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{n-2}
\]</span></p>
<p>Dividimos por <span class="math inline">\(n-2\)</span>, los <strong>grados de libertad del error</strong>, porque hemos “gastado” dos grados de libertad de nuestros datos para estimar los dos parámetros, <span class="math inline">\(\beta_0\)</span> y <span class="math inline">\(\beta_1\)</span>. La raíz cuadrada de la MSE, <span class="math inline">\(\hat{\sigma}\)</span>, se conoce como el <strong>error estándar de los residuos</strong> y es una medida de la dispersión promedio de los puntos alrededor de la recta de regresión.</p>
<section id="el-error-estándar-de-los-residuos-y-el-rmse" class="level4" data-number="2.4.2.1">
<h4 data-number="2.4.2.1" class="anchored" data-anchor-id="el-error-estándar-de-los-residuos-y-el-rmse"><span class="header-section-number">2.4.2.1</span> El error estándar de los residuos y el RMSE</h4>
<p>La raíz cuadrada de la MSE, <span class="math inline">\(\hat{\sigma}\)</span>, se conoce formalmente como el <strong>error estándar de los residuos</strong> (<em>Residual Standard Error</em>). Este valor es nuestra estimación de la desviación estándar del error poblacional, <span class="math inline">\(\sigma\)</span>, y es una medida de la dispersión promedio de los puntos alrededor de la recta de regresión.</p>
<p><span class="math display">\[
\hat{\sigma} = \sqrt{\text{MSE}}
\]</span></p>
<p>En el campo del modelado predictivo y el <em>machine learning</em>, esta misma cantidad se conoce como la <strong>Raíz del Error Cuadrático Medio</strong> o <strong>RMSE</strong> (<em>Root Mean Squared Error</em>). Aunque la fórmula es idéntica, la interpretación del RMSE se centra en la <strong>evaluación del rendimiento predictivo</strong> del modelo. El RMSE nos dice, en promedio, cuál es la magnitud del error de predicción de nuestro modelo, y tiene la ventaja de estar en las <strong>mismas unidades</strong> que la variable respuesta <span class="math inline">\(Y\)</span>. Por ejemplo, si estamos prediciendo precios de viviendas en euros, un RMSE de 5000 significa que nuestras predicciones se desvían, en promedio, unos 5000 € de los precios reales.</p>
</section>
</section>
<section id="análisis-de-la-varianza-anova-para-la-significancia-de-la-regresión" class="level3" data-number="2.4.3">
<h3 data-number="2.4.3" class="anchored" data-anchor-id="análisis-de-la-varianza-anova-para-la-significancia-de-la-regresión"><span class="header-section-number">2.4.3</span> Análisis de la Varianza (ANOVA) para la significancia de la regresión</h3>
<p>Una vez hemos estimado los coeficientes, necesitamos una prueba formal para determinar si el modelo en su conjunto es útil. Es decir, ¿la variable predictora <span class="math inline">\(X\)</span> explica una porción de la variabilidad de la variable respuesta <span class="math inline">\(Y\)</span> que sea estadísticamente significativa, o la relación que observamos podría deberse simplemente al azar? El <strong>Análisis de la Varianza (ANOVA)</strong> nos proporciona la herramienta para responder a esta pregunta a través del <strong>contraste F de significancia global</strong>.</p>
<p>Las hipótesis de este contraste son:</p>
<ul>
<li><span class="math inline">\(H_0: \beta_1 = 0\)</span>: La hipótesis nula postula que no existe una relación lineal entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>. El modelo no tiene poder explicativo y no es mejor que usar simplemente la media, <span class="math inline">\(\bar{y}\)</span>, como predicción para cualquier valor de <span class="math inline">\(x\)</span>.</li>
<li><span class="math inline">\(H_1: \beta_1 \neq 0\)</span>: La hipótesis alternativa sostiene que sí existe una relación lineal significativa.</li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled" title="Repaso">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Repaso
</div>
</div>
<div class="callout-body-container callout-body">
<p>Es conveniente repasar el tema de <em>Análisis de la Varianza</em> estudiado en la asignatura de Inferencia, ya que los conceptos son directamente aplicables aquí.</p>
</div>
</div>
<p>La idea fundamental del ANOVA es comparar la variabilidad que nuestro modelo <em>explica</em> con la variabilidad que <em>no puede explicar</em> (el error residual). Para ello, se descompone la variabilidad total de nuestras observaciones (<span class="math inline">\(y_i\)</span>) en dos partes ortogonales.</p>
<ol type="1">
<li><p>La <strong>Suma Total de Cuadrados (SST)</strong> mide la variabilidad total de los datos alrededor de su media. Es nuestra referencia base de la dispersión total que hay que explicar. <span class="math display">\[
\text{SST} = \sum_{i=1}^{n} (y_i - \bar{y})^2
\]</span></p></li>
<li><p>Esta variabilidad se descompone en:</p>
<ul>
<li><strong>Suma de Cuadrados de la Regresión (SSR)</strong>: Mide la parte de la variabilidad total que es explicada por nuestro modelo. Cuantifica cuánto se desvían las predicciones del modelo (<span class="math inline">\(\hat{y}_i\)</span>) de la media general (<span class="math inline">\(\bar{y}\)</span>). <span class="math display">\[
  \text{SSR} = \sum_{i=1}^{n} (\hat{y}_i - \bar{y})^2
  \]</span></li>
<li><strong>Suma de Cuadrados del Error (SSE)</strong>: Mide la variabilidad residual, es decir, la parte que el modelo no puede capturar. Cuantifica la dispersión de los puntos reales (<span class="math inline">\(y_i\)</span>) alrededor de la recta de regresión (<span class="math inline">\(\hat{y}_i\)</span>). <span class="math display">\[
  \text{SSE} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
  \]</span></li>
</ul></li>
</ol>
<p>La descomposición fundamental de la varianza es, por tanto: <span class="math inline">\(\text{SST} = \text{SSR} + \text{SSE}\)</span>.</p>
<p>Para poder comparar estas sumas de cuadrados de forma justa, las estandarizamos dividiéndolas por sus respectivos <strong>grados de libertad</strong>, obteniendo así las <strong>Medias Cuadráticas</strong> (MS):</p>
<p><span class="math display">\[
\text{MSR} = \frac{\text{SSR}}{1} \quad \quad \quad \text{MSE} = \frac{\text{SSE}}{n-2}
\]</span></p>
<p>Finalmente, el <strong>estadístico F</strong> se construye como el cociente entre la variabilidad explicada por el modelo y la variabilidad no explicada:</p>
<p><span class="math display">\[
F = \frac{\text{MSR}}{\text{MSE}}
\]</span></p>
<p>Intuitivamente, el estadístico F actúa como una <strong>ratio de señal a ruido</strong>. La MSR (la “señal”) representa la variabilidad que nuestro modelo captura sistemáticamente, mientras que la MSE (el “ruido”) representa la variabilidad aleatoria o residual. Un valor de F grande nos dice que la señal es mucho más fuerte que el ruido, lo que apoya la hipótesis de que la relación que hemos modelado es real y no fruto del azar.</p>
<p>Toda esta información se organiza de forma estándar en la <strong>tabla ANOVA</strong>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Fuente</th>
<th><span class="math inline">\(df\)</span></th>
<th><span class="math inline">\(SS\)</span></th>
<th><span class="math inline">\(MS = SS/df\)</span></th>
<th>Estadístico <span class="math inline">\(F\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regresión</td>
<td>1</td>
<td><span class="math inline">\(SSR\)</span></td>
<td><span class="math inline">\(MSR\)</span></td>
<td><span class="math inline">\(F = MSR/MSE\)</span></td>
</tr>
<tr class="even">
<td>Error</td>
<td><span class="math inline">\(n-2\)</span></td>
<td><span class="math inline">\(SSE\)</span></td>
<td><span class="math inline">\(MSE\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td><span class="math inline">\(n-1\)</span></td>
<td><span class="math inline">\(SST\)</span></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Bajo la hipótesis nula (<span class="math inline">\(H_0: \beta_1 = 0\)</span>), el estadístico <span class="math inline">\(F\)</span> sigue una distribución <span class="math inline">\(F\)</span> con 1 y <span class="math inline">\(n-2\)</span> grados de libertad. Si el p-valor asociado a nuestro estadístico F es suficientemente pequeño (<span class="math inline">\(p &lt; \alpha\)</span>), rechazamos <span class="math inline">\(H_0\)</span> y concluimos que nuestro modelo tiene un poder explicativo estadísticamente significativo.</p>
</section>
<section id="bondad-del-ajuste-coeficiente-de-determinación" class="level3" data-number="2.4.4">
<h3 data-number="2.4.4" class="anchored" data-anchor-id="bondad-del-ajuste-coeficiente-de-determinación"><span class="header-section-number">2.4.4</span> Bondad del ajuste: coeficiente de determinación</h3>
<p>El coeficiente de determinación (<span class="math inline">\(R^2\)</span>) es una medida clave que cuantifica qué proporción de la variabilidad total observada en la muestra (<span class="math inline">\(y_i\)</span>) es explicada por la relación lineal con <span class="math inline">\(X\)</span> a través del modelo. Su fórmula se deriva de la descomposición de la varianza:</p>
<p><span class="math display">\[
R^2 = \frac{\text{SSR}}{\text{SST}} = 1 - \frac{\text{SSE}}{\text{SST}}
\]</span></p>
<p>Donde las sumas de cuadrados se calculan a partir de los datos muestrales:</p>
<ul>
<li><span class="math inline">\(\text{SST} = \sum_{i=1}^n (y_i - \bar{y})^2\)</span>: Suma Total de Cuadrados, mide la variabilidad total de las observaciones.</li>
<li><span class="math inline">\(\text{SSR} = \sum_{i=1}^n (\hat{y}_i - \bar{y})^2\)</span>: Suma de Cuadrados de la Regresión, mide la variabilidad explicada por el modelo.</li>
<li><span class="math inline">\(\text{SSE} = \sum_{i=1}^n (y_i - \hat{y}_i)^2\)</span>: Suma de Cuadrados del Error, mide la variabilidad no explicada (residual).</li>
</ul>
<p>Un <span class="math inline">\(R^2\)</span> cercano a 1 indica que el modelo ajusta bien los datos, mientras que un <span class="math inline">\(R^2\)</span> cercano a 0 indica un ajuste pobre.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Relación entre R² y el coeficiente de correlación">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Relación entre R² y el coeficiente de correlación
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>En el caso específico del modelo de regresión lineal simple, existe una relación directa y simple: el coeficiente de determinación <span class="math inline">\(R^2\)</span> es literalmente el cuadrado del coeficiente de correlación de Pearson (<span class="math inline">\(r\)</span>) entre <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span>.</p>
<p><span class="math display">\[ R^2 = (r_{xy})^2 \]</span></p>
<p>Esto refuerza la idea de que ambos miden la fuerza de la asociación <em>lineal</em>, aunque <span class="math inline">\(R^2\)</span> lo hace desde la perspectiva de la varianza explicada por el modelo.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-caution callout-titled" title="Interpretación de R²">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Interpretación de R²
</div>
</div>
<div class="callout-body-container callout-body">
<p>El coeficiente de determinación, <span class="math inline">\(R^2\)</span>, es una métrica muy popular, pero su interpretación requiere cautela. Un valor alto no garantiza un buen modelo, y un valor bajo no siempre implica un modelo inútil. Es fundamental tener en cuenta las siguientes observaciones:</p>
<ul>
<li><p><strong><span class="math inline">\(R^2\)</span> no mide la linealidad de la relación.</strong> Un modelo puede tener un <span class="math inline">\(R^2\)</span> muy alto incluso si la relación subyacente entre las variables <span class="math inline">\(X\)</span> e <span class="math inline">\(Y\)</span> no es lineal. Por ello, un <span class="math inline">\(R^2\)</span> elevado nunca debe sustituir a un análisis gráfico de los residuos para verificar el supuesto de linealidad.</p></li>
<li><p><strong><span class="math inline">\(R^2\)</span> es sensible al rango de la variable predictora <span class="math inline">\(X\)</span>.</strong> Si el modelo de regresión es adecuado, la magnitud de <span class="math inline">\(R^2\)</span> aumentará si aumenta la dispersión de las observaciones <span class="math inline">\(x_i\)</span> (es decir, si <span class="math inline">\(S_{xx}\)</span> crece). Esto se debe a que un mayor rango en <span class="math inline">\(X\)</span> tiende a aumentar la Suma Total de Cuadrados (SST), lo que puede inflar el valor de <span class="math inline">\(R^2\)</span> sin que la precisión del modelo (medida por la MSE) haya mejorado.</p></li>
<li><p><strong>Un rango restringido en <span class="math inline">\(X\)</span> puede producir un <span class="math inline">\(R^2\)</span> artificialmente bajo.</strong> Como consecuencia del punto anterior, si los datos se han recogido en un rango muy estrecho de la variable <span class="math inline">\(X\)</span>, el <span class="math inline">\(R^2\)</span> puede ser muy pequeño, aunque exista una relación fuerte y significativa entre las variables. Esto podría llevar a la conclusión errónea de que el predictor no es útil.</p></li>
</ul>
</div>
</div>
</section>
<section id="inferencia-sobre-los-coeficientes" class="level3" data-number="2.4.5">
<h3 data-number="2.4.5" class="anchored" data-anchor-id="inferencia-sobre-los-coeficientes"><span class="header-section-number">2.4.5</span> Inferencia sobre los coeficientes</h3>
<p>Además de la prueba F global, podemos realizar inferencias sobre cada parámetro individualmente. Para ello, necesitamos el supuesto de normalidad de los errores.</p>
<section id="distribución-de-los-estimadores" class="level4" data-number="2.4.5.1">
<h4 data-number="2.4.5.1" class="anchored" data-anchor-id="distribución-de-los-estimadores"><span class="header-section-number">2.4.5.1</span> Distribución de los estimadores</h4>
<p>Bajo el supuesto de normalidad, se puede demostrar que los estimadores también siguen una distribución Normal: <span class="math display">\[
\hat{\beta}_1 \sim N\left(\beta_1, \frac{\sigma^2}{S_{xx}}\right) \quad \quad \quad \hat{\beta}_0 \sim N\left(\beta_0, \sigma^2 \left[ \frac{1}{n} + \frac{\bar{x}^2}{S_{xx}} \right]\right)
\]</span></p>
<p>Al estandarizar y reemplazar la desconocida <span class="math inline">\(\sigma^2\)</span> por su estimador <span class="math inline">\(\hat{\sigma}^2 = \text{MSE}\)</span>, obtenemos un estadístico que sigue una distribución t-Student con <span class="math inline">\(n-2\)</span> grados de libertad: <span class="math display">\[
t = \frac{\hat{\beta}_1 - \beta_1}{\text{SE}(\hat{\beta}_1)} \sim t_{n-2}
\]</span> donde <span class="math inline">\(\text{SE}(\hat{\beta}_1) = \sqrt{\frac{\text{MSE}}{S_{xx}}}\)</span> es el <strong>error estándar</strong> del estimador <span class="math inline">\(\hat{\beta}_1\)</span>.</p>
</section>
<section id="contraste-de-hipótesis-para-la-pendiente" class="level4" data-number="2.4.5.2">
<h4 data-number="2.4.5.2" class="anchored" data-anchor-id="contraste-de-hipótesis-para-la-pendiente"><span class="header-section-number">2.4.5.2</span> Contraste de hipótesis para la pendiente</h4>
<p>El contraste más común es el de la significancia de la pendiente: * <span class="math inline">\(H_0: \beta_1 = 0\)</span> * <span class="math inline">\(H_1: \beta_1 \neq 0\)</span></p>
<p>Bajo <span class="math inline">\(H_0\)</span>, el estadístico de contraste es: <span class="math display">\[
t_0 = \frac{\hat{\beta}_1}{\text{SE}(\hat{\beta}_1)}
\]</span> Rechazamos <span class="math inline">\(H_0\)</span> si <span class="math inline">\(|t_0| &gt; t_{\alpha/2, n-2}\)</span> o, equivalentemente, si el p-valor asociado es menor que <span class="math inline">\(\alpha\)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled" title="Relación entre el contraste F y el contraste t">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Relación entre el contraste F y el contraste t
</div>
</div>
<div class="callout-body-container callout-body">
<p>En el contexto de la <strong>regresión lineal simple</strong> (y solo en este caso), el contraste F para la significancia global del modelo es matemáticamente equivalente al contraste t para la significancia del coeficiente <span class="math inline">\(\beta_1\)</span>. Se puede demostrar que <span class="math inline">\(F = t^2\)</span>, y el p-valor de ambos contrastes será idéntico.</p>
</div>
</div>
</section>
<section id="intervalo-de-confianza-para-la-pendiente" class="level4" data-number="2.4.5.3">
<h4 data-number="2.4.5.3" class="anchored" data-anchor-id="intervalo-de-confianza-para-la-pendiente"><span class="header-section-number">2.4.5.3</span> Intervalo de confianza para la pendiente</h4>
<p>A partir de la distribución t, podemos construir un intervalo de confianza al <span class="math inline">\(100(1-\alpha)\%\)</span> para el verdadero valor de la pendiente <span class="math inline">\(\beta_1\)</span>: <span class="math display">\[
\hat{\beta}_1 \pm t_{\alpha/2, n-2} \cdot \text{SE}(\hat{\beta}_1)
\]</span> Este intervalo nos da un rango de valores plausibles para el efecto de <span class="math inline">\(X\)</span> sobre <span class="math inline">\(Y\)</span>. Si el intervalo no contiene el cero, es equivalente a rechazar la hipótesis nula <span class="math inline">\(H_0: \beta_1 = 0\)</span>.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Para recordar">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Para recordar
</div>
</div>
<div class="callout-body-container callout-body">
<p>En los programas estadísticos se suele proporcionar el p-valor del contraste. Puedes repasar el significado de p-valor proporcionado en la asignatura de Inferencia.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo: Interpretación del `summary`">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo: Interpretación del <code>summary</code>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>La función <code>summary()</code> en R nos proporciona toda esta información.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(modelo_estudio)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = Calificaciones ~ Tiempo_Estudio, data = datos)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.11465 -0.30262 -0.00942  0.29509  1.10533 

Coefficients:
               Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)     5.00118    0.11977   41.76   &lt;2e-16 ***
Tiempo_Estudio  0.09875    0.00488   20.23   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.4842 on 98 degrees of freedom
Multiple R-squared:  0.8069,    Adjusted R-squared:  0.8049 
F-statistic: 409.5 on 1 and 98 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p><strong>Interpretación:</strong></p>
<ul>
<li><strong>Coefficients</strong>: El p-valor para <code>Tiempo_Estudio</code> (&lt;0.001) es muy pequeño, por lo que rechazamos <span class="math inline">\(H_0\)</span> y concluimos que la variable es un predictor significativo.</li>
<li><strong>R-squared</strong>: El valor de <span class="math inline">\(R^2\)</span> (0.81) nos indica que el 81% de la variabilidad en las calificaciones es explicada por el tiempo de estudio.</li>
<li><strong>F-statistic</strong>: El p-valor del estadístico F (98) confirma que el modelo en su conjunto es estadísticamente significativo.</li>
</ul>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="predicción-de-nuevas-observaciones" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="predicción-de-nuevas-observaciones"><span class="header-section-number">2.5</span> Predicción de nuevas observaciones</h2>
<p>Una vez que hemos ajustado y validado un modelo de regresión, uno de sus propósitos más importantes es utilizarlo para hacer predicciones. Sin embargo, es fundamental distinguir entre dos tipos de predicción:</p>
<ol type="1">
<li><strong>Estimar la respuesta media</strong> para un valor dado de <span class="math inline">\(X\)</span>. Por ejemplo: “¿Cuál es la calificación <em>promedio</em> que esperamos para todos los estudiantes que estudian 25 horas semanales?”.</li>
<li><strong>Predecir una respuesta individual</strong> para un valor dado de <span class="math inline">\(X\)</span>. Por ejemplo: “Si un estudiante <em>concreto</em> estudia 25 horas semanales, ¿entre qué valores esperamos que se encuentre su calificación?”.</li>
</ol>
<p>Estos dos objetivos, aunque parecidos, responden a preguntas distintas y manejan diferentes fuentes de incertidumbre, lo que da lugar a dos tipos de intervalos.</p>
<section id="intervalo-de-confianza-para-la-respuesta-media" class="level3" data-number="2.5.1">
<h3 data-number="2.5.1" class="anchored" data-anchor-id="intervalo-de-confianza-para-la-respuesta-media"><span class="header-section-number">2.5.1</span> Intervalo de confianza para la respuesta media</h3>
<p>Este intervalo estima el valor esperado de <span class="math inline">\(Y\)</span> para un valor concreto del regresor, <span class="math inline">\(x_0\)</span>. Su objetivo es acotar dónde se encuentra la <strong>línea de regresión poblacional verdadera</strong> para ese punto <span class="math inline">\(x_0\)</span>. La estimación puntual es <span class="math inline">\(\hat{y}_0 = \hat{\beta}_0 + \hat{\beta}_1 x_0\)</span>.</p>
<p>El intervalo de confianza al <span class="math inline">\(100(1-\alpha)\%\)</span> para la respuesta media <span class="math inline">\(E[Y|X=x_0]\)</span> viene dado por:</p>
<p><span class="math display">\[
\hat{y}_0 \pm t_{\alpha/2, n-2} \cdot \sqrt{\text{MSE} \left( \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}} \right)}
\]</span></p>
<p>La anchura de este intervalo depende de dos fuentes de error: la incertidumbre en la estimación de la recta y la distancia del punto <span class="math inline">\(x_0\)</span> a la media <span class="math inline">\(\bar{x}\)</span>. El intervalo es más estrecho cerca del centro de los datos y más ancho en los extremos.</p>
</section>
<section id="intervalo-de-predicción-para-una-respuesta-individual" class="level3" data-number="2.5.2">
<h3 data-number="2.5.2" class="anchored" data-anchor-id="intervalo-de-predicción-para-una-respuesta-individual"><span class="header-section-number">2.5.2</span> Intervalo de predicción para una respuesta individual</h3>
<p>Este intervalo es el que debemos usar cuando queremos predecir el valor para <strong>una única observación futura</strong>, no para la media. Como indicas, este intervalo debe tener en cuenta dos fuentes de variabilidad:</p>
<ol type="1">
<li>La incertidumbre sobre la localización de la verdadera recta de regresión (la misma que en el intervalo de confianza).</li>
<li>La variabilidad inherente de una observación individual alrededor de la recta de regresión (el error aleatorio <span class="math inline">\(\varepsilon_i\)</span>, cuya varianza estimamos con la MSE).</li>
</ol>
<p>Por esta razón, el intervalo de predicción <strong>siempre será más ancho</strong> que el intervalo de confianza para la respuesta media. El intervalo de predicción al <span class="math inline">\(100(1-\alpha)\%\)</span> para una observación futura <span class="math inline">\(y_0\)</span> en el punto <span class="math inline">\(x_0\)</span> es:</p>
<p><span class="math display">\[
\hat{y}_0 \pm t_{\alpha/2, n-2} \cdot \sqrt{\text{MSE} \left( 1 + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}} \right)}
\]</span></p>
<p>La única diferencia matemática es el <strong>“+1”</strong> dentro de la raíz cuadrada, que representa la varianza <span class="math inline">\(\sigma^2\)</span> del error de una sola observación.</p>
<section id="predicción-para-la-media-de-m-observaciones-futuras" class="level4" data-number="2.5.2.1">
<h4 data-number="2.5.2.1" class="anchored" data-anchor-id="predicción-para-la-media-de-m-observaciones-futuras"><span class="header-section-number">2.5.2.1</span> Predicción para la media de <em>m</em> observaciones futuras</h4>
<p>Si se desea un intervalo de predicción para la media de <em>m</em> futuras observaciones en un valor <span class="math inline">\(x_0\)</span>, la fórmula se modifica ligeramente. Este intervalo será más estrecho que el de una sola observación pero más ancho que el de la respuesta media:</p>
<p><span class="math display">\[
\hat{y}_0 \pm t_{\alpha/2, n-2} \cdot \sqrt{\text{MSE} \left( \frac{1}{m} + \frac{1}{n} + \frac{(x_0 - \bar{x})^2}{S_{xx}} \right)}
\]</span></p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo práctico: Predicción de calificaciones">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo práctico: Predicción de calificaciones
</div>
</div>
<div class="callout-body-container callout-body">
<p>Vamos a calcular y visualizar los intervalos para nuestro modelo de estudio. Usaremos la función <code>predict()</code> de R, que calcula estos intervalos de forma automática.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Crear una secuencia de nuevos valores de X para predecir</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>nuevos_datos <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">Tiempo_Estudio =</span> <span class="fu">seq</span>(<span class="fu">min</span>(datos<span class="sc">$</span>Tiempo_Estudio), <span class="fu">max</span>(datos<span class="sc">$</span>Tiempo_Estudio), <span class="at">length.out =</span> <span class="dv">100</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Calcular el intervalo de confianza para la RESPUESTA MEDIA</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>conf_interval <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  modelo_estudio, </span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">newdata =</span> nuevos_datos, </span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">"confidence"</span>, </span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">level =</span> <span class="fl">0.95</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Calcular el intervalo de predicción para una OBSERVACIÓN INDIVIDUAL</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>pred_interval <span class="ot">&lt;-</span> <span class="fu">predict</span>(</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  modelo_estudio, </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">newdata =</span> nuevos_datos, </span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">"prediction"</span>, </span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">level =</span> <span class="fl">0.95</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Unir todo para graficar con ggplot2</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> <span class="fu">cbind</span>(nuevos_datos, <span class="fu">as.data.frame</span>(conf_interval), <span class="at">pred_pred =</span> <span class="fu">as.data.frame</span>(pred_interval))</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(plot_data) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"Tiempo_Estudio"</span>, <span class="st">"fit_conf"</span>, <span class="st">"lwr_conf"</span>, <span class="st">"upr_conf"</span>, <span class="st">"fit_pred"</span>, <span class="st">"lwr_pred"</span>, <span class="st">"upr_pred"</span>)</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. Visualización</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Capa 1: Puntos originales del dataframe 'datos'</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> datos, <span class="fu">aes</span>(<span class="at">x =</span> Tiempo_Estudio, <span class="at">y =</span> Calificaciones), <span class="at">color =</span> <span class="st">"#0072B2"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Capa 2: Línea de regresión del dataframe 'plot_data'</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> plot_data, <span class="fu">aes</span>(<span class="at">x =</span> Tiempo_Estudio, <span class="at">y =</span> fit_conf), <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Capa 3: Banda de predicción (roja) del dataframe 'plot_data'</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> plot_data, <span class="fu">aes</span>(<span class="at">x =</span> Tiempo_Estudio, <span class="at">ymin =</span> lwr_pred, <span class="at">ymax =</span> upr_pred), <span class="at">fill =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Capa 4: Banda de confianza (azul) del dataframe 'plot_data'</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data =</span> plot_data, <span class="fu">aes</span>(<span class="at">x =</span> Tiempo_Estudio, <span class="at">ymin =</span> lwr_conf, <span class="at">ymax =</span> upr_conf), <span class="at">fill =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Etiquetas y tema</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Intervalos de Confianza y Predicción"</span>,</span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Tiempo de Estudio (horas/semana)"</span>,</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Calificaciones (promedio)"</span>,</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"La banda azul (más estrecha) es el IC del 95% para la media.</span><span class="sc">\n</span><span class="st">La banda roja (más ancha) es el IP del 95% para una nueva observación."</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_classic</span>(<span class="at">base_size =</span> <span class="dv">14</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-prediccion" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-prediccion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-prediccion-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-prediccion-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.2: Comparación visual del intervalo de confianza (azul, más estrecho) y el intervalo de predicción (rojo, más ancho).
</figcaption>
</figure>
</div>
</div>
</div>
<p>El gráfico muestra claramente que la incertidumbre al predecir una calificación individual es mucho mayor que la incertidumbre al estimar la calificación promedio. Ambas bandas se ensanchan al alejarse del centro de los datos.</p>
<p>Si quisiéramos una predicción para un estudiante que estudia 25 horas:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>dato_nuevo <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Tiempo_Estudio =</span> <span class="dv">25</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardamos la predicción para la media en un objeto</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>pred_media <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_estudio, <span class="at">newdata =</span> dato_nuevo, <span class="at">interval =</span> <span class="st">"confidence"</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardamos la predicción para un individuo en un objeto</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>pred_indiv <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelo_estudio, <span class="at">newdata =</span> dato_nuevo, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Interpretación:</strong></p>
<ul>
<li>Con un 95% de confianza, la calificación <strong>promedio</strong> de los estudiantes que estudian 25 horas está entre <strong>7.37</strong> y <strong>7.57</strong>.</li>
<li>Con un 95% de confianza, la calificación de <strong>un estudiante concreto</strong> que estudia 25 horas estará entre <strong>6.5</strong> y <strong>8.44</strong>.</li>
</ul>
</div>
</div>
</section>
</section>
</section>
<section id="diagnóstico-del-modelo" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="diagnóstico-del-modelo"><span class="header-section-number">2.6</span> Diagnóstico del Modelo</h2>
<p>Una vez que hemos ajustado un modelo y evaluado su significancia, el trabajo no ha terminado. Un paso crucial, a menudo subestimado, es el <strong>diagnóstico del modelo</strong>. Este proceso consiste en verificar si se cumplen los supuestos del modelo de regresión lineal clásico. La fiabilidad de nuestras inferencias (los p-valores de los contrastes t y F, y los intervalos de confianza) depende directamente de la validez de estos supuestos.</p>
<p>El diagnóstico se realiza principalmente a través del <strong>análisis de los residuos</strong> del modelo (<span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>). Los residuos son nuestra mejor aproximación empírica de los errores teóricos no observables (<span class="math inline">\(\varepsilon_i\)</span>). A continuación, se detalla cómo verificar cada uno de los supuestos clave.</p>
<section id="linealidad" class="level3" data-number="2.6.1">
<h3 data-number="2.6.1" class="anchored" data-anchor-id="linealidad"><span class="header-section-number">2.6.1</span> Linealidad</h3>
<p>Este supuesto establece que la relación entre la variable predictora <span class="math inline">\(X\)</span> y el valor esperado de la variable respuesta <span class="math inline">\(Y\)</span> es, en promedio, una línea recta: <span class="math inline">\(E[Y | X] = \beta_0 + \beta_1 X\)</span>.</p>
<p>La herramienta fundamental para diagnosticar la linealidad es el gráfico de <strong>residuos</strong> (<span class="math inline">\(e_i\)</span>) frente a los <strong>valores ajustados</strong> por el modelo (<span class="math inline">\(\hat{y}_i\)</span>). La lógica de este gráfico es sencilla pero potente: si el modelo lineal es adecuado, los errores que comete (los residuos) deberían ser completamente aleatorios, sin guardar relación alguna con la magnitud de las predicciones. En esencia, buscamos confirmar que no queda ninguna información sistemática en los errores que el modelo no haya capturado.</p>
<p><strong>En un escenario ideal</strong>, este gráfico debería parecer una nube de puntos distribuida horizontalmente y sin estructura aparente, centrada en la línea del cero. Esto nos indica que los errores son, en promedio, nulos para todos los niveles de predicción, cumpliendo así el supuesto de linealidad. La línea roja que R superpone en este gráfico, que suaviza la tendencia de los puntos, debería ser prácticamente plana y pegada al cero, confirmando la ausencia de patrones.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo de un Modelo Válido (Nuestro Caso)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo de un Modelo Válido (Nuestro Caso)
</div>
</div>
<div class="callout-body-container callout-body">
<p>Para nuestro <code>modelo_estudio</code>, podemos generar específicamente el primer gráfico de diagnóstico, que es el de Residuos vs.&nbsp;Valores Ajustados.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usamos which = 1 para seleccionar solo el primer gráfico de diagnóstico</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_estudio, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-linealidad-ok" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-linealidad-ok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-linealidad-ok-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-linealidad-ok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.3: Gráfico de Residuos vs.&nbsp;Valores Ajustados para el modelo de estudio. No se observan patrones.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Como se puede observar, los puntos se distribuyen de forma aleatoria alrededor de la línea horizontal en cero. La línea roja, que suaviza la tendencia de los residuos, es prácticamente plana. Esto es un claro indicativo de que el supuesto de linealidad se cumple en nuestro modelo.</p>
</div>
</div>
<p>Por el contrario, la aparición de un <strong>patrón sistemático</strong> en los residuos es la señal de alarma de que algo anda mal. En lo que respecta al supuesto de <strong>linealidad</strong>, la evidencia más clara de una violación es una <strong>tendencia curvilínea</strong> (como una “U” o una parábola). Este patrón nos dice que el modelo es estructuralmente incapaz de capturar la forma de los datos y, por lo tanto, comete errores predecibles. Por ejemplo, puede subestimar la respuesta en los extremos (generando residuos positivos) y sobreestimarla en el centro (residuos negativos), lo que invalida el modelo lineal.</p>
<div class="callout callout-style-default callout-tip callout-titled" title="Contraejemplo: Violación del Supuesto de Linealidad">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Contraejemplo: Violación del Supuesto de Linealidad
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ahora, vamos a simular a propósito unos datos que siguen una relación cuadrática (curva) y ajustaremos incorrectamente un modelo lineal para ver cómo se manifiesta el problema en el gráfico de diagnóstico.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Simulación de datos no lineales</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>) <span class="co"># Nueva semilla para este ejemplo</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>x_no_lineal <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="co"># La relación verdadera es cuadrática (y = 10 - (x-5)^2) más un error</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>y_no_lineal <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="sc">-</span> (x_no_lineal <span class="sc">-</span> <span class="dv">5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="dv">0</span>, <span class="dv">4</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>datos_no_lineal <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x_no_lineal, <span class="at">y =</span> y_no_lineal)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Ajuste de un modelo lineal (incorrecto)</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>modelo_no_lineal <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> datos_no_lineal)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Gráfico de Residuos vs. Valores Ajustados</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_no_lineal, <span class="at">which =</span> <span class="dv">1</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-linealidad-mal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-linealidad-mal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-linealidad-mal-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-linealidad-mal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.4: Patrón curvo evidente en los residuos, violando el supuesto de linealidad.
</figcaption>
</figure>
</div>
</div>
</div>
<p>El gráfico de diagnóstico es inequívoco. A diferencia del ejemplo anterior, donde los puntos formaban una nube aleatoria, aquí los residuos dibujan un <strong>patrón parabólico</strong> perfecto (una “U” invertida). La línea roja de tendencia, en lugar de ser plana, sigue fielmente esta curva.</p>
</div>
</div>
</section>
<section id="homocedasticidad" class="level3" data-number="2.6.2">
<h3 data-number="2.6.2" class="anchored" data-anchor-id="homocedasticidad"><span class="header-section-number">2.6.2</span> Homocedasticidad</h3>
<p>El supuesto de homocedasticidad establece que la varianza de los errores del modelo debe ser constante para todos los niveles de la variable predictora. Es decir, la dispersión de los datos alrededor de la línea de regresión es la misma en todo su recorrido (<span class="math inline">\(Var(\varepsilon_i | X_i) = \sigma^2\)</span>). La violación de este supuesto se conoce como <strong>heteroscedasticidad</strong>, y es un problema común en el modelado.</p>
<p>¿Por qué es tan importante? Si un modelo es heteroscedástico, los errores estándar de los coeficientes (<span class="math inline">\(\beta_0, \beta_1\)</span>) estarán calculados de forma incorrecta. Como consecuencia, los intervalos de confianza y los contrastes de hipótesis (p-valores) no serán fiables, pudiendo llevarnos a conclusiones erróneas sobre la significancia de nuestras variables.</p>
<div class="callout callout-style-default callout-note callout-titled" title="¿Qué son los Residuos Estandarizados y Estudentizados?">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
¿Qué son los Residuos Estandarizados y Estudentizados?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Antes de analizar los gráficos, es útil definir los <strong>residuos estandarizados</strong>. Un residuo simple (<span class="math inline">\(e_i = y_i - \hat{y}_i\)</span>) nos dice cuán lejos está una observación de la línea de regresión. Sin embargo, no todos los residuos son directamente comparables, ya que su varianza puede depender de los valores de <span class="math inline">\(X\)</span> (especialmente de su apalancamiento o <em>leverage</em>).</p>
<p>Para solucionar esto, se estandarizan los residuos, dividiéndolos por una estimación de su desviación estándar. Esto los pone a todos en una escala común (similar a una puntuación Z), haciendo más fácil la identificación de patrones y valores atípicos. R, en sus gráficos de diagnóstico, utiliza una versión aún más refinada llamada <strong>residuos estudentizados</strong>, que es más precisa para detectar outliers. A efectos prácticos, la interpretación es la misma.</p>
</div>
</div>
<p>La heteroscedasticidad se detecta principalmente buscando patrones en la dispersión de los residuos.</p>
<ul>
<li><p><strong>Gráfico de Residuos vs.&nbsp;Valores Ajustados:</strong> Como en la prueba de linealidad, este gráfico es nuestra primera herramienta. Aquí no buscamos patrones en la media de los residuos (que debe ser cero), sino en su <strong>dispersión</strong>. La señal de alarma inequívoca de heteroscedasticidad es una <strong>forma de embudo o megáfono</strong>, donde la dispersión de los residuos aumenta o disminuye a medida que cambian los valores ajustados.</p></li>
<li><p><strong>Gráfico Scale-Location:</strong> Este gráfico está diseñado específicamente para detectar heteroscedasticidad. Muestra la raíz cuadrada de los residuos estandarizados en el eje Y (<code>sqrt(|Standardized residuals|)</code>) frente a los valores ajustados en el eje X. Al usar la raíz cuadrada, se suaviza la distribución de los residuos, haciendo los patrones de varianza más fáciles de ver. Si la varianza es constante (homocedasticidad), deberíamos ver una nube de puntos aleatoria con una línea de tendencia roja aproximadamente plana. Una pendiente en esta línea roja indica que la varianza cambia con el nivel de la respuesta.</p></li>
<li><p><strong>Prueba de Breusch-Pagan:</strong> Es el contraste de hipótesis formal. Su lógica es ingeniosa: realiza una regresión auxiliar donde intenta predecir los residuos al cuadrado a partir de las variables predictoras originales. Si las variables predictoras ayudan a explicar la magnitud de los residuos al cuadrado, significa que la varianza del error depende de los predictores, y por tanto, hay heteroscedasticidad.</p>
<ul>
<li><strong>Hipótesis Nula (<span class="math inline">\(H_0\)</span>):</strong> El modelo es homocedástico.</li>
<li><strong>Decisión:</strong> Un p-valor pequeño (p.&nbsp;ej., &lt; 0.05) es evidencia en contra de la homocedasticidad.</li>
</ul></li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="Ejemplo de un Modelo Válido (Nuestro Caso)">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Ejemplo de un Modelo Válido (Nuestro Caso)
</div>
</div>
<div class="callout-body-container callout-body">
<p>Analicemos nuestro <code>modelo_estudio</code>. Nos centraremos en el gráfico <code>Scale-Location</code> (<code>which = 3</code>) y en la prueba de Breusch-Pagan.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Usamos which = 3 para seleccionar el gráfico Scale-Location</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_estudio, <span class="at">which =</span> <span class="dv">3</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Prueba de Breusch-Pagan</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>Loading required package: zoo</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>
Attaching package: 'zoo'</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>The following objects are masked from 'package:base':

    as.Date, as.Date.numeric</code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">bptest</span>(modelo_estudio)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    studentized Breusch-Pagan test

data:  modelo_estudio
BP = 0.019638, df = 1, p-value = 0.8886</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-homocedasticidad-ok" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-homocedasticidad-ok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-homocedasticidad-ok-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-homocedasticidad-ok-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.5: Gráfico Scale-Location para el modelo de estudio. La línea de tendencia es casi plana.
</figcaption>
</figure>
</div>
</div>
</div>
<p>El diagnóstico es positivo. En el gráfico <code>Scale-Location</code>, la línea roja es casi horizontal, lo que indica que la varianza de los residuos es estable a lo largo de los valores ajustados. Esto se confirma con la prueba de Breusch-Pagan, que arroja un <strong>p-valor alto</strong>, por lo que no tenemos evidencia para rechazar la hipótesis nula de homocedasticidad. <strong>Nuestro modelo cumple el supuesto</strong>.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled" title="Contraejemplo: Violación del Supuesto de Homocedasticidad">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Contraejemplo: Violación del Supuesto de Homocedasticidad
</div>
</div>
<div class="callout-body-container callout-body">
<p>Ahora, simularemos datos donde el error aumenta a medida que <code>x</code> crece, un caso clásico de heteroscedasticidad.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Esta línea le dice a R que prepare una rejilla de 1 fila y 2 columnas para los gráficos</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)) </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Simulación de datos (la misma que antes)</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>x_hetero <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">100</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>y_hetero <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="sc">+</span> <span class="dv">2</span> <span class="sc">*</span> x_hetero <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="fl">0.4</span> <span class="sc">*</span> x_hetero)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>datos_hetero <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x_hetero, <span class="at">y =</span> y_hetero)</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>modelo_hetero <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> datos_hetero)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Gráficos de diagnóstico</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># El primer plot irá a la izquierda</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_hetero, <span class="at">which =</span> <span class="dv">1</span>) </span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a><span class="co"># El segundo plot irá a la derecha</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_hetero, <span class="at">which =</span> <span class="dv">3</span>)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Prueba de Breusch-Pagan</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a><span class="co"># La prueba no genera un gráfico, por lo que no afecta al layout</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>test_values <span class="ot">&lt;-</span> <span class="fu">bptest</span>(modelo_hetero)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-homocedasticidad-mal" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-homocedasticidad-mal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-homocedasticidad-mal-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-homocedasticidad-mal-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.6: Diagnóstico de heteroscedasticidad. Izquierda: Gráfico de Residuos vs.&nbsp;Ajustados (patrón de embudo). Derecha: Gráfico Scale-Location (tendencia ascendente).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Los resultados son un libro de texto sobre la heteroscedasticidad.</p>
<ul>
<li>El gráfico de <strong>Residuos vs.&nbsp;Valores Ajustados</strong> (izquierda) tiene una <strong>forma de embudo</strong> inconfundible: la dispersión de los puntos aumenta drásticamente de izquierda a derecha.</li>
<li>El gráfico <strong>Scale-Location</strong> (derecha) confirma el problema, mostrando una línea roja con una <strong>clara pendiente ascendente</strong>.</li>
<li>La <strong>prueba de Breusch-Pagan</strong> arroja un <strong>p-valor 7.43e-07</strong>, dándonos una fuerte evidencia estadística para rechazar la hipótesis nula de homocedasticidad.</li>
</ul>
<p>Este modelo viola claramente el supuesto, y las inferencias basadas en él (como el p-valor del coeficiente de <code>x</code>) no serían fiables.</p>
</div>
</div>
</section>
<section id="normalidad-de-los-errores" class="level3" data-number="2.6.3">
<h3 data-number="2.6.3" class="anchored" data-anchor-id="normalidad-de-los-errores"><span class="header-section-number">2.6.3</span> 3. Normalidad de los Errores</h3>
<p>Este supuesto postula que los errores del modelo (<span class="math inline">\(\varepsilon_i\)</span>) siguen una distribución normal: <span class="math inline">\(\varepsilon_i \sim N(0, \sigma^2)\)</span>. Es especialmente importante para la validez de los intervalos de confianza y los contrastes de hipótesis cuando el tamaño de la muestra es pequeño.</p>
<section id="evaluación-visual" class="level4" data-number="2.6.3.1">
<h4 data-number="2.6.3.1" class="anchored" data-anchor-id="evaluación-visual"><span class="header-section-number">2.6.3.1</span> <strong>Evaluación Visual</strong></h4>
<ul>
<li><strong>Gráfico Normal Q-Q (<code>Normal Q-Q Plot</code>):</strong> Compara los cuantiles de los residuos estandarizados con los cuantiles de una distribución normal teórica.
<ul>
<li><strong>Qué buscar:</strong> Los puntos deben caer muy cerca de la línea diagonal de 45 grados.</li>
</ul></li>
<li><strong>Histograma de los Residuos:</strong> Un simple histograma de los residuos debe mostrar una forma aproximada de campana de Gauss.</li>
</ul>
</section>
<section id="prueba-analítica" class="level4" data-number="2.6.3.2">
<h4 data-number="2.6.3.2" class="anchored" data-anchor-id="prueba-analítica"><span class="header-section-number">2.6.3.2</span> <strong>Prueba Analítica</strong></h4>
<ul>
<li><strong>Prueba de Shapiro-Wilk:</strong> Es uno de los contrastes más potentes para la normalidad.
<ul>
<li><strong>Hipótesis Nula (<span class="math inline">\(H_0\)</span>):</strong> Los residuos provienen de una distribución normal.</li>
<li><strong>Decisión:</strong> Un p-valor pequeño (&lt; 0.05) sugiere rechazar <span class="math inline">\(H_0\)</span>.</li>
</ul></li>
</ul>
<hr>
</section>
</section>
<section id="independencia-de-los-errores" class="level3" data-number="2.6.4">
<h3 data-number="2.6.4" class="anchored" data-anchor-id="independencia-de-los-errores"><span class="header-section-number">2.6.4</span> 4. Independencia de los Errores</h3>
<p>Este supuesto afirma que el error de una observación no está correlacionado con el de ninguna otra: <span class="math inline">\(Cov(\varepsilon_i, \varepsilon_j) = 0\)</span> para <span class="math inline">\(i \neq j\)</span>. La violación, conocida como <strong>autocorrelación</strong>, es común en datos de series temporales.</p>
<section id="evaluación" class="level4" data-number="2.6.4.1">
<h4 data-number="2.6.4.1" class="anchored" data-anchor-id="evaluación"><span class="header-section-number">2.6.4.1</span> <strong>Evaluación</strong></h4>
<ul>
<li><strong>Prueba de Durbin-Watson:</strong> Es el contraste clásico para la autocorrelación de primer orden. Su estadístico se calcula como: <span class="math display">\[ DW = \frac{\sum_{i=2}^{n}(e_i - e_{i-1})^2}{\sum_{i=1}^{n}e_i^2} \]</span> El estadístico varía entre 0 y 4. Un valor cercano a 2 sugiere no autocorrelación. Valores cercanos a 0 indican autocorrelación positiva, y cercanos a 4, autocorrelación negativa.</li>
</ul>
<hr>
</section>
</section>
<section id="identificación-de-observaciones-influyentes-y-atípicas" class="level3" data-number="2.6.5">
<h3 data-number="2.6.5" class="anchored" data-anchor-id="identificación-de-observaciones-influyentes-y-atípicas"><span class="header-section-number">2.6.5</span> 5. Identificación de Observaciones Influyentes y Atípicas</h3>
<p>Algunos puntos pueden tener una influencia desproporcionada en el modelo. Es crucial identificarlos usando tres métricas clave:</p>
<ul>
<li><p><strong>Apalancamiento (Leverage, <span class="math inline">\(h_{ii}\)</span>):</strong> Mide cuán atípico es el valor de la variable predictora <span class="math inline">\(X_i\)</span> de una observación. Un apalancamiento alto significa que el punto tiene el <em>potencial</em> de ser muy influyente. En regresión simple, se calcula como: <span class="math display">\[ h_{ii} = \frac{1}{n} + \frac{(x_i - \bar{x})^2}{\sum_{j=1}^{n}(x_j - \bar{x})^2} \]</span> Una regla común es considerar un apalancamiento alto si <span class="math inline">\(h_{ii} &gt; \frac{2(k+1)}{n}\)</span>, donde <span class="math inline">\(k\)</span> es el número de predictores (1 en regresión simple).</p></li>
<li><p><strong>Residuos Estudentizados:</strong> Son una versión de los residuos estandarizados que son más efectivos para detectar outliers. Un residuo estudentizado (<span class="math inline">\(r_i\)</span>) sigue una distribución t de Student con <span class="math inline">\(n-k-2\)</span> grados de libertad. Valores <span class="math inline">\(|r_i| &gt; 2\)</span> o <span class="math inline">\(3\)</span> a menudo se consideran atípicos.</p></li>
<li><p><strong>Distancia de Cook (<span class="math inline">\(D_i\)</span>):</strong> Mide la influencia global de una observación, combinando su apalancamiento y su residuo. Representa cuánto cambian los coeficientes del modelo si la i-ésima observación es eliminada. <span class="math display">\[ D_i = \frac{r_i^2}{k+1} \cdot \frac{h_{ii}}{1-h_{ii}} \]</span> Se considera que un punto es influyente si su distancia de Cook es grande, por ejemplo, si <span class="math inline">\(D_i &gt; 1\)</span> o <span class="math inline">\(D_i &gt; 4/(n-k-1)\)</span>.</p></li>
</ul>
<p>El gráfico <strong><code>Residuals vs. Leverage</code></strong> es la herramienta visual que combina estas tres métricas, facilitando la identificación de puntos problemáticos.</p>
</section>
<section id="aplicación-práctica-en-r" class="level3" data-number="2.6.6">
<h3 data-number="2.6.6" class="anchored" data-anchor-id="aplicación-práctica-en-r"><span class="header-section-number">2.6.6</span> Aplicación Práctica en R</h3>
<p>A continuación, se realizan las pruebas de diagnóstico para nuestro <code>modelo_estudio</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráficos de diagnóstico visual estándar</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modelo_estudio)</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Para las pruebas analíticas, usamos el paquete 'lmtest'</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Si no está instalado, ejecuta: install.packages("lmtest")</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lmtest)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Prueba de Breusch-Pagan para homocedasticidad</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="fu">bptest</span>(modelo_estudio)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    studentized Breusch-Pagan test

data:  modelo_estudio
BP = 0.019638, df = 1, p-value = 0.8886</code></pre>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Prueba de Shapiro-Wilk para normalidad (sobre los residuos)</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="fu">shapiro.test</span>(<span class="fu">residuals</span>(modelo_estudio))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Shapiro-Wilk normality test

data:  residuals(modelo_estudio)
W = 0.99008, p-value = 0.671</code></pre>
</div>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Prueba de Durbin-Watson para independencia</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dwtest</span>(modelo_estudio)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
    Durbin-Watson test

data:  modelo_estudio
DW = 2.0565, p-value = 0.6104
alternative hypothesis: true autocorrelation is greater than 0</code></pre>
</div>
<div class="cell-output-display">
<div id="fig-diagnostico-detallado" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagnostico-detallado-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="tema1_files/figure-html/fig-diagnostico-detallado-1.png" class="img-fluid figure-img" width="672">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagnostico-detallado-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;2.7: Gráficos de diagnóstico estándar generados por R.
</figcaption>
</figure>
</div>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-draper1998applied" class="csl-entry" role="listitem">
Draper, NR. 1998. <em>Applied regression analysis</em>. McGraw-Hill. Inc.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copiado");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copiado");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./tema0.html" class="pagination-link" aria-label="Introducción a los modelos de regresión">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción a los modelos de regresión</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./tema2.html" class="pagination-link" aria-label="Métodos de selección de variables y problemas de regularización">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Métodos de selección de variables y problemas de regularización</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>