# Soluciones: Regresi√≥n Lineal Simple

En este cap√≠tulo encontrar√°s las soluciones detalladas a todos los ejercicios del Tema 1. Cada ejercicio incluye tanto el enunciado como la soluci√≥n completa con c√≥digo R y explicaciones te√≥ricas.

::: {.callout-note}
## Instrucciones de Uso

Intenta resolver cada ejercicio por tu cuenta antes de consultar la soluci√≥n. Las soluciones est√°n organizadas en secciones desplegables para facilitar este proceso.
:::

## Ejercicio 1: Fundamentos Conceptuales

Bas√°ndote en el texto, explica con tus propias palabras por qu√© un coeficiente de correlaci√≥n de Pearson ($r$) alto no es suficiente para modelar una relaci√≥n y por qu√© la regresi√≥n lineal es un paso m√°s all√°. Menciona al menos dos cosas que el modelo de regresi√≥n proporciona y que la correlaci√≥n por s√≠ sola no ofrece. 

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>

La correlaci√≥n de Pearson ($r$) solo mide la **fuerza y direcci√≥n** de una relaci√≥n lineal entre dos variables, pero no es suficiente para modelar porque:

1. **No proporciona un modelo predictivo**: La correlaci√≥n solo nos dice qu√© tan relacionadas est√°n las variables, pero no nos permite hacer predicciones espec√≠ficas sobre una variable a partir de la otra.

2. **No cuantifica el cambio**: No nos dice cu√°nto cambia una variable cuando la otra cambia en una unidad espec√≠fica.

La regresi√≥n lineal va m√°s all√° porque proporciona:

1. **Capacidad predictiva**: Permite predecir valores espec√≠ficos de la variable dependiente para valores dados de la independiente.

2. **Cuantificaci√≥n del cambio**: Los coeficientes nos dicen exactamente cu√°nto cambia Y por cada unidad de cambio en X.

3. **Intervalos de confianza y predicci√≥n**: Permite cuantificar la incertidumbre de nuestras estimaciones.

4. **Marco para inferencia estad√≠stica**: Permite realizar pruebas de hip√≥tesis sobre la significancia de la relaci√≥n.

</details>

## Ejercicio 2: Interpretaci√≥n de Coeficientes

Un analista ajusta un modelo para predecir el gasto anual en compras online (`gasto`, en euros) bas√°ndose en la edad del cliente (`edad`). El modelo ajustado es:

`gasto = 1500 + 12 * edad`

a) ¬øCu√°l es el gasto predicho para un cliente de 30 a√±os?
b) Interpreta el significado de la pendiente (12) en el contexto espec√≠fico de este problema. 
c) Interpreta el significado del intercepto (1500). ¬øCrees que esta interpretaci√≥n tiene sentido pr√°ctico en el mundo real? ¬øPor qu√©? 

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>

**a) Gasto predicho para un cliente de 30 a√±os:**
```{r}
# C√°lculo directo
gasto_30 = 1500 + 12 * 30
print(paste("Gasto predicho:", gasto_30, "euros"))
```

**b) Interpretaci√≥n de la pendiente (12):**
Por cada a√±o adicional de edad del cliente, se espera que el gasto anual en compras online aumente en 12 euros, manteniendo todo lo dem√°s constante.

**c) Interpretaci√≥n del intercepto (1500):**
Representa el gasto predicho para un cliente de 0 a√±os, que ser√≠a 1500 euros. **Esta interpretaci√≥n NO tiene sentido pr√°ctico** porque:
- No existen clientes de 0 a√±os
- Estamos extrapolando fuera del rango de datos observados
- El modelo probablemente no es v√°lido para edades tan bajas

:::

### Ejercicio 3: Aplicaci√≥n Pr√°ctica con R (Ajuste e Inferencia)

Utiliza el conjunto de datos `pressure` de R, que contiene mediciones de temperatura y presi√≥n de vapor de mercurio.

a) Ajusta un modelo de regresi√≥n lineal simple para predecir la presi√≥n (`pressure`) en funci√≥n de la temperatura (`temperature`). Guarda el modelo en un objeto.
b) Utiliza la funci√≥n `summary()` sobre el objeto del modelo.
c) Interpreta el valor del **coeficiente de determinaci√≥n R¬≤**. ¬øQu√© porcentaje de la variabilidad de la presi√≥n es explicado por la temperatura? 
d) Interpreta el **p-valor del estad√≠stico F**. ¬øEs el modelo √∫til en su conjunto? 
e) ¬øEs el coeficiente de la temperatura estad√≠sticamente significativo a un nivel de $\alpha = 0.05$? Justifica tu respuesta bas√°ndote en el p-valor del test t. 

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


```{r}
# a) Ajustar el modelo
modelo_pressure <- lm(pressure ~ temperature, data = pressure)

# b) Summary del modelo
summary(modelo_pressure)
```

**c) Interpretaci√≥n del R¬≤:**
```{r}
r_squared <- summary(modelo_pressure)$r.squared
print(paste("R¬≤ =", round(r_squared, 4)))
print(paste("La temperatura explica el", round(r_squared * 100, 2), "% de la variabilidad en la presi√≥n"))
```

**d) Interpretaci√≥n del p-valor del estad√≠stico F:**
```{r}
f_pvalue <- summary(modelo_pressure)$fstatistic
f_test_pvalue <- pf(f_pvalue[1], f_pvalue[2], f_pvalue[3], lower.tail = FALSE)
print(paste("p-valor F-test:", format(f_test_pvalue, scientific = TRUE)))
```
Como p < 0.05, **el modelo es globalmente significativo** - es decir, el modelo es √∫til para predecir la presi√≥n.

**e) Significancia del coeficiente de temperatura:**
```{r}
temp_pvalue <- summary(modelo_pressure)$coefficients["temperature", "Pr(>|t|)"]
print(paste("p-valor temperatura:", format(temp_pvalue, scientific = TRUE)))
```
Como p < 0.05, **el coeficiente de temperatura es estad√≠sticamente significativo**.


</details>

### Ejercicio 4: Intervalos de Confianza y Predicci√≥n

Usando el modelo del ejercicio anterior (`lm(pressure ~ temperature, data = pressure)`):

a) Calcula el **intervalo de confianza al 95%** para la *presi√≥n media* esperada cuando la temperatura es de 250 grados. 
b) Calcula el **intervalo de predicci√≥n al 95%** para la presi√≥n de una *√∫nica y nueva* medici√≥n realizada a 250 grados. 
c) ¬øCu√°l de los dos intervalos es m√°s ancho? Explica la raz√≥n te√≥rica de esta diferencia.

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


```{r}
# a) Intervalo de confianza para la media cuando temp = 250
ic_mean <- predict(modelo_pressure, newdata = data.frame(temperature = 250), 
                   interval = "confidence", level = 0.95)
print("Intervalo de confianza (95%) para la presi√≥n media:")
print(ic_mean)

# b) Intervalo de predicci√≥n para una nueva observaci√≥n
ic_pred <- predict(modelo_pressure, newdata = data.frame(temperature = 250), 
                   interval = "prediction", level = 0.95)
print("Intervalo de predicci√≥n (95%) para una nueva observaci√≥n:")
print(ic_pred)

# c) Comparaci√≥n de anchos
ancho_conf <- ic_mean[3] - ic_mean[2]
ancho_pred <- ic_pred[3] - ic_pred[2]
print(paste("Ancho intervalo confianza:", round(ancho_conf, 2)))
print(paste("Ancho intervalo predicci√≥n:", round(ancho_pred, 2)))
```

**c) ¬øCu√°l es m√°s ancho?**
El **intervalo de predicci√≥n es m√°s ancho** porque incluye dos fuentes de incertidumbre:
1. La incertidumbre sobre la media poblacional (como en el intervalo de confianza)
2. La variabilidad natural de las observaciones individuales alrededor de esa media


</details>

### Ejercicio 5: Supuestos del Modelo

Enumera los cuatro supuestos del modelo de regresi√≥n lineal cl√°sico (tambi√©n conocidos como supuestos de Gauss-Markov) y explica brevemente la importancia de cada uno.

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


Los **cuatro supuestos de Gauss-Markov** son:

1. **Linealidad**: La relaci√≥n entre X e Y es lineal. Importante porque si no se cumple, las predicciones ser√°n sistem√°ticamente err√≥neas.

2. **Independencia**: Las observaciones son independientes entre s√≠. Crucial para que los errores est√°ndar sean correctos.

3. **Homocedasticidad**: La varianza de los errores es constante. Necesario para que los intervalos de confianza y las pruebas de hip√≥tesis sean v√°lidas.

4. **Normalidad de los errores**: Los errores siguen una distribuci√≥n normal. Importante para la validez de las pruebas de hip√≥tesis y los intervalos de confianza.


</details>

### Ejercicio 6: Diagn√≥stico de Linealidad y Homocedasticidad

Para el modelo del ejercicio 3:

a) Genera y muestra el gr√°fico de **Residuos vs. Valores Ajustados**. Bas√°ndote en este gr√°fico, ¬øse cumple el supuesto de **linealidad**? Explica en qu√© te basas.
b) Genera y muestra el gr√°fico **Scale-Location**. Bas√°ndote en este gr√°fico, ¬øse cumple el supuesto de **homocedasticidad**? Describe el patr√≥n que indicar√≠a un problema de heterocedasticidad.

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


```{r}
# a) Gr√°fico de Residuos vs. Valores Ajustados
par(mfrow = c(1, 2))
plot(modelo_pressure, which = 1, main = "Residuos vs. Valores Ajustados")

# b) Gr√°fico Scale-Location
plot(modelo_pressure, which = 3, main = "Scale-Location")
```

**a) Linealidad**: En el gr√°fico de residuos vs. valores ajustados, observamos un **patr√≥n curvado** en lugar de una distribuci√≥n aleatoria alrededor de cero. Esto indica que **NO se cumple perfectamente el supuesto de linealidad**.

**a) Linealidad**: En el gr√°fico de residuos vs. valores ajustados, observamos un **patr√≥n curvado** en lugar de una distribuci√≥n aleatoria alrededor de cero. Esto indica que **NO se cumple perfectamente el supuesto de linealidad**.

**b) Homocedasticidad**: En el gr√°fico Scale-Location, la l√≠nea roja muestra una tendencia creciente, lo que sugiere **heterocedasticidad** (varianza no constante). Un problema de heterocedasticidad se manifestar√≠a como un patr√≥n de embudo o una tendencia clara en este gr√°fico.


</details>

### Ejercicio 7: Diagn√≥stico de Normalidad

Para el modelo del ejercicio 3:

a) Genera un gr√°fico **Normal Q-Q** de los residuos. ¬øParecen seguir los residuos una distribuci√≥n normal?
b) Realiza un **test de Shapiro-Wilk** sobre los residuos del modelo. ¬øQu√© concluyes a partir del p-valor? 

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


```{r}
# a) Gr√°fico Normal Q-Q
par(mfrow = c(1, 1))
plot(modelo_pressure, which = 2, main = "Normal Q-Q Plot")

# b) Test de Shapiro-Wilk
shapiro_test <- shapiro.test(residuals(modelo_pressure))
print("Test de Shapiro-Wilk para normalidad de residuos:")
print(shapiro_test)
```

**a) Q-Q Plot**: Los puntos se desv√≠an considerablemente de la l√≠nea diagonal, especialmente en las colas, indicando que los residuos **no siguen una distribuci√≥n normal**.

**b) Test de Shapiro-Wilk**: Con p-valor < 0.05, **rechazamos la hip√≥tesis nula de normalidad**. Los residuos no son normales.


</details>

### Ejercicio 8: Descomposici√≥n de la Varianza (ANOVA)

Explica qu√© representan la **Suma de Cuadrados Total (SST)**, la **Suma de Cuadrados de la Regresi√≥n (SSR)** y la **Suma de Cuadrados del Error (SSE)**. ¬øCu√°l es la ecuaci√≥n fundamental que las relaciona? 

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


- **SST (Suma de Cuadrados Total)**: Mide la variabilidad total en Y alrededor de su media. $SST = \sum(y_i - \bar{y})^2$

- **SSR (Suma de Cuadrados de la Regresi√≥n)**: Mide la variabilidad explicada por el modelo. $SSR = \sum(\hat{y}_i - \bar{y})^2$

- **SSE (Suma de Cuadrados del Error)**: Mide la variabilidad no explicada (residual). $SSE = \sum(y_i - \hat{y}_i)^2$

**Ecuaci√≥n fundamental**: $SST = SSR + SSE$

Esta descomposici√≥n permite calcular el coeficiente de determinaci√≥n: $R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$


</details>

### Ejercicio 9: Observaciones Influyentes

Basado en la teor√≠a de los apuntes:

a) Explica la diferencia entre un residuo simple ($e_i$), un residuo estandarizado y un residuo estudentizado. ¬øPor qu√© se prefieren los estudentizados para el diagn√≥stico? 
b) ¬øQu√© mide el **leverage** ($h_{ii}$)? ¬øY la **distancia de Cook** ($D_i$)? ¬øPuede una observaci√≥n tener un leverage alto y no ser influyente?

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


**a) Tipos de residuos:**

- **Residuo simple ($e_i$)**: $e_i = y_i - \hat{y}_i$. Diferencia bruta entre observado y predicho.

- **Residuo estandarizado**: $\frac{e_i}{\hat{\sigma}}$. Residuo dividido por la desviaci√≥n est√°ndar residual.

- **Residuo estudentizado**: $\frac{e_i}{\hat{\sigma}_{(i)}\sqrt{1-h_{ii}}}$. Usa la desviaci√≥n est√°ndar calculada sin la observaci√≥n i-√©sima.

Los **estudentizados se prefieren** porque tienen propiedades estad√≠sticas m√°s estables y siguen una distribuci√≥n t conocida.

**b) Medidas de influencia:**

- **Leverage ($h_{ii}$)**: Mide qu√© tan extrema es una observaci√≥n en el espacio de las X. Valores altos indican observaciones con valores de X inusuales.

- **Distancia de Cook ($D_i$)**: Mide el cambio en las predicciones si se elimina la observaci√≥n i. Combina residuo y leverage.

**S√≠, una observaci√≥n puede tener leverage alto pero no ser influyente** si est√° cerca de la l√≠nea de regresi√≥n (residuo peque√±o).


</details>

### Ejercicio 10: Relaci√≥n entre Pruebas de Hip√≥tesis

En el contexto **exclusivo** de la regresi√≥n lineal simple, ¬øqu√© relaci√≥n matem√°tica existe entre el estad√≠stico **F** del test ANOVA y el estad√≠stico **t** del test para la pendiente $\beta_1$? ¬øQu√© implica esto para sus respectivos p-valores?

<details>
<summary><strong>üëÅÔ∏è Ver Soluci√≥n</strong></summary>


En regresi√≥n lineal simple, existe una relaci√≥n matem√°tica exacta:

$$F = t^2$$

Donde:
- $F$ es el estad√≠stico F del test ANOVA global
- $t$ es el estad√≠stico t para la pendiente $\beta_1$

**Implicaciones para los p-valores:**
- Los p-valores de ambos tests son **id√©nticos**
- Si el coeficiente de la pendiente es significativo (test t), entonces el modelo global tambi√©n lo es (test F)
- Ambos tests eval√∫an la misma hip√≥tesis nula: $H_0: \beta_1 = 0$

Esta equivalencia solo se da en regresi√≥n simple. En regresi√≥n m√∫ltiple, el test F eval√∫a todos los coeficientes conjuntamente, mientras que cada test t eval√∫a coeficientes individuales.


</details>
