[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Problemas de Modelos Estadísticos para la Predicción",
    "section": "",
    "text": "Prefacio\nEste manual de soluciones complementa el libro Modelos Estadísticos para la Predicción y está diseñado para proporcionar un apoyo integral al proceso de aprendizaje. Cada solución ha sido desarrollada con el mismo rigor teórico-práctico que caracteriza al curso, ofreciendo no solo la respuesta correcta, sino también el razonamiento estadístico y la interpretación práctica necesarios para una comprensión profunda.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#filosofía-pedagógica",
    "href": "index.html#filosofía-pedagógica",
    "title": "Problemas de Modelos Estadísticos para la Predicción",
    "section": "Filosofía pedagógica",
    "text": "Filosofía pedagógica\nAl igual que el libro principal, este manual sigue un enfoque “teórico-práctico” sin concesiones. Las soluciones están diseñadas para:\n\nReforzar la comprensión de los conceptos fundamentales mediante aplicaciones concretas\nDesarrollar la intuición estadística a través de interpretaciones razonadas\n\nConectar la teoría con la práctica mediante código R completamente funcional\nFomentar el pensamiento crítico sobre las limitaciones y supuestos de cada método",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#cómo-usar-este-manual",
    "href": "index.html#cómo-usar-este-manual",
    "title": "Problemas de Modelos Estadísticos para la Predicción",
    "section": "¿Cómo usar este manual?",
    "text": "¿Cómo usar este manual?\nPara maximizar el beneficio de este recurso:\n\nIntentar primero: Resuelve cada ejercicio por tu cuenta antes de consultar la solución\nEstudiar el proceso: No solo copies el código, entiende la lógica detrás de cada paso\n\nExperimentar: Modifica los parámetros y observa cómo cambian los resultados\nReflexionar: Considera las implicaciones prácticas de cada resultado obtenido",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#metodología-de-las-soluciones",
    "href": "index.html#metodología-de-las-soluciones",
    "title": "Problemas de Modelos Estadísticos para la Predicción",
    "section": "Metodología de las soluciones",
    "text": "Metodología de las soluciones\nCada solución incluye:\n\nCódigo R completo: Totalmente ejecutable y comentado\nExplicaciones paso a paso: Qué hace cada línea y por qué\nInterpretación de resultados: Qué significan los números obtenidos\nGráficos explicativos: Visualización de conceptos clave\nConsejos prácticos: Cuándo y cómo usar cada técnica\n\n\n\n\n\n\n\nImportanteUso responsable\n\n\n\nEste manual es una herramienta de aprendizaje, no un sustituto del pensamiento propio. Utilízalo para verificar tu comprensión y mejorar tu técnica, pero siempre tras haber hecho un esfuerzo genuino por resolver los problemas de forma independiente.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-de-software",
    "href": "index.html#requisitos-de-software",
    "title": "Problemas de Modelos Estadísticos para la Predicción",
    "section": "Requisitos de software",
    "text": "Requisitos de software\nPara ejecutar las soluciones necesitas tener instalados los siguientes paquetes de R:\n# Paquetes principales\ninstall.packages(c(\n  \"car\",           # Diagnósticos avanzados\n  \"MASS\",          # Datasets y funciones estadísticas  \n  \"glmnet\",        # Regularización\n  \"caret\",         # Machine learning\n  \"pROC\",          # Curvas ROC\n  \"fitdistrplus\",  # Ajuste de distribuciones\n  \"lmtest\"         # Tests estadísticos\n))\n\n\n\n\n\n\nNotaSobre los autores\n\n\n\nVíctor Aceña Gil es graduado en Matemáticas por la UNED, máster en Tratamiento Estadístico y Computacional de la Información por la UCM y la UPM, doctor en Tecnologías de la Información y las Comunicaciones por la URJC y profesor del departamento de Informática y Estadística de la URJC. Miembro del grupo de investigación de alto rendimiento en Fundamentos y Aplicaciones de la Ciencia de Datos, DSLAB, de la URJC. Pertenece al grupo de innovación docente, DSLAB-TI.\nIsaac Martín de Diego es diplomado en Estadística por la Universidad de Valladolid (UVA), licenciado en Ciencias y Técnicas Estadísticas por la Universidad Carlos III de Madrid (UC3M), doctor en Ingeniería Matemática por la UC3M, catedrático de Ciencias de la Computación e Inteligencia Artificial del departamento de Informática y Estadística de la URJC. Es fundador y coordinador del DSLAB y del DSLAB-TI.\n\n\nEsta obra está bajo una licencia de Creative Commons Atribución-CompartirIgual 4.0 Internacional.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html",
    "href": "tema1_regresion_simple_soluciones.html",
    "title": "1  Regresión Lineal Simple",
    "section": "",
    "text": "1.1 Ejercicio 1: Fundamentos Conceptuales\nEn este capítulo encontrarás las soluciones detalladas a todos los ejercicios del Tema 1. Cada ejercicio incluye tanto el enunciado como la solución completa con código R y explicaciones teóricas.\nBasándote en el texto, explica con tus propias palabras por qué un coeficiente de correlación de Pearson (\\(r\\)) alto no es suficiente para modelar una relación y por qué la regresión lineal es un paso más allá. Menciona al menos dos cosas que el modelo de regresión proporciona y que la correlación por sí sola no ofrece.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regresión Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html#ejercicio-1-fundamentos-conceptuales",
    "href": "tema1_regresion_simple_soluciones.html#ejercicio-1-fundamentos-conceptuales",
    "title": "1  Regresión Lineal Simple",
    "section": "",
    "text": "La correlación de Pearson (\\(r\\)) solo mide la fuerza y dirección de una relación lineal entre dos variables, pero no es suficiente para modelar porque:\n\nNo proporciona un modelo predictivo: La correlación solo nos dice qué tan relacionadas están las variables, pero no nos permite hacer predicciones específicas sobre una variable a partir de la otra.\nNo cuantifica el cambio: No nos dice cuánto cambia una variable cuando la otra cambia en una unidad específica.\n\nLa regresión lineal va más allá porque proporciona:\n\nCapacidad predictiva: Permite predecir valores específicos de la variable dependiente para valores dados de la independiente.\nCuantificación del cambio: Los coeficientes nos dicen exactamente cuánto cambia Y por cada unidad de cambio en X.\nIntervalos de confianza y predicción: Permite cuantificar la incertidumbre de nuestras estimaciones.\nMarco para inferencia estadística: Permite realizar pruebas de hipótesis sobre la significancia de la relación.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regresión Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema1_regresion_simple_soluciones.html#ejercicio-2-interpretación-de-coeficientes",
    "href": "tema1_regresion_simple_soluciones.html#ejercicio-2-interpretación-de-coeficientes",
    "title": "1  Regresión Lineal Simple",
    "section": "1.2 Ejercicio 2: Interpretación de Coeficientes",
    "text": "1.2 Ejercicio 2: Interpretación de Coeficientes\nUn analista ajusta un modelo para predecir el gasto anual en compras online (gasto, en euros) basándose en la edad del cliente (edad). El modelo ajustado es:\ngasto = 1500 + 12 * edad\n\n¿Cuál es el gasto predicho para un cliente de 30 años?\nInterpreta el significado de la pendiente (12) en el contexto específico de este problema.\nInterpreta el significado del intercepto (1500). ¿Crees que esta interpretación tiene sentido práctico en el mundo real? ¿Por qué?\n\n\n\n\na) Gasto predicho para un cliente de 30 años:\n\n# Cálculo directo\ngasto_30 = 1500 + 12 * 30\nprint(paste(\"Gasto predicho:\", gasto_30, \"euros\"))\n\n[1] \"Gasto predicho: 1860 euros\"\n\n\nb) Interpretación de la pendiente (12): Por cada año adicional de edad del cliente, se espera que el gasto anual en compras online aumente en 12 euros, manteniendo todo lo demás constante.\nc) Interpretación del intercepto (1500): Representa el gasto predicho para un cliente de 0 años, que sería 1500 euros. Esta interpretación NO tiene sentido práctico porque:\n\nNo existen clientes de 0 años\nEstamos extrapolando fuera del rango de datos observados\nEl modelo probablemente no es válido para edades tan bajas\n\n\n\n1.2.1 Ejercicio 3: Aplicación Práctica con R (Ajuste e Inferencia)\nUtiliza el conjunto de datos pressure de R, que contiene mediciones de temperatura y presión de vapor de mercurio.\n\nAjusta un modelo de regresión lineal simple para predecir la presión (pressure) en función de la temperatura (temperature). Guarda el modelo en un objeto.\nUtiliza la función summary() sobre el objeto del modelo.\nInterpreta el valor del coeficiente de determinación R². ¿Qué porcentaje de la variabilidad de la presión es explicado por la temperatura?\nInterpreta el p-valor del estadístico F. ¿Es el modelo útil en su conjunto?\n¿Es el coeficiente de la temperatura estadísticamente significativo a un nivel de \\(\\alpha = 0.05\\)? Justifica tu respuesta basándote en el p-valor del test t.\n\n\n\n\na) Ajustar el modelo:\n\nmodelo_pressure &lt;- lm(pressure ~ temperature, data = pressure)\n\nb) Summary del modelo:\n\nsummary(modelo_pressure)\n\n\nCall:\nlm(formula = pressure ~ temperature, data = pressure)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-158.08 -117.06  -32.84   72.30  409.43 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -147.8989    66.5529  -2.222 0.040124 *  \ntemperature    1.5124     0.3158   4.788 0.000171 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 150.8 on 17 degrees of freedom\nMultiple R-squared:  0.5742,    Adjusted R-squared:  0.5492 \nF-statistic: 22.93 on 1 and 17 DF,  p-value: 0.000171\n\n\nc), d) y e) Interpretación de la Salida del Modelo\nLa forma más eficiente de analizar el modelo es observar directamente la salida de la función summary().\nA partir de esta salida, interpretamos:\nc) Coeficiente de determinación R²: El valor de Multiple R-squared es 0.5742. Esto significa que la temperatura explica el 57.42% de la variabilidad en la presión.\nd) p-valor del estadístico F: En la última línea, el p-value del F-statistic es 0.000171. Al ser un valor muy inferior a 0.05, rechazamos la hipótesis nula (\\(H_0\\)) de que el modelo no tiene capacidad predictiva. Concluimos que el modelo es globalmente significativo.\ne) Significancia del coeficiente: En la tabla de coeficientes, el p-valor (Pr(&gt;|t|)) para temperature es 0.000171. Rechazamos la hipótesis nula (\\(H_0: \\beta_1 = 0\\)) y concluimos que la temperatura tiene una relación estadísticamente significativa con la presión.\n\n\n\n1.2.2 Ejercicio 4: Intervalos de Confianza y Predicción\nUsando el modelo del ejercicio anterior (lm(pressure ~ temperature, data = pressure)):\n\nCalcula el intervalo de confianza al 95% para la presión media esperada cuando la temperatura es de 250 grados.\nCalcula el intervalo de predicción al 95% para la presión de una única y nueva medición realizada a 250 grados.\n¿Cuál de los dos intervalos es más ancho? Explica la razón teórica de esta diferencia.\n\n\n\n\na) Intervalo de confianza para la media cuando temp = 250:\n\nic_mean &lt;- predict(modelo_pressure, newdata = data.frame(temperature = 250), \n                   interval = \"confidence\", level = 0.95)\nprint(\"Intervalo de confianza (95%) para la presión media:\")\n\n[1] \"Intervalo de confianza (95%) para la presión media:\"\n\nprint(ic_mean)\n\n       fit      lwr      upr\n1 230.2061 143.5771 316.8351\n\n\nb) Intervalo de predicción para una nueva observación:\n\nic_pred &lt;- predict(modelo_pressure, newdata = data.frame(temperature = 250), \n                   interval = \"prediction\", level = 0.95)\nprint(\"Intervalo de predicción (95%) para una nueva observación:\")\n\n[1] \"Intervalo de predicción (95%) para una nueva observación:\"\n\nprint(ic_pred)\n\n       fit      lwr      upr\n1 230.2061 -99.5663 559.9785\n\n\nc) Comparación de anchos:\n\nancho_conf &lt;- ic_mean[3] - ic_mean[2]\nancho_pred &lt;- ic_pred[3] - ic_pred[2]\nprint(paste(\"Ancho intervalo confianza:\", round(ancho_conf, 2)))\n\n[1] \"Ancho intervalo confianza: 173.26\"\n\nprint(paste(\"Ancho intervalo predicción:\", round(ancho_pred, 2)))\n\n[1] \"Ancho intervalo predicción: 659.54\"\n\n\nUna visualización ayuda a entender la diferencia al instante:\n\n# Crear gráfico con bandas de confianza y predicción\ntemp_range &lt;- seq(min(pressure$temperature), max(pressure$temperature), length.out = 100)\nconf_bands &lt;- predict(modelo_pressure, newdata = data.frame(temperature = temp_range), \n                     interval = \"confidence\", level = 0.95)\npred_bands &lt;- predict(modelo_pressure, newdata = data.frame(temperature = temp_range), \n                     interval = \"prediction\", level = 0.95)\n\nplot(pressure$temperature, pressure$pressure, \n     xlab = \"Temperatura\", ylab = \"Presión\", \n     main = \"Intervalos de Confianza vs Predicción\")\nabline(modelo_pressure, col = \"red\", lwd = 2)\nlines(temp_range, conf_bands[,\"lwr\"], col = \"blue\", lty = 2)\nlines(temp_range, conf_bands[,\"upr\"], col = \"blue\", lty = 2)\nlines(temp_range, pred_bands[,\"lwr\"], col = \"green\", lty = 3)\nlines(temp_range, pred_bands[,\"upr\"], col = \"green\", lty = 3)\nlegend(\"topleft\", legend = c(\"Regresión\", \"Confianza\", \"Predicción\"), \n       col = c(\"red\", \"blue\", \"green\"), lty = c(1, 2, 3))\n\n\n\n\n\n\n\n\nEn el gráfico, las bandas de confianza (las más internas) definen el rango probable para la media de la presión a una temperatura dada. Las bandas de predicción (las más externas y anchas) definen el rango probable para una única observación futura de presión.\nc) ¿Cuál es más ancho?\nEl intervalo de predicción es más ancho porque incluye dos fuentes de incertidumbre:\n\nLa incertidumbre sobre la media poblacional (como en el intervalo de confianza)\nLa variabilidad natural de las observaciones individuales alrededor de esa media\n\n\n\n\n1.2.3 Ejercicio 5: Supuestos del Modelo\nEnumera los cuatro supuestos del modelo de regresión lineal clásico (también conocidos como supuestos de Gauss-Markov) y explica brevemente la importancia de cada uno.\n\n\n\nLos cuatro supuestos de Gauss-Markov son:\n\nLinealidad: La relación entre X e Y es lineal. Importante porque si no se cumple, las predicciones serán sistemáticamente erróneas.\nIndependencia: Las observaciones son independientes entre sí. Crucial para que los errores estándar sean correctos.\nHomocedasticidad: La varianza de los errores es constante. Necesario para que los intervalos de confianza y las pruebas de hipótesis sean válidas.\nNormalidad de los errores: Los errores siguen una distribución normal. Importante para la validez de las pruebas de hipótesis y los intervalos de confianza.\n\n\n\n\n1.2.4 Ejercicio 6: Diagnóstico de Linealidad y Homocedasticidad\nPara el modelo del ejercicio 3:\n\nGenera y muestra el gráfico de Residuos vs. Valores Ajustados. Basándote en este gráfico, ¿se cumple el supuesto de linealidad? Explica en qué te basas.\nGenera y muestra el gráfico Scale-Location. Basándote en este gráfico, ¿se cumple el supuesto de homocedasticidad? Describe el patrón que indicaría un problema de heterocedasticidad.\n\n\n\n\na) Gráfico de Residuos vs. Valores Ajustados:\n\npar(mfrow = c(1, 2))\nplot(modelo_pressure, which = 1, main = \"Residuos vs. Valores Ajustados\")\n\n\n\n\n\n\n\n\nb) Gráfico Scale-Location:\n\nplot(modelo_pressure, which = 3, main = \"Scale-Location\")\n\n\n\n\n\n\n\n\na) Linealidad: En el gráfico de residuos vs. valores ajustados, observamos un patrón curvado en lugar de una distribución aleatoria alrededor de cero. Esto indica que NO se cumple perfectamente el supuesto de linealidad.\nb) Homocedasticidad: En el gráfico Scale-Location, la línea roja muestra una tendencia creciente, lo que sugiere heterocedasticidad (varianza no constante). Un problema de heterocedasticidad se manifestaría como un patrón de embudo o una tendencia clara en este gráfico.\n\n1.2.4.1 ¿Y ahora qué? Pasos Siguientes\nUn buen análisis no termina al detectar un problema, sino al proponer una solución.\n\nContexto: El mal ajuste del modelo tiene una razón física. La relación entre temperatura y presión de vapor no es lineal, sino exponencial.\nSolución: Para corregirlo, aplicamos una transformación para linealizar la relación. La más común es el logaritmo natural sobre la variable respuesta.\n\n\n# 1. Ajustamos un nuevo modelo con log(pressure)\nmodelo_log &lt;- lm(log(pressure) ~ temperature, data = pressure)\n\n# 2. Generamos los nuevos gráficos de diagnóstico\npar(mfrow = c(1, 2))\nplot(modelo_log, which = 1) # Linealidad\nplot(modelo_log, which = 3) # Homocedasticidad\n\n\n\n\n\n\n\n\nComo se puede observar, en los nuevos gráficos el patrón curvado ha desaparecido y la varianza de los residuos es mucho más constante. Esto demuestra cómo el diagnóstico nos lleva a mejorar y validar nuestro modelo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Regresión Lineal Simple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html",
    "href": "tema2_regresion_multiple_soluciones.html",
    "title": "2  Regresión Lineal Múltiple",
    "section": "",
    "text": "2.1 Ejercicio 1: Conceptual (Interpretación Ceteris Paribus)\nUn analista ajusta dos modelos para predecir el consumo de un coche (mpg):\nExplica detalladamente por qué el coeficiente para la variable wt (peso) cambia al añadir la variable hp (caballos de fuerza). ¿Cuál de los dos coeficientes representa el efecto “puro” o “aislado” del peso? Fundamenta tu respuesta en el principio de ceteris paribus.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-1-conceptual-interpretación-ceteris-paribus",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-1-conceptual-interpretación-ceteris-paribus",
    "title": "2  Regresión Lineal Múltiple",
    "section": "",
    "text": "lm(mpg ~ wt) obtiene un coeficiente para wt de -5.3.\nlm(mpg ~ wt + hp) obtiene un coeficiente para wt de -3.8.\n\n\n\n\n\nExplicación del cambio en coeficientes:\nEl cambio en el coeficiente de wt (de -5.3 a -3.8) se debe a que en el modelo múltiple controlamos por el efecto de hp.\nEn el modelo simple (mpg ~ wt):\n\nEl coeficiente -5.3 captura el efecto “total” del peso, incluyendo efectos directos e indirectos.\nParte de este efecto puede deberse a que los coches más pesados tienden a tener más caballos de fuerza, y los caballos de fuerza también reducen el consumo.\n\nEn el modelo múltiple (mpg ~ wt + hp):\n\nEl coeficiente -3.8 representa el efecto “puro” del peso, manteniendo constante los caballos de fuerza.\nEs el efecto del peso ceteris paribus (todo lo demás igual).\n\nEl coeficiente que representa el efecto “puro” es el del modelo múltiple (-3.8), porque aísla el efecto del peso de otras variables correlacionadas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-2-práctico-ajuste-e-interpretación-de-un-modelo-múltiple",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-2-práctico-ajuste-e-interpretación-de-un-modelo-múltiple",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.2 Ejercicio 2: Práctico (Ajuste e Interpretación de un Modelo Múltiple)",
    "text": "2.2 Ejercicio 2: Práctico (Ajuste e Interpretación de un Modelo Múltiple)\nUsa el conjunto de datos iris de R. Queremos modelar la anchura del pétalo (Petal.Width) en función de la longitud del pétalo (Petal.Length) y la anchura del sépalo (Sepal.Width).\n\nAjusta un modelo de regresión lineal múltiple: lm(Petal.Width ~ Petal.Length + Sepal.Width, data = iris).\nInterpreta el coeficiente estimado para Petal.Length.\nInterpreta el coeficiente estimado para Sepal.Width.\nInterpreta el intercepto del modelo. ¿Tiene un significado práctico en este contexto biológico?\n\n\n\n\na) Ajustar modelo múltiple\n\nmodelo_iris &lt;- lm(Petal.Width ~ Petal.Length + Sepal.Width, data = iris)\nsummary(modelo_iris)\n\n\nCall:\nlm(formula = Petal.Width ~ Petal.Length + Sepal.Width, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.53907 -0.11443 -0.01447  0.12168  0.65419 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -0.70648    0.15133  -4.668 6.78e-06 ***\nPetal.Length  0.42627    0.01045  40.804  &lt; 2e-16 ***\nSepal.Width   0.09940    0.04231   2.349   0.0201 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2034 on 147 degrees of freedom\nMultiple R-squared:  0.9297,    Adjusted R-squared:  0.9288 \nF-statistic: 972.7 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nb) Interpretación coeficiente Petal.Length: Por cada unidad adicional en la longitud del pétalo (Petal.Length), se espera que la anchura del pétalo (Petal.Width) aumente en aproximadamente 0.426 cm, manteniendo constante la anchura del sépalo.\nc) Interpretación coeficiente Sepal.Width: Por cada unidad adicional en la anchura del sépalo (Sepal.Width), se espera que la anchura del pétalo (Petal.Width) aumente en aproximadamente 0.099 cm, manteniendo constante la longitud del pétalo.\nd) Interpretación del intercepto: Representa la anchura predicha del pétalo cuando tanto la longitud del pétalo como la anchura del sépalo son 0 cm. No tiene significado práctico en este contexto biológico porque no existen flores con estas dimensiones cero.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-3-conceptual-r²-vs.-r²-ajustado",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-3-conceptual-r²-vs.-r²-ajustado",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.3 Ejercicio 3: Conceptual (R² vs. R² Ajustado)",
    "text": "2.3 Ejercicio 3: Conceptual (R² vs. R² Ajustado)\nCuando pasamos de un modelo simple a uno múltiple, introducimos el R² ajustado como medida de bondad de ajuste.\n\n¿Cuál es el principal problema de usar el R² tradicional para comparar modelos con diferente número de predictores?\n¿Cómo soluciona el R² ajustado este problema? Explica qué “penalización” introduce en su fórmula.\n\n\n\n\na) Problema del R² tradicional: El R² tradicional siempre aumenta (o permanece igual) cuando añadimos más predictores al modelo, incluso si estos predictores no aportan información real. Esto hace que no sea útil para comparar modelos con diferente número de variables, ya que favorece artificialmente a los modelos más complejos.\nb) Solución del R² ajustado: El R² ajustado penaliza la complejidad del modelo introduciendo un factor de ajuste que depende del número de predictores:\n\\(R^2_{adj} = 1 - \\frac{(1-R^2)(n-1)}{n-p-1}\\)\nDonde: - \\(n\\) = número de observaciones - \\(p\\) = número de predictores\nEsta penalización hace que el R² ajustado pueda disminuir si añadimos predictores que no mejoran suficientemente el ajuste.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-4-interpretación-de-salidas-de-r",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-4-interpretación-de-salidas-de-r",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.4 Ejercicio 4: Interpretación de Salidas de R",
    "text": "2.4 Ejercicio 4: Interpretación de Salidas de R\nTe presentan el siguiente resumen de un modelo que predice el prestigio de una ocupación (prestige) en función de los ingresos (income) y el nivel educativo (education).\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.0647    4.2750   -1.419   0.1595    \nincome       0.0013    0.0003    4.524   1.9e-05 ***\neducation    4.1832    0.3887   10.762   &lt; 2e-16 ***\n\nMultiple R-squared:  0.79,  Adjusted R-squared:  0.785 \nF-statistic: 185.6 on 2 and 99 DF,  p-value: &lt; 2.2e-16\n\n¿Es el modelo globalmente significativo? ¿En qué te basas?\n¿Son los predictores income y education individualmente significativos, después de controlar por el efecto del otro? Justifica tu respuesta.\nExplica la diferencia conceptual entre lo que evalúa el test F global y lo que evalúan los tests t individuales en este modelo.\n\n\n\n\na) ¿Es el modelo globalmente significativo? Sí, el modelo es globalmente significativo porque el p-valor del estadístico F es &lt; 2.2e-16 (prácticamente 0), que es mucho menor que 0.05. Esto significa que al menos uno de los predictores es significativo.\nb) ¿Son los predictores individualmente significativos?\n\nincome: Sí es significativo (p = 1.9e-05 &lt; 0.05) después de controlar por education.\neducation: Sí es significativo (p &lt; 2e-16 &lt; 0.05) después de controlar por income.\n\nc) Diferencia conceptual entre tests:\n\nTest F global: Evalúa si el modelo en conjunto es mejor que no tener modelo (H₀: β₁ = β₂ = 0).\nTests t individuales: Evalúan si cada coeficiente específico es significativamente diferente de cero, controlando por las otras variables en el modelo.\n\nEs posible tener un F significativo con algunos t no significativos si hay multicolinealidad.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-5-conceptual-multicolinealidad",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-5-conceptual-multicolinealidad",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.5 Ejercicio 5: Conceptual (Multicolinealidad)",
    "text": "2.5 Ejercicio 5: Conceptual (Multicolinealidad)\nDescribe con tus propias palabras qué es la multicolinealidad. Menciona tres consecuencias negativas que puede tener la multicolinealidad severa en un modelo de regresión y si afecta más a la predicción o a la inferencia.\n\n\n\nMulticolinealidad es la existencia de relaciones lineales fuertes entre dos o más variables predictoras en un modelo de regresión.\nTres consecuencias negativas:\n\nInestabilidad de los coeficientes: Pequeños cambios en los datos pueden causar grandes cambios en las estimaciones de los coeficientes.\nErrores estándar inflados: Los errores estándar de los coeficientes se vuelven muy grandes, dificultando detectar efectos significativos.\nDificultad interpretativa: Los coeficientes individuales pierden significado claro porque las variables están confundidas entre sí.\n\nAnalogía útil: Es como intentar medir la contribución individual de dos escaladores que siempre suben una montaña atados el uno al otro. Es muy difícil saber qué parte del ascenso se debe a cada uno por separado.\nLa multicolinealidad afecta más a la inferencia que a la predicción. Las predicciones pueden seguir siendo buenas, pero la interpretación de los coeficientes se vuelve problemática.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-6-práctico-diagnóstico-de-multicolinealidad",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-6-práctico-diagnóstico-de-multicolinealidad",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.6 Ejercicio 6: Práctico (Diagnóstico de Multicolinealidad)",
    "text": "2.6 Ejercicio 6: Práctico (Diagnóstico de Multicolinealidad)\nUsa el dataset mtcars. Ajusta un modelo para predecir el consumo (mpg) usando como predictores el número de cilindros (cyl), la cilindrada (disp), los caballos de fuerza (hp) y el peso (wt).\n\nObserva el summary() del modelo. ¿Hay alguna variable que, a pesar de tener una alta correlación simple con mpg, no resulte significativa en el modelo múltiple?\nCarga la librería car y calcula el Factor de Inflación de la Varianza (VIF) para cada predictor.\nBasándote en los valores del VIF, ¿qué variables presentan un problema de multicolinealidad? ¿Cuál es tu recomendación para simplificar el modelo?\n\n\n\n\n\n# Ajustar modelo con mtcars\nmodelo_mtcars &lt;- lm(mpg ~ cyl + disp + hp + wt, data = mtcars)\nsummary(modelo_mtcars)\n\n\nCall:\nlm(formula = mpg ~ cyl + disp + hp + wt, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0562 -1.4636 -0.4281  1.2854  5.8269 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 40.82854    2.75747  14.807 1.76e-14 ***\ncyl         -1.29332    0.65588  -1.972 0.058947 .  \ndisp         0.01160    0.01173   0.989 0.331386    \nhp          -0.02054    0.01215  -1.691 0.102379    \nwt          -3.85390    1.01547  -3.795 0.000759 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.513 on 27 degrees of freedom\nMultiple R-squared:  0.8486,    Adjusted R-squared:  0.8262 \nF-statistic: 37.84 on 4 and 27 DF,  p-value: 1.061e-10\n\n# Examinar correlaciones simples primero\ncor_matrix &lt;- cor(mtcars[c(\"mpg\", \"cyl\", \"disp\", \"hp\", \"wt\")])\nprint(\"Matriz de correlaciones:\")\n\n[1] \"Matriz de correlaciones:\"\n\nprint(round(cor_matrix, 3))\n\n        mpg    cyl   disp     hp     wt\nmpg   1.000 -0.852 -0.848 -0.776 -0.868\ncyl  -0.852  1.000  0.902  0.832  0.782\ndisp -0.848  0.902  1.000  0.791  0.888\nhp   -0.776  0.832  0.791  1.000  0.659\nwt   -0.868  0.782  0.888  0.659  1.000\n\n\na) Observación del summary: A pesar de que variables como cyl y disp tienen correlaciones altas con mpg individualmente, en el modelo múltiple pueden aparecer como no significativas debido a la multicolinealidad entre predictores.\nb) Calcular VIF\n\nlibrary(car)\n\nLoading required package: carData\n\nvif_values &lt;- vif(modelo_mtcars)\nprint(\"Valores VIF:\")\n\n[1] \"Valores VIF:\"\n\nprint(vif_values)\n\n      cyl      disp        hp        wt \n 6.737707 10.373286  3.405983  4.848016 \n\n\nc) Interpretación VIF:\n\nVIF &gt; 5: Multicolinealidad moderada\nVIF &gt; 10: Multicolinealidad severa\n\nVariables con VIF alto (probablemente cyl, disp) presentan problemas de multicolinealidad.\nRecomendación: Las variables disp y cyl presentan una fuerte multicolinealidad, como indican sus VIFs altos. Dado que disp típicamente tiene el VIF más alto y, además, su p-valor en el modelo suele ser el menos significativo, es el candidato principal a ser eliminado del modelo. Después de eliminarla, se debería volver a ajustar el modelo y re-evaluar los VIFs para confirmar que la multicolinealidad se ha reducido.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-7-teórico-notación-matricial",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-7-teórico-notación-matricial",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.7 Ejercicio 7: Teórico (Notación Matricial)",
    "text": "2.7 Ejercicio 7: Teórico (Notación Matricial)\n\nEscribe la fórmula del estimador de Mínimos Cuadrados Ordinarios (\\(\\hat{\\mathbf{\\beta}}\\)) en notación matricial.\n¿Qué supuesto fundamental del modelo de regresión múltiple garantiza que la matriz \\((\\mathbf{X}^T\\mathbf{X})\\) sea invertible?\n\n\n\n\na) Estimador de MCO: \\[\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\\]\nb) Supuesto fundamental: El supuesto de no multicolinealidad perfecta garantiza que las columnas de \\(\\mathbf{X}\\) sean linealmente independientes, lo que asegura que \\((\\mathbf{X}^T\\mathbf{X})\\) sea invertible.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-8-práctico-gráficos-de-regresión-parcial",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-8-práctico-gráficos-de-regresión-parcial",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.8 Ejercicio 8: Práctico (Gráficos de Regresión Parcial)",
    "text": "2.8 Ejercicio 8: Práctico (Gráficos de Regresión Parcial)\nUsa el dataset Prestige de la librería car.\n\nAjusta el modelo lm(prestige ~ income + education + women, data = Prestige).\nGenera los gráficos de regresión parcial (o “added-variable plots”) para este modelo usando la función avPlots(tu_modelo).\nExplica qué representa el gráfico para la variable education. ¿Qué significan los ejes X e Y de ese gráfico específico? ¿A qué corresponde la pendiente de la línea en ese gráfico?\n\n\n\n\na) Gráficos de regresión parcial\n\n# Cargar datos Prestige (si no está disponible, usar mtcars como alternativa)\n# library(car)\n# data(Prestige)\n# modelo_prestige &lt;- lm(prestige ~ income + education + women, data = Prestige)\n\n# Alternativa con mtcars\nmodelo_parcial &lt;- lm(mpg ~ wt + hp + qsec, data = mtcars)\n\nlibrary(car)\navPlots(modelo_parcial)\n\n\n\n\n\n\n\n\nc) Interpretación del gráfico para education (o variable elegida):\n\nEje X: Residuos de education después de regresionar contra las otras variables\nEje Y: Residuos de prestige después de regresionar contra las otras variables\n\nPendiente: Es exactamente el coeficiente de education en el modelo múltiple\nInterpretación: Muestra la relación “pura” entre education y prestige, eliminando el efecto de las otras variables.\n\nPor ejemplo, si miramos el gráfico para wt | others, la pendiente negativa de la línea azul representa visualmente el coeficiente negativo para la variable wt en el modelo múltiple. Nos muestra que, incluso después de descontar el efecto de los caballos de fuerza (hp) y el tiempo de cuarto de milla (qsec), un mayor peso (wt) sigue estando asociado a un menor consumo (mpg).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-9-inferencia-f-test-vs.-t-tests",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-9-inferencia-f-test-vs.-t-tests",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.9 Ejercicio 9: Inferencia (F-test vs. t-tests)",
    "text": "2.9 Ejercicio 9: Inferencia (F-test vs. t-tests)\nDescribe un escenario hipotético en el que el test F global de un modelo de regresión múltiple sea altamente significativo (p &lt; 0.001), pero ninguno de los tests t individuales para los coeficientes sea significativo. ¿Cuál es la causa estadística más probable de este fenómeno?\n\n\n\nEscenario hipotético: Un modelo con multicolinealidad severa entre predictores podría tener:\n\nF-test significativo: Porque el conjunto de variables sí explica la variabilidad\nt-tests no significativos: Porque la multicolinealidad infla los errores estándar individuales\n\nCausa estadística: La multicolinealidad hace que sea difícil determinar la contribución individual de cada variable, pero el conjunto sí tiene poder predictivo.\nUna analogía sería un dúo de cantantes que siempre actúan juntos. Sabemos que el dúo en su conjunto es un éxito (F-test significativo), pero es imposible determinar estadísticamente cuál de los dos es el responsable principal del éxito (ningún t-test es significativo), porque sus contribuciones están perfectamente correlacionadas.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema2_regresion_multiple_soluciones.html#ejercicio-10-práctico-comparación-de-modelos-anidados",
    "href": "tema2_regresion_multiple_soluciones.html#ejercicio-10-práctico-comparación-de-modelos-anidados",
    "title": "2  Regresión Lineal Múltiple",
    "section": "2.10 Ejercicio 10: Práctico (Comparación de Modelos Anidados)",
    "text": "2.10 Ejercicio 10: Práctico (Comparación de Modelos Anidados)\nUsa el dataset swiss.\n\nAjusta un modelo reducido para predecir Fertility usando solo Agriculture y Education.\nAjusta un modelo completo que, además de las variables anteriores, incluya Catholic y Infant.Mortality.\nUtiliza la función anova() para comparar formalmente los dos modelos. ¿Aportan las variables Catholic y Infant.Mortality una mejora estadísticamente significativa al modelo? Interpreta el p-valor del test F resultante.\n\n\n\n\n\n# a) Modelo reducido\nmodelo_reducido &lt;- lm(Fertility ~ Agriculture + Education, data = swiss)\n\n# b) Modelo completo  \nmodelo_completo &lt;- lm(Fertility ~ Agriculture + Education + Catholic + Infant.Mortality, data = swiss)\n\n# c) Comparación con ANOVA\nanova_test &lt;- anova(modelo_reducido, modelo_completo)\nprint(\"Test F para comparación de modelos anidados:\")\n\n[1] \"Test F para comparación de modelos anidados:\"\n\nprint(anova_test)\n\nAnalysis of Variance Table\n\nModel 1: Fertility ~ Agriculture + Education\nModel 2: Fertility ~ Agriculture + Education + Catholic + Infant.Mortality\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     44 3953.3                                  \n2     42 2158.1  2    1795.2 17.469 3.015e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nInterpretación: El p-valor del test F, que se encuentra en la columna Pr(&gt;F), es 3.015e-06. Como este valor es muchísimo menor que nuestro nivel de significancia de 0.05, rechazamos la hipótesis nula de que no hay diferencia entre los modelos. Concluimos que añadir las variables Catholic y Infant.Mortality aporta una mejora estadísticamente significativa al poder predictivo del modelo. Por lo tanto, debemos preferir el modelo completo.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Regresión Lineal Múltiple</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html",
    "title": "3  Ingeniería de Características",
    "section": "",
    "text": "3.1 Ejercicio 1: Conceptual (Diagnóstico antes de Transformar)\nEl texto desaconseja fuertemente el enfoque de “ensayo y error” al aplicar transformaciones. Explica con tus propias palabras por qué la práctica de probar transformaciones hasta que mejore el R² es metodológicamente peligrosa. Menciona al menos tres de los riesgos específicos discutidos en los apuntes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-1-conceptual-diagnóstico-antes-de-transformar",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-1-conceptual-diagnóstico-antes-de-transformar",
    "title": "3  Ingeniería de Características",
    "section": "",
    "text": "El enfoque de “ensayo y error” para transformaciones es metodológicamente peligroso por varios riesgos:\n1. Data snooping/p-hacking: Probar múltiples transformaciones hasta encontrar una que mejore el R² aumenta artificialmente la probabilidad de encontrar patrones espurios.\n2. Sobreajuste: El modelo resultante puede ajustarse específicamente a las peculiaridades de los datos de entrenamiento y no generalizar bien.\n3. Pérdida de interpretabilidad: Las transformaciones complejas pueden hacer que el modelo sea difícil de interpretar y comunicar.\n4. Invalidación de la inferencia estadística: Los p-valores y intervalos de confianza ya no son válidos cuando se ha hecho selección de modelos basada en los datos.\n5. Falta de justificación teórica: Sin una base conceptual, la transformación puede no tener sentido en el contexto del problema.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-2-práctico-escalado-de-variables",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-2-práctico-escalado-de-variables",
    "title": "3  Ingeniería de Características",
    "section": "3.2 Ejercicio 2: Práctico (Escalado de Variables)",
    "text": "3.2 Ejercicio 2: Práctico (Escalado de Variables)\nUtiliza el dataset iris de R y céntrate en las cuatro variables predictoras continuas (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width).\n\nCalcula la media y la desviación estándar de estas cuatro variables en su escala original. ¿Son sus escalas directamente comparables?\nCrea un nuevo data frame donde hayas aplicado la estandarización Z-Score a estas cuatro variables. Verifica que las nuevas variables tienen una media cercana a 0 y una desviación estándar de 1.\n¿Por qué este paso de escalado es crucial antes de aplicar métodos de regularización como Ridge o Lasso, tal y como se menciona en el texto?\n\n\n\n\na) Estadísticas descriptivas originales:\n\nvariables_iris &lt;- iris[, 1:4]\nestadisticas_orig &lt;- data.frame(\n  Media = sapply(variables_iris, mean),\n  Desv_Est = sapply(variables_iris, sd)\n)\nprint(\"Estadísticas originales:\")\n\n[1] \"Estadísticas originales:\"\n\nprint(round(estadisticas_orig, 3))\n\n             Media Desv_Est\nSepal.Length 5.843    0.828\nSepal.Width  3.057    0.436\nPetal.Length 3.758    1.765\nPetal.Width  1.199    0.762\n\n\nLas escalas NO son directamente comparables porque tienen diferentes unidades y rangos de variación.\nb) Estandarización Z-Score:\n\niris_scaled &lt;- as.data.frame(scale(variables_iris))\nestadisticas_scaled &lt;- data.frame(\n  Media = sapply(iris_scaled, mean),\n  Desv_Est = sapply(iris_scaled, sd)\n)\nprint(\"Estadísticas después de estandarización:\")\n\n[1] \"Estadísticas después de estandarización:\"\n\nprint(round(estadisticas_scaled, 10))\n\n             Media Desv_Est\nSepal.Length     0        1\nSepal.Width      0        1\nPetal.Length     0        1\nPetal.Width      0        1\n\n\nc) Importancia para regularización: El escalado es crucial para Ridge/Lasso porque estos métodos penalizan los coeficientes por su magnitud. Sin escalado, variables con escalas más grandes serían penalizadas más severamente, creando un sesgo artificial en la selección de variables.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-3-conceptual-elección-del-método-de-escalado",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-3-conceptual-elección-del-método-de-escalado",
    "title": "3  Ingeniería de Características",
    "section": "3.3 Ejercicio 3: Conceptual (Elección del Método de Escalado)",
    "text": "3.3 Ejercicio 3: Conceptual (Elección del Método de Escalado)\nDescribe un escenario hipotético para cada uno de los siguientes casos, explicando por qué el método de escalado elegido sería el más apropiado:\n\nUn escenario donde la estandarización Z-Score es preferible.\nUn escenario donde la normalización Min-Max es preferible.\nUn escenario donde el escalado robusto (usando mediana y IQR) es necesario.\n\n\n\n\na) Estandarización Z-Score preferible:\n\nEscenario: Análisis de datos de rendimiento académico donde las variables son notas de diferentes materias con distribuciones aproximadamente normales.\nRazón: Es el método estándar y funciona especialmente bien cuando las variables ya tienen una distribución aproximadamente simétrica o normal. Es la base de muchos procedimientos estadísticos que asumen este tipo de distribución.\n\nb) Normalización Min-Max preferible:\n\nEscenario: Sistema de recomendación donde necesitas que todas las variables estén en el rango [0,1] para combinarlas en un score.\nRazón: Garantiza un rango específico y preserva las relaciones exactas entre valores.\n\nc) Escalado robusto necesario:\n\nEscenario: Datos financieros con outliers extremos (como ingresos con algunos multimillonarios).\nRazón: La mediana y el IQR son menos sensibles a outliers que la media y desviación estándar.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-4-práctico-transformación-para-linealizar",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-4-práctico-transformación-para-linealizar",
    "title": "3  Ingeniería de Características",
    "section": "3.4 Ejercicio 4: Práctico (Transformación para Linealizar)",
    "text": "3.4 Ejercicio 4: Práctico (Transformación para Linealizar)\nEn el tema anterior vimos que la relación en el dataset cars (entre speed y dist) no era perfectamente lineal.\n\nAjusta el modelo lm(dist ~ speed, data = cars) y genera el gráfico de residuos vs. valores ajustados para confirmar visualmente la no linealidad (patrón curvo).\nLos apuntes sugieren que la transformación logarítmica es útil para relaciones con “rendimientos decrecientes”. Propón y aplica una transformación (ej. sobre el predictor, la respuesta, o ambos) para intentar linealizar la relación. Por ejemplo, ajusta lm(log(dist) ~ speed, data = cars).\nGenera de nuevo el gráfico de residuos vs. valores ajustados para el nuevo modelo. Compara ambos diagnósticos. ¿Ha mejorado la linealidad?\n\n\n\n\na) Modelo original y diagnóstico:\n\nmodelo_cars_orig &lt;- lm(dist ~ speed, data = cars)\npar(mfrow = c(1, 2))\nplot(modelo_cars_orig, which = 1, main = \"Modelo Original\")\n\n\n\n\n\n\n\n\nb) Transformación propuesta:\n\n# Probamos transformación cuadrática del predictor\nmodelo_cars_trans &lt;- lm(dist ~ I(speed^2), data = cars)\nplot(modelo_cars_trans, which = 1, main = \"Modelo Transformado\")\n\n\n\n\n\n\n\n\n\n# Alternativa: transformación logarítmica de la respuesta\n# (eliminando dist = 0 si existe)\ncars_filtered &lt;- cars[cars$dist &gt; 0, ]\nmodelo_log &lt;- lm(log(dist) ~ speed, data = cars_filtered)\npar(mfrow = c(1, 1))\nplot(modelo_log, which = 1, main = \"Modelo log(dist) ~ speed\")\n\n\n\n\n\n\n\n\nc) Evaluación: Sí, la linealidad ha mejorado notablemente con ambas transformaciones. Comparando los gráficos, tanto la transformación cuadrática del predictor como la logarítmica en la respuesta consiguen eliminar el patrón curvo de los residuos. La transformación logarítmica (log(dist)) parece producir una dispersión de residuos ligeramente más aleatoria y homogénea.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-5-práctico-transformación-de-box-cox",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-5-práctico-transformación-de-box-cox",
    "title": "3  Ingeniería de Características",
    "section": "3.5 Ejercicio 5: Práctico (Transformación de Box-Cox)",
    "text": "3.5 Ejercicio 5: Práctico (Transformación de Box-Cox)\nUsa el dataset Boston de la librería MASS. La variable respuesta medv (valor mediano de la vivienda) es estrictamente positiva y tiene cierta asimetría.\n\nCarga la librería MASS y utiliza la función boxcox() para encontrar el valor de \\(\\lambda\\) óptimo para la variable medv en un modelo simple frente a lstat. La fórmula sería boxcox(medv ~ lstat, data = Boston).\nObservando el gráfico que se genera, ¿a qué valor “simple” (como -1, 0, 0.5, 1) se aproxima el \\(\\lambda\\) óptimo?\nBasándote en este resultado, ¿cuál de las transformaciones clásicas (logarítmica, raíz cuadrada, inversa, etc.) sería la más recomendable para la variable medv?\n\n\n\n\na) Análisis Box-Cox:\n\nlibrary(MASS)\nmodelo_boston &lt;- lm(medv ~ lstat, data = Boston)\nboxcox(modelo_boston)\n\n\n\n\n\n\n\n\nb) Interpretación del gráfico: El λ óptimo parece estar cerca de λ = 0, lo que sugiere una transformación logarítmica.\nc) Recomendación: Basándose en λ ≈ 0, la transformación más recomendable sería log(medv), que es la transformación logarítmica estándar.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-6-conceptual-codificación-de-variables-categóricas",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-6-conceptual-codificación-de-variables-categóricas",
    "title": "3  Ingeniería de Características",
    "section": "3.6 Ejercicio 6: Conceptual (Codificación de Variables Categóricas)",
    "text": "3.6 Ejercicio 6: Conceptual (Codificación de Variables Categóricas)\nExplica la diferencia fundamental entre la Codificación Ordinal y la Codificación One-Hot. Para cada una de las siguientes variables, indica qué método de codificación usarías y justifica tu elección:\n\nmes: (“Enero”, “Febrero”, “Marzo”, …)\nnivel_riesgo: (“Bajo”, “Medio”, “Alto”, “Crítico”)\npais_origen: (“España”, “Francia”, “Alemania”, “Italia”)\n\n\n\n\nDiferencias fundamentales:\n\nCodificación Ordinal: Asigna números consecutivos preservando el orden (1, 2, 3, …)\nCodificación One-Hot: Crea variables binarias (0/1) para cada categoría\n\nRecomendaciones:\n\nmes: One-Hot - Aunque tiene orden natural, los meses son cíclicos y la distancia entre Enero y Diciembre no es 11.\nnivel_riesgo: Ordinal - Hay una clara jerarquía natural (Bajo &lt; Medio &lt; Alto &lt; Crítico).\npais_origen: One-Hot - No hay orden natural entre países, son categorías nominales.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-7-práctico-interacción-entre-variables-continuas",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-7-práctico-interacción-entre-variables-continuas",
    "title": "3  Ingeniería de Características",
    "section": "3.7 Ejercicio 7: Práctico (Interacción entre Variables Continuas)",
    "text": "3.7 Ejercicio 7: Práctico (Interacción entre Variables Continuas)\nUsa el dataset mtcars para investigar si el efecto del peso de un coche (wt) sobre su consumo (mpg) depende de su potencia (hp).\n\nAjusta un modelo que incluya un término de interacción entre wt y hp. Escribe la fórmula en R.\nObserva el summary() del modelo. ¿Es el término de interacción (wt:hp) estadísticamente significativo a un nivel de \\(\\alpha = 0.05\\)?\nBasándote en el signo del coeficiente de la interacción, ¿cómo cambia el efecto del peso sobre el consumo a medida que aumenta la potencia? (Es decir, ¿el efecto negativo del peso se hace más fuerte o más débil en los coches más potentes?).\n\n\n\n\na) Modelo con interacción:\n\nmodelo_interaccion &lt;- lm(mpg ~ wt + hp + wt:hp, data = mtcars)\n# O equivalentemente: lm(mpg ~ wt * hp, data = mtcars)\n\nb) Summary del modelo:\n\nsummary(modelo_interaccion)\n\n\nCall:\nlm(formula = mpg ~ wt + hp + wt:hp, data = mtcars)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.0632 -1.6491 -0.7362  1.4211  4.5513 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 49.80842    3.60516  13.816 5.01e-14 ***\nwt          -8.21662    1.26971  -6.471 5.20e-07 ***\nhp          -0.12010    0.02470  -4.863 4.04e-05 ***\nwt:hp        0.02785    0.00742   3.753 0.000811 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.153 on 28 degrees of freedom\nMultiple R-squared:  0.8848,    Adjusted R-squared:  0.8724 \nF-statistic: 71.66 on 3 and 28 DF,  p-value: 2.981e-13\n\n\nb) Significancia de la interacción: El p-valor del término de interacción wt:hp es aproximadamente 0.000811, que es mucho menor que 0.05, confirmando que la interacción es estadísticamente significativa.\nc) Interpretación del signo y la significancia:\n\nSignificancia: El p-valor del término de interacción wt:hp es 0.000811, que es mucho menor que 0.05. Esto confirma que la interacción es estadísticamente significativa. El efecto del peso sobre el consumo realmente depende de la potencia del coche.\nInterpretación del Coeficiente: El coeficiente de la interacción wt:hp es positivo (+0.02785). Esto significa que a medida que hp (potencia) aumenta, el efecto negativo de wt (peso) sobre mpg (consumo) se vuelve menos negativo (más débil). En términos prácticos: el “castigo” al consumo por cada kilo extra de peso es menor en los coches que ya son muy potentes.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-8-interpretación-de-una-interacción-continua-x-categórica",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-8-interpretación-de-una-interacción-continua-x-categórica",
    "title": "3  Ingeniería de Características",
    "section": "3.8 Ejercicio 8: Interpretación de una Interacción (Continua x Categórica)",
    "text": "3.8 Ejercicio 8: Interpretación de una Interacción (Continua x Categórica)\nUn investigador modela el salario (salario, en euros) en función de los años de experiencia (experiencia) y si el empleado tiene o no un máster (master, con “No” como categoría de referencia). El modelo ajustado es:\nsalario = 30000 + 1200*experiencia + 8000*masterSi + 300*experiencia:masterSi\n\nEscribe la ecuación de regresión específica para los empleados que no tienen un máster.\nEscribe la ecuación de regresión específica para los empleados que sí tienen un máster.\nInterpreta el coeficiente de la interacción (300). ¿Qué nos dice sobre el retorno económico de la experiencia para ambos grupos?\n\n\n\n\nModelo: salario = 30000 + 1200*experiencia + 8000*masterSi + 300*experiencia:masterSi\na) Ecuación para empleados SIN máster:\nsalario = 30000 + 1200*experiencia + 8000*(0) + 300*experiencia*(0)\nsalario = 30000 + 1200*experiencia\nb) Ecuación para empleados CON máster:\nsalario = 30000 + 1200*experiencia + 8000*(1) + 300*experiencia*(1)\nsalario = 38000 + 1500*experiencia\nc) Interpretación del coeficiente de interacción (300): El coeficiente de interacción indica que el retorno económico de cada año de experiencia es 300 euros mayor para los empleados con máster que para los empleados sin máster. Es decir, la experiencia es más valiosa económicamente para quienes tienen un máster.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-9-conceptual-principio-de-jerarquía",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-9-conceptual-principio-de-jerarquía",
    "title": "3  Ingeniería de Características",
    "section": "3.9 Ejercicio 9: Conceptual (Principio de Jerarquía)",
    "text": "3.9 Ejercicio 9: Conceptual (Principio de Jerarquía)\nExplica el principio de jerarquía en el contexto de los modelos de regresión con interacciones. Si un modelo incluye el término de interacción A:B, ¿por qué es una buena práctica incluir siempre los efectos principales A y B, incluso si sus tests t individuales no son significativos?\n\n\n\nEl principio de jerarquía establece que si incluimos un término de interacción A:B, debemos incluir siempre los efectos principales A y B, incluso si no son individualmente significativos.\nRazones:\n\nInterpretabilidad: Los términos de interacción representan desviaciones de los efectos principales. Sin los efectos principales, la interpretación se vuelve confusa.\nEstabilidad numérica: Los algoritmos de ajuste pueden volverse inestables sin los términos principales.\nCoherencia teórica: Desde una perspectiva conceptual, una interacción implica que existen efectos principales que se modifican mutuamente.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-10-conceptual-ingeniería-de-características-avanzada",
    "href": "tema3_ingenieria_caracteristicas_soluciones.html#ejercicio-10-conceptual-ingeniería-de-características-avanzada",
    "title": "3  Ingeniería de Características",
    "section": "3.10 Ejercicio 10: Conceptual (Ingeniería de Características Avanzada)",
    "text": "3.10 Ejercicio 10: Conceptual (Ingeniería de Características Avanzada)\nLos apuntes discuten la creación de nuevas variables mediante ratios y combinaciones. Para cada uno de los siguientes escenarios, propón una nueva variable (feature) que podrías crear y explica qué relación podría capturar mejor que las variables originales por sí solas.\n\nPara predecir la rentabilidad de una tienda, tienes las variables ventas_totales y numero_de_empleados.\nPara predecir el riesgo de impago de un solicitante de préstamo, tienes las variables ingresos_anuales y deuda_total.\n\n\n\n\na) Para predecir rentabilidad de tienda:\n\nVariable propuesta: eficiencia_empleado = ventas_totales / numero_de_empleados\nRelación capturada: Productividad por empleado, que puede ser mejor predictor de rentabilidad que las variables por separado, ya que considera tanto el volumen de negocio como la eficiencia operativa.\n\nb) Para predecir riesgo de impago:\n\nVariable propuesta: ratio_deuda_ingresos = deuda_total / ingresos_anuales\nRelación capturada: Capacidad de pago relativa. Un ratio alto indica mayor riesgo independientemente de los valores absolutos. Por ejemplo, 50,000€ de deuda es muy diferente con ingresos de 30,000€ vs 100,000€.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Ingeniería de Características</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html",
    "href": "tema4_seleccion_validacion_soluciones.html",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "",
    "text": "4.1 Ejercicio 1: Conceptual (Sobreajuste vs. Subajuste)\nExplica con tus propias palabras qué es el sobreajuste (overfitting) y el subajuste (underfitting). Describe los síntomas de cada uno comparando el error de entrenamiento con el error de validación (o de test), y menciona la solución principal para cada problema.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-1-conceptual-sobreajuste-vs.-subajuste",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-1-conceptual-sobreajuste-vs.-subajuste",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "",
    "text": "Sobreajuste (Overfitting):\n\nDefinición: El modelo aprende demasiado específicamente los datos de entrenamiento, incluyendo ruido y patrones espurios.\nSíntomas: Error de entrenamiento muy bajo, pero error de validación/test alto. Gran diferencia entre ambos errores.\nSolución principal: Reducir complejidad del modelo (menos variables, regularización, más datos).\n\nSubajuste (Underfitting):\n\nDefinición: El modelo es demasiado simple para capturar los patrones reales en los datos.\nSíntomas: Tanto el error de entrenamiento como el de validación son altos y similares.\nSolución principal: Aumentar complejidad del modelo (más variables, términos de interacción, modelos más flexibles).\n\nUna imagen clásica ayuda a visualizar esto:\n\n# Simulación del gráfico clásico de sobreajuste vs subajuste\ncomplejidad &lt;- 1:20\nset.seed(123)\n\n# Error de entrenamiento (siempre decrece)\nerror_entrenamiento &lt;- 10 * exp(-0.3 * complejidad) + rnorm(20, 0, 0.2)\nerror_entrenamiento &lt;- pmax(error_entrenamiento, 0.5)  # Mínimo realista\n\n# Error de validación (forma de U)\nerror_validacion &lt;- 8 * exp(-0.2 * complejidad) + 0.15 * complejidad^1.5 + rnorm(20, 0, 0.3)\nerror_validacion &lt;- pmax(error_validacion, 1)  # Mínimo realista\n\n# Crear el gráfico\nplot(complejidad, error_entrenamiento, type = \"l\", col = \"blue\", lwd = 2,\n     ylim = c(0, max(c(error_entrenamiento, error_validacion)) + 1),\n     xlab = \"Complejidad del Modelo\", \n     ylab = \"Error\",\n     main = \"Sobreajuste vs. Subajuste: Error de Entrenamiento vs. Validación\")\n\nlines(complejidad, error_validacion, col = \"red\", lwd = 2)\n\n# Marcar el punto óptimo\npunto_optimo &lt;- which.min(error_validacion)\npoints(complejidad[punto_optimo], error_validacion[punto_optimo], \n       col = \"darkgreen\", pch = 19, cex = 1.5)\n\n# Añadir leyenda\nlegend(\"topright\", \n       legend = c(\"Error Entrenamiento\", \"Error Validación\", \"Punto Óptimo\"),\n       col = c(\"blue\", \"red\", \"darkgreen\"),\n       lty = c(1, 1, NA),\n       pch = c(NA, NA, 19),\n       lwd = 2)\n\n# Añadir regiones\ntext(5, max(error_validacion) * 0.9, \"SUBAJUSTE\", col = \"orange\", cex = 1.2, font = 2)\ntext(15, max(error_validacion) * 0.7, \"SOBREAJUSTE\", col = \"purple\", cex = 1.2, font = 2)\n\n\n\n\n\n\n\n\n\nEn el gráfico, a medida que aumenta la complejidad del modelo (hacia la derecha), el error de entrenamiento siempre baja. Sin embargo, el error de validación (el que realmente importa) baja hasta un punto óptimo y luego empieza a subir, indicando sobreajuste.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-2-práctico-filtrado-básico",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-2-práctico-filtrado-básico",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.2 Ejercicio 2: Práctico (Filtrado Básico)",
    "text": "4.2 Ejercicio 2: Práctico (Filtrado Básico)\nImagina que recibes un nuevo conjunto de datos con 50 predictores para un modelo de regresión. Antes de aplicar métodos computacionalmente costosos, decides hacer un filtrado inicial. Describe los cuatro criterios básicos que aplicarías para descartar variables de forma preliminar, según lo explicado en los apuntes.\n\n\n\nLos cuatro criterios básicos para filtrado inicial son:\n\nVarianza casi cero: Eliminar variables con varianza extremadamente baja o constantes.\nCorrelación muy alta entre predictores: Eliminar variables redundantes (correlación &gt; 0.95).\nMuchos valores faltantes: Eliminar variables con un porcentaje alto de datos perdidos.\nIrrelevancia teórica: Eliminar variables que no tienen sentido conceptual para el problema (ej: ID, timestamps irrelevantes).",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-3-conceptual-aic-vs.-bic",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-3-conceptual-aic-vs.-bic",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.3 Ejercicio 3: Conceptual (AIC vs. BIC)",
    "text": "4.3 Ejercicio 3: Conceptual (AIC vs. BIC)\nTanto el AIC como el BIC son criterios para comparar modelos, pero se basan en filosofías distintas y tienen penalizaciones diferentes.\n\nEscribe la fórmula de la penalización por complejidad para el AIC y para el BIC.\n¿Cuál de los dos criterios tenderá a seleccionar modelos más simples (más parsimoniosos)? ¿Por qué?\nSi tu objetivo principal es la precisión predictiva, ¿cuál de los dos criterios es generalmente preferido?\n\n\n\n\na) Fórmulas de penalización:\n\nAIC: \\(-2\\log L + 2p\\)\nBIC: \\(-2\\log L + p\\log(n)\\)\n\nDonde \\(p\\) = número de parámetros, \\(n\\) = número de observaciones.\nb) ¿Cuál selecciona modelos más simples? BIC tenderá a seleccionar modelos más parsimoniosos porque su penalización es más severa cuando \\(n &gt; 8\\) (ya que \\(\\log(n) &gt; 2\\)).\nc) Para precisión predictiva: AIC es generalmente preferido para precisión predictiva porque está más orientado a minimizar el error de predicción, mientras que BIC está más orientado a encontrar el “modelo verdadero”.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-4-práctico-best-subset-y-criterios-de-información",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-4-práctico-best-subset-y-criterios-de-información",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.4 Ejercicio 4: Práctico (Best Subset y Criterios de Información)",
    "text": "4.4 Ejercicio 4: Práctico (Best Subset y Criterios de Información)\nUsa el conjunto de datos mtcars y la librería leaps.\n\nUtiliza la función regsubsets() para realizar una selección del mejor subconjunto (best subset selection) para predecir mpg usando el resto de variables.\nObtén el summary() de los resultados. ¿Qué modelo (cuántas variables) es el mejor según el criterio Cp de Mallows?\n¿Y cuál es el mejor modelo según el R² ajustado?\n¿Coinciden ambos criterios en el número de variables del modelo óptimo?\n\n\n\n\na) Best subset selection:\n\nlibrary(leaps)\nregfit_full &lt;- regsubsets(mpg ~ ., data = mtcars, nvmax = 10)\n\nb) Summary de resultados:\n\nreg_summary &lt;- summary(regfit_full)\nprint(\"Cp de Mallows por número de variables:\")\n\n[1] \"Cp de Mallows por número de variables:\"\n\nprint(reg_summary$cp)\n\n [1] 11.6269926  1.2187315  0.1026357  0.7899838  1.8462076  3.3700162\n [7]  5.1471984  7.0496037  9.0113719 11.0000000\n\n# Mejor modelo según Cp\nbest_cp &lt;- which.min(reg_summary$cp)\nprint(paste(\"Mejor modelo según Cp:\", best_cp, \"variables\"))\n\n[1] \"Mejor modelo según Cp: 3 variables\"\n\n\nc) Mejor según R² ajustado:\n\nprint(\"R² ajustado por número de variables:\")\n\n[1] \"R² ajustado por número de variables:\"\n\nprint(reg_summary$adjr2)\n\n [1] 0.7445939 0.8185189 0.8335561 0.8367919 0.8375334 0.8347177 0.8296261\n [8] 0.8230390 0.8153314 0.8066423\n\nbest_adjr2 &lt;- which.max(reg_summary$adjr2)\nprint(paste(\"Mejor modelo según R² ajustado:\", best_adjr2, \"variables\"))\n\n[1] \"Mejor modelo según R² ajustado: 5 variables\"\n\n\nd) ¿Coinciden?\n\nprint(paste(\"¿Coinciden Cp y R² adj?\", best_cp == best_adjr2))\n\n[1] \"¿Coinciden Cp y R² adj? FALSE\"\n\n\nPara ver qué variables específicas selecciona cada modelo, podemos usar la función coef():\n\n# Variables del mejor modelo según Cp (3 variables)\nprint(\"Mejores 3 variables (Cp):\")\n\n[1] \"Mejores 3 variables (Cp):\"\n\nprint(names(coef(regfit_full, id = 3)))\n\n[1] \"(Intercept)\" \"wt\"          \"qsec\"        \"am\"         \n\n# Variables del mejor modelo según R² ajustado (5 variables)\nprint(\"Mejores 5 variables (R² adj):\")\n\n[1] \"Mejores 5 variables (R² adj):\"\n\nprint(names(coef(regfit_full, id = 5)))\n\n[1] \"(Intercept)\" \"disp\"        \"hp\"          \"wt\"          \"qsec\"       \n[6] \"am\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-5-conceptual-métodos-stepwise",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-5-conceptual-métodos-stepwise",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.5 Ejercicio 5: Conceptual (Métodos Stepwise)",
    "text": "4.5 Ejercicio 5: Conceptual (Métodos Stepwise)\nLos métodos automáticos paso a paso (forward, backward, stepwise) son computacionalmente eficientes, pero el texto advierte sobre su uso. Menciona y explica brevemente tres de las principales limitaciones o problemas de estos métodos.\n\n\n\nTres principales limitaciones:\n\nInestabilidad: Pequeños cambios en los datos pueden llevar a modelos completamente diferentes. La selección puede ser muy sensible al orden de entrada/salida.\nMúltiples comparaciones: Se realizan muchos tests sin ajuste por multiplicidad, inflando la tasa de error tipo I. Los p-valores ya no tienen su interpretación usual.\nOptimización local: Los métodos stepwise pueden quedarse atrapados en óptimos locales y no encontrar el mejor conjunto global de variables.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-6-práctico-selección-backward-stepwise",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-6-práctico-selección-backward-stepwise",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.6 Ejercicio 6: Práctico (Selección Backward Stepwise)",
    "text": "4.6 Ejercicio 6: Práctico (Selección Backward Stepwise)\nUtiliza el conjunto de datos swiss para predecir Fertility.\n\nAjusta el modelo completo: modelo_completo &lt;- lm(Fertility ~ ., data = swiss).\nUtiliza la función step() para realizar una selección regresiva (backward) basada en el criterio AIC.\nReporta la fórmula del modelo final que selecciona el algoritmo y su valor de AIC.\n\n\n\n\na) Modelo completo:\n\nmodelo_completo &lt;- lm(Fertility ~ ., data = swiss)\n\nb) Selección backward:\n\nmodelo_step &lt;- step(modelo_completo, direction = \"backward\", trace = FALSE)\n\nc) Reporte de resultados:\n\nprint(\"Fórmula del modelo final:\")\n\n[1] \"Fórmula del modelo final:\"\n\nprint(formula(modelo_step))\n\nFertility ~ Agriculture + Education + Catholic + Infant.Mortality\n\nprint(paste(\"AIC del modelo final:\", round(AIC(modelo_step), 2)))\n\n[1] \"AIC del modelo final: 325.24\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-7-conceptual-ridge-vs.-lasso",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-7-conceptual-ridge-vs.-lasso",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.7 Ejercicio 7: Conceptual (Ridge vs. Lasso)",
    "text": "4.7 Ejercicio 7: Conceptual (Ridge vs. Lasso)\nLa regresión Ridge y Lasso son dos métodos de regularización muy populares, pero tienen un efecto fundamentalmente diferente sobre los coeficientes del modelo.\n\n¿Qué tipo de penalización utiliza cada método (\\(L_1\\) o \\(L_2\\))?\n¿Cuál de los dos métodos puede realizar selección de variables (es decir, anular coeficientes por completo)?\nDescribe un escenario en el que preferirías usar Ridge sobre Lasso.\n\n\n\n\na) Tipo de penalización:\n\nRidge: Penalización \\(L_2\\) (suma de cuadrados de coeficientes): \\(\\lambda\\sum\\beta_j^2\\)\nLasso: Penalización \\(L_1\\) (suma de valores absolutos): \\(\\lambda\\sum|\\beta_j|\\)\n\nb) ¿Cuál puede hacer selección de variables? Lasso puede anular coeficientes completamente (hacerlos exactamente cero), realizando selección automática de variables. Ridge solo los reduce hacia cero.\nLa diferencia se debe a la forma geométrica de sus restricciones. La restricción de Lasso (un rombo) tiene “esquinas”, lo que permite que la solución óptima caiga sobre un eje, anulando el coeficiente de la otra variable. La restricción de Ridge (un círculo) es suave y no tiene esquinas, por lo que los coeficientes se acercan a cero pero nunca lo alcanzan.\nc) Escenario para preferir Ridge: Cuando hay muchas variables con efectos pequeños pero reales, y queremos mantenerlas todas con coeficientes reducidos. Por ejemplo, en genómica donde miles de genes pueden tener efectos pequeños pero relevantes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-8-práctico-regresión-lasso",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-8-práctico-regresión-lasso",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.8 Ejercicio 8: Práctico (Regresión Lasso)",
    "text": "4.8 Ejercicio 8: Práctico (Regresión Lasso)\nUtiliza el paquete glmnet y el conjunto de datos mtcars para predecir mpg.\n\nPrepara los datos: crea una matriz x para los predictores y un vector y para la respuesta.\nUtiliza la función cv.glmnet() para realizar una validación cruzada y encontrar el valor de lambda óptimo para una regresión Lasso (alpha = 1).\nExtrae y muestra los coeficientes del modelo Lasso ajustado con el lambda.min.\n¿Qué variables ha eliminado el modelo (coeficientes iguales a cero)?\n\n\n\n\na) Preparar datos:\n\nlibrary(glmnet)\n\nLoading required package: Matrix\n\n\nLoaded glmnet 4.1-10\n\nx &lt;- model.matrix(mpg ~ ., mtcars)[, -1]  # Remover intercepto\ny &lt;- mtcars$mpg\n\nb) Validación cruzada para Lasso:\n\nset.seed(123)\ncv_lasso &lt;- cv.glmnet(x, y, alpha = 1)  # alpha = 1 para Lasso\nplot(cv_lasso)\n\n\n\n\n\n\n\n\nInterpretación del gráfico: El gráfico muestra el Error Cuadrático Medio (MSE) de la validación cruzada en el eje Y para diferentes valores de penalización en el eje X (logaritmo de lambda). La primera línea de puntos vertical (lambda.min) indica el valor de lambda que minimiza el error. La segunda línea (lambda.1se) es una opción más parsimoniosa que se encuentra a un error estándar del mínimo. Los números en la parte superior indican cuántas variables se mantienen en el modelo para cada nivel de penalización.\nc) Coeficientes con lambda óptimo:\n\nlambda_min &lt;- cv_lasso$lambda.min\ncoef_lasso &lt;- coef(cv_lasso, s = lambda_min)\nprint(\"Coeficientes del modelo Lasso:\")\n\n[1] \"Coeficientes del modelo Lasso:\"\n\nprint(coef_lasso)\n\n11 x 1 sparse Matrix of class \"dgCMatrix\"\n            s=0.8007036\n(Intercept) 36.00001676\ncyl         -0.88608541\ndisp         .         \nhp          -0.01168438\ndrat         .         \nwt          -2.70814703\nqsec         .         \nvs           .         \nam           .         \ngear         .         \ncarb         .         \n\n\nd) Variables eliminadas:\n\nvariables_eliminadas &lt;- rownames(coef_lasso)[coef_lasso[,1] == 0 & rownames(coef_lasso) != \"(Intercept)\"]\nprint(\"Variables eliminadas (coeficientes = 0):\")\n\n[1] \"Variables eliminadas (coeficientes = 0):\"\n\nprint(variables_eliminadas)\n\n[1] \"disp\" \"drat\" \"qsec\" \"vs\"   \"am\"   \"gear\" \"carb\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-9-conceptual-validación",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-9-conceptual-validación",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.9 Ejercicio 9: Conceptual (Validación)",
    "text": "4.9 Ejercicio 9: Conceptual (Validación)\nExplica la diferencia entre la estrategia de validación Train/Test Split simple y la Validación Cruzada k-fold. ¿Cuál es la principal ventaja de la validación cruzada sobre la división simple? ¿En qué situación (tamaño del dataset) recomendarías usar cada una?\n\n\n\nTrain/Test Split Simple:\n\nSe divide el dataset una sola vez en entrenamiento y test\nSe entrena en train, se evalúa en test\nVentaja: Rápido y simple\nDesventaja: La estimación del error puede ser inestable y depender de la división específica\n\nValidación Cruzada k-fold:\n\nSe divide el dataset en k particiones\nSe entrena k veces, usando k-1 particiones para entrenar y 1 para validar\nSe promedia el error de las k evaluaciones\nVentaja principal: Estimación más estable y menos dependiente de una división particular\n\nCuándo usar cada una:\n\nTrain/Test simple: Datasets grandes (&gt;10,000 observaciones) donde la estabilidad no es crítica\nValidación cruzada: Datasets pequeños o medianos donde necesitamos estimaciones estables del rendimiento",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema4_seleccion_validacion_soluciones.html#ejercicio-10-práctico-validación-cruzada",
    "href": "tema4_seleccion_validacion_soluciones.html#ejercicio-10-práctico-validación-cruzada",
    "title": "4  Selección de variables, Regularización y Validación",
    "section": "4.10 Ejercicio 10: Práctico (Validación Cruzada)",
    "text": "4.10 Ejercicio 10: Práctico (Validación Cruzada)\nImagina que has ajustado dos modelos para predecir mpg en el dataset mtcars: 1. Un modelo simple: mpg ~ wt + hp 2. Un modelo complejo: mpg ~ . (todas las variables)\nUtilizando la librería caret y la función train(), como se muestra en el callout-tip “La maldición del sobreajuste”, configura y ejecuta una validación cruzada de 10 particiones para estimar el RMSE de ambos modelos. ¿Cuál de los dos modelos generaliza mejor a nuevos datos según esta estimación?\n\n\n\n\n# Configurar validación cruzada\nlibrary(caret)\n\nLoading required package: ggplot2\n\n\nLoading required package: lattice\n\nset.seed(123)\n\n# Configuración de CV\nctrl &lt;- trainControl(\n  method = \"cv\",\n  number = 10,\n  verboseIter = FALSE\n)\n\n# Modelo simple\nmodelo_simple &lt;- train(\n  mpg ~ wt + hp,\n  data = mtcars,\n  method = \"lm\",\n  trControl = ctrl\n)\n\n# Modelo complejo\nmodelo_complejo &lt;- train(\n  mpg ~ .,\n  data = mtcars,\n  method = \"lm\",\n  trControl = ctrl\n)\n\n# Comparar resultados\nprint(\"RMSE - Modelo Simple:\")\n\n[1] \"RMSE - Modelo Simple:\"\n\nprint(modelo_simple$results$RMSE)\n\n[1] 2.430329\n\nprint(\"RMSE - Modelo Complejo:\")\n\n[1] \"RMSE - Modelo Complejo:\"\n\nprint(modelo_complejo$results$RMSE)\n\n[1] 3.257194\n\n# Conclusión\nif(modelo_simple$results$RMSE &lt; modelo_complejo$results$RMSE) {\n  print(\"El modelo simple generaliza mejor\")\n} else {\n  print(\"El modelo complejo generaliza mejor\")\n}\n\n[1] \"El modelo simple generaliza mejor\"",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Selección de variables, Regularización y Validación</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html",
    "href": "tema5_glm_soluciones.html",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "",
    "text": "5.1 Ejercicio 1: Conceptual (Fundamentos de GLM)\nExplica los tres componentes clave que definen a cualquier Modelo Lineal Generalizado (GLM) y describe brevemente la función de cada uno.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-1-conceptual-fundamentos-de-glm",
    "href": "tema5_glm_soluciones.html#ejercicio-1-conceptual-fundamentos-de-glm",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "",
    "text": "Los tres componentes clave de un GLM son:\n\nComponente aleatorio: Especifica la distribución de probabilidad de la variable respuesta (Normal, Binomial, Poisson, etc.). Define cómo se distribuyen los errores.\nComponente sistemático: Define el predictor lineal \\(\\eta = \\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p\\). Es la parte lineal del modelo.\nFunción de enlace: Conecta la media de la distribución (\\(\\mu\\)) con el predictor lineal: \\(g(\\mu) = \\eta\\). Permite que el predictor lineal tenga rango completo mientras la media respeta las restricciones de la distribución.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-2-conceptual-función-de-enlace",
    "href": "tema5_glm_soluciones.html#ejercicio-2-conceptual-función-de-enlace",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.2 Ejercicio 2: Conceptual (Función de Enlace)",
    "text": "5.2 Ejercicio 2: Conceptual (Función de Enlace)\n¿Cuál es el propósito fundamental de la función de enlace en un GLM? ¿Por qué la regresión lineal clásica es considerada un caso particular de un GLM? (Pista: piensa en su función de enlace).\n\n\n\nPropósito de la función de enlace:\nTransformar la media de la variable respuesta para que pueda ser modelada como una combinación lineal de los predictores, respetando las restricciones del dominio de la variable respuesta.\nRegresión lineal como caso particular:\nLa regresión lineal clásica es un GLM con: - Distribución: Normal - Función de enlace: Identidad (\\(g(\\mu) = \\mu\\)) - Por tanto: \\(\\mu = \\beta_0 + \\beta_1 X_1 + ... + \\beta_p X_p\\)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-3-práctico-ajuste-de-un-modelo-logístico",
    "href": "tema5_glm_soluciones.html#ejercicio-3-práctico-ajuste-de-un-modelo-logístico",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.3 Ejercicio 3: Práctico (Ajuste de un Modelo Logístico)",
    "text": "5.3 Ejercicio 3: Práctico (Ajuste de un Modelo Logístico)\nUsa el conjunto de datos mtcars de R. La variable am indica si la transmisión de un coche es automática (0) o manual (1).\n\nAjusta un modelo de regresión logística para predecir la probabilidad de que una transmisión sea manual (am) en función del peso del coche (wt) y los caballos de fuerza (hp).\nUtiliza la función summary() para examinar el modelo. ¿Qué variables parecen ser significativas?\nObtén los coeficientes del modelo. ¿Cómo interpretarías el signo del coeficiente para la variable wt?\n\n\n\n\na) Ajustar modelo logístico:\n\nmodelo_logistico &lt;- glm(am ~ wt + hp, data = mtcars, family = binomial)\n\nb) Summary del modelo:\n\nsummary(modelo_logistico)\n\n\nCall:\nglm(formula = am ~ wt + hp, family = binomial, data = mtcars)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) 18.86630    7.44356   2.535  0.01126 * \nwt          -8.08348    3.06868  -2.634  0.00843 **\nhp           0.03626    0.01773   2.044  0.04091 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.230  on 31  degrees of freedom\nResidual deviance: 10.059  on 29  degrees of freedom\nAIC: 16.059\n\nNumber of Fisher Scoring iterations: 8\n\n\nb) Variables significativas: Basándose en los p-valores, identificar qué variables tienen p &lt; 0.05.\nc) Interpretación del signo de wt: Si el coeficiente de wt es negativo, significa que coches más pesados tienen menor probabilidad de tener transmisión manual (lo cual es intuitivo).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-4-interpretación-odds-ratios",
    "href": "tema5_glm_soluciones.html#ejercicio-4-interpretación-odds-ratios",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.4 Ejercicio 4: Interpretación (Odds Ratios)",
    "text": "5.4 Ejercicio 4: Interpretación (Odds Ratios)\nBasado en el modelo del ejercicio anterior:\n\nCalcula el Odds Ratio (OR) para el coeficiente de la variable hp.\nInterpreta este Odds Ratio en el contexto del problema. Específicamente, ¿cómo cambian las “odds” (la razón de probabilidad) de tener una transmisión manual por cada caballo de fuerza adicional, manteniendo el peso constante?\n\n\n\n\na) Calcular Odds Ratio para hp:\n\ncoef_hp &lt;- coef(modelo_logistico)[\"hp\"]\nodds_ratio_hp &lt;- exp(coef_hp)\nprint(paste(\"Odds Ratio para hp:\", round(odds_ratio_hp, 4)))\n\n[1] \"Odds Ratio para hp: 1.0369\"\n\n# Para todos los coeficientes\nodds_ratios &lt;- exp(coef(modelo_logistico))\nprint(\"Todos los Odds Ratios:\")\n\n[1] \"Todos los Odds Ratios:\"\n\nprint(odds_ratios)\n\n (Intercept)           wt           hp \n1.561455e+08 3.085967e-04 1.036921e+00 \n\n\nb) Interpretación: El Odds Ratio para hp es 1.0369. Esto significa que por cada caballo de fuerza adicional, las odds (la razón de probabilidad) de que un coche tenga transmisión manual se multiplican por 1.0369 (es decir, aumentan aproximadamente un 3.7%), manteniendo constante el peso del coche.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-5-práctico-validación-del-modelo-logístico",
    "href": "tema5_glm_soluciones.html#ejercicio-5-práctico-validación-del-modelo-logístico",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.5 Ejercicio 5: Práctico (Validación del Modelo Logístico)",
    "text": "5.5 Ejercicio 5: Práctico (Validación del Modelo Logístico)\nContinuando con el modelo logístico de mtcars:\n\nGenera las predicciones de probabilidad del modelo para los datos.\nConvierte estas probabilidades en clases (“0” o “1”) usando un umbral de decisión de 0.5.\nCrea la matriz de confusión comparando las predicciones con los valores reales.\nCalcula la precisión (accuracy) global del modelo.\n(Bonus) Utiliza el paquete pROC para calcular y visualizar la curva ROC y obtener el valor del AUC. ¿Qué tan buena es la capacidad discriminativa del modelo?\n\n\n\n\na) Predicciones de probabilidad:\n\nprobabilidades &lt;- predict(modelo_logistico, type = \"response\")\n\nb) Conversión a clases con umbral 0.5:\n\npredicciones_clase &lt;- ifelse(probabilidades &gt; 0.5, 1, 0)\n\nc) Matriz de confusión:\n\ntabla_confusion &lt;- table(Predicho = predicciones_clase, Real = mtcars$am)\nprint(\"Matriz de Confusión:\")\n\n[1] \"Matriz de Confusión:\"\n\nprint(tabla_confusion)\n\n        Real\nPredicho  0  1\n       0 18  1\n       1  1 12\n\n\nd) Cálculo de precisión:\n\nprecision &lt;- sum(diag(tabla_confusion)) / sum(tabla_confusion)\nprint(paste(\"Precisión (Accuracy):\", round(precision, 3)))\n\n[1] \"Precisión (Accuracy): 0.938\"\n\n\ne) Curva ROC y AUC:\n\nlibrary(pROC)\n\nType 'citation(\"pROC\")' for a citation.\n\n\n\nAttaching package: 'pROC'\n\n\nThe following objects are masked from 'package:stats':\n\n    cov, smooth, var\n\nroc_obj &lt;- roc(mtcars$am, probabilidades)\n\nSetting levels: control = 0, case = 1\n\n\nSetting direction: controls &lt; cases\n\nauc_value &lt;- auc(roc_obj)\nplot(roc_obj, main = paste(\"Curva ROC (AUC =\", round(auc_value, 3), \")\"))\n\n\n\n\n\n\n\nprint(paste(\"AUC:\", round(auc_value, 3)))\n\n[1] \"AUC: 0.984\"\n\n\nInterpretación AUC:\n\nAUC &gt; 0.8: Buena capacidad discriminativa\nAUC &gt; 0.9: Excelente capacidad discriminativa\nAUC = 0.5: Sin capacidad discriminativa (azar)",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-6-conceptual-regresión-de-poisson",
    "href": "tema5_glm_soluciones.html#ejercicio-6-conceptual-regresión-de-poisson",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.6 Ejercicio 6: Conceptual (Regresión de Poisson)",
    "text": "5.6 Ejercicio 6: Conceptual (Regresión de Poisson)\n\n¿Qué tipo de variable respuesta está diseñada para modelar la regresión de Poisson?\n¿Cuál es el supuesto fundamental de la distribución de Poisson respecto a la relación entre la media y la varianza?\n¿Cómo se llama el problema que surge cuando este supuesto se viola y la varianza es mayor que la media?\n\n\n\n\na) Tipo de variable respuesta: La regresión de Poisson está diseñada para variables de conteo: enteros no negativos que representan el número de ocurrencias de un evento en un período o espacio fijo.\nb) Supuesto fundamental: En la distribución de Poisson, la media es igual a la varianza: \\(E[Y] = Var[Y] = \\mu\\).\nc) Problema cuando se viola: Cuando \\(Var[Y] &gt; E[Y]\\), se llama sobredispersión. Esto puede llevar a errores estándar subestimados y conclusiones incorrectas sobre la significancia.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-7-práctico-ajuste-de-un-modelo-de-poisson",
    "href": "tema5_glm_soluciones.html#ejercicio-7-práctico-ajuste-de-un-modelo-de-poisson",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.7 Ejercicio 7: Práctico (Ajuste de un Modelo de Poisson)",
    "text": "5.7 Ejercicio 7: Práctico (Ajuste de un Modelo de Poisson)\nEl dataset discoveries de R es una serie temporal que cuenta el número de “grandes inventos” por año.\n\nCrea un gráfico de la serie temporal. ¿Parece la media del conteo constante a lo largo del tiempo?\nAjusta un modelo de regresión de Poisson simple donde discoveries es la respuesta y el tiempo (time(discoveries)) es el predictor.\nInterpreta el coeficiente del tiempo. (Pista: recuerda exponenciarlo para obtener el Incidence Rate Ratio - IRR).\n\n\n\n\n\n# Usar dataset discoveries\ndata(discoveries)\n\na) Gráfico de la serie temporal:\n\nplot(discoveries, main = \"Grandes Inventos por Año\", \n     ylab = \"Número de Descubrimientos\", xlab = \"Año\")\n\n\n\n\n\n\n\n\nb) Ajustar modelo de Poisson:\n\n# Crear data frame con tiempo\ndf_discoveries &lt;- data.frame(\n  count = as.numeric(discoveries),\n  time = as.numeric(time(discoveries))\n)\n\nmodelo_poisson &lt;- glm(count ~ time, data = df_discoveries, family = poisson)\nsummary(modelo_poisson)\n\n\nCall:\nglm(formula = count ~ time, family = poisson, data = df_discoveries)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) 11.354807   3.775677   3.007  0.00264 **\ntime        -0.005360   0.001982  -2.705  0.00683 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 164.68  on 99  degrees of freedom\nResidual deviance: 157.32  on 98  degrees of freedom\nAIC: 430.32\n\nNumber of Fisher Scoring iterations: 5\n\n\nc) Interpretación del coeficiente de tiempo:\n\n# IRR (Incidence Rate Ratio)\ncoef_time &lt;- coef(modelo_poisson)[\"time\"]\nirr &lt;- exp(coef_time)\nprint(paste(\"IRR para tiempo:\", round(irr, 6)))\n\n[1] \"IRR para tiempo: 0.994654\"\n\n\nEl IRR para el tiempo es 0.994654. Esto significa que por cada año que pasa, se espera que la tasa de grandes inventos se multiplique por 0.994654, lo que representa una disminución anual de aproximadamente 0.53% (calculado como 1 - 0.994654).",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-8-diagnóstico-sobredispersión",
    "href": "tema5_glm_soluciones.html#ejercicio-8-diagnóstico-sobredispersión",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.8 Ejercicio 8: Diagnóstico (Sobredispersión)",
    "text": "5.8 Ejercicio 8: Diagnóstico (Sobredispersión)\n\nPara el modelo de Poisson del ejercicio anterior, calcula el estadístico de dispersión (\\(\\hat{\\phi}\\)). (Pista: \\(\\hat{\\phi} = \\frac{\\sum r_i^2}{n-p}\\), donde los \\(r_i\\) son los residuos Pearson).\nBasándote en el valor de \\(\\hat{\\phi}\\), ¿hay evidencia de sobredispersión?\nSi encuentras sobredispersión, ¿cuál es el modelo alternativo que proponen los apuntes? ¿Qué ventaja teórica ofrece este modelo alternativo?\n\n\n\n\na) Calcular estadístico de dispersión:\n\nresiduos_pearson &lt;- residuals(modelo_poisson, type = \"pearson\")\nn &lt;- nrow(df_discoveries)\np &lt;- length(coef(modelo_poisson))\nphi_hat &lt;- sum(residuos_pearson^2) / (n - p)\n\nprint(paste(\"Estadístico de dispersión (φ̂):\", round(phi_hat, 3)))\n\n[1] \"Estadístico de dispersión (φ̂): 1.541\"\n\n\nb) Evidencia de sobredispersión: Si φ̂ &gt; 1, hay evidencia de sobredispersión. Valores &gt; 1.5 indican sobredispersión considerable.\nc) Modelo alternativo: Si hay sobredispersión, se puede usar regresión Binomial Negativa, que incluye un parámetro adicional que permite que la varianza sea mayor que la media: \\(Var[Y] = \\mu + \\alpha\\mu^2\\).\n\n# Ajuste con binomial negativa si hay sobredispersión\nif(phi_hat &gt; 1.5) {\n  library(MASS)\n  modelo_nb &lt;- glm.nb(count ~ time, data = df_discoveries)\n  print(\"Modelo Binomial Negativo ajustado:\")\n  print(summary(modelo_nb))\n}\n\n[1] \"Modelo Binomial Negativo ajustado:\"\n\nCall:\nglm.nb(formula = count ~ time, data = df_discoveries, init.theta = 6.214857583, \n    link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept) 12.254546   4.628240   2.648   0.0081 **\ntime        -0.005832   0.002428  -2.402   0.0163 * \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(6.2149) family taken to be 1)\n\n    Null deviance: 114.04  on 99  degrees of freedom\nResidual deviance: 108.69  on 98  degrees of freedom\nAIC: 422.34\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  6.21 \n          Std. Err.:  2.67 \n\n 2 x log-likelihood:  -416.34",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-9-conceptual-deviance",
    "href": "tema5_glm_soluciones.html#ejercicio-9-conceptual-deviance",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.9 Ejercicio 9: Conceptual (Deviance)",
    "text": "5.9 Ejercicio 9: Conceptual (Deviance)\nLa deviance es la medida principal de bondad de ajuste en los GLM. Explica conceptualmente qué mide. ¿Cómo se utiliza la diferencia en deviance entre dos modelos anidados para decidir cuál es mejor?\n\n\n\nDeviance mide qué tan bien el modelo ajustado se compara con el modelo saturado (perfecto). Es análogo a la suma de cuadrados residuales en regresión lineal.\nFórmula: \\(D = 2[L(\\text{modelo saturado}) - L(\\text{modelo ajustado})]\\)\nUso para comparar modelos anidados: La diferencia en deviance entre dos modelos anidados sigue una distribución χ² con grados de libertad igual a la diferencia en número de parámetros. Si esta diferencia es significativa, el modelo más complejo es preferible.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "tema5_glm_soluciones.html#ejercicio-10-elección-del-modelo-adecuado",
    "href": "tema5_glm_soluciones.html#ejercicio-10-elección-del-modelo-adecuado",
    "title": "5  Modelos de Regresión Generalizada",
    "section": "5.10 Ejercicio 10: Elección del Modelo Adecuado",
    "text": "5.10 Ejercicio 10: Elección del Modelo Adecuado\nPara cada uno de los siguientes escenarios, indica qué tipo de GLM (Logístico, Poisson, Binomial Negativo, Gamma…) sería el más apropiado y por qué.\n\nQuieres modelar el tiempo (en minutos) que tarda un cliente en resolver una consulta en un centro de atención telefónica. El tiempo es siempre positivo y muchos valores se agrupan en tiempos cortos, con una cola larga de tiempos muy largos.\nQuieres predecir la presencia o ausencia de una especie de planta en diferentes parcelas de un bosque.\nQuieres modelar el número de visitas que cada usuario hace a una página web en un mes. Observas que la varianza del número de visitas es mucho mayor que la media.\n\n\n\n\na) Tiempo de resolución de consultas: Modelo Gamma sería más apropiado porque:\n\nLa variable es continua y positiva\nTípicamente tiene distribución asimétrica con cola derecha larga\nLa distribución Gamma es flexible para este tipo de datos\n\nb) Presencia/ausencia de especies: Regresión Logística es la elección obvia porque:\n\nVariable respuesta binaria (presencia = 1, ausencia = 0)\nQueremos modelar probabilidades que están restringidas al intervalo [0,1]\n\nc) Número de visitas con varianza mayor que la media: Regresión Binomial Negativa sería más apropiada porque:\n\nVariable de conteo (número de visitas)\nLa sobredispersión (varianza &gt; media) viola el supuesto de Poisson\nLa binomial negativa maneja naturalmente la sobredispersión",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Modelos de Regresión Generalizada</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html",
    "href": "ejercicios_avanzados_soluciones.html",
    "title": "6  Ejercicios Avanzados",
    "section": "",
    "text": "6.1 Ejercicio 1: Derivación de Estimadores\nConsidera el modelo de regresión lineal simple \\(Y_i = \\beta_0 + \\beta_1 X_i + \\varepsilon_i\\). Partiendo de la función objetivo de Mínimos Cuadrados Ordinarios (MCO), \\(S(\\beta_0, \\beta_1) = \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)^2\\), realiza la derivación matemática completa para obtener las expresiones de los estimadores \\(\\hat{\\beta}_0\\) y \\(\\hat{\\beta}_1\\). Muestra todos los pasos, desde el cálculo de las derivadas parciales hasta la resolución de las ecuaciones normales.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-1-derivación-de-estimadores",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-1-derivación-de-estimadores",
    "title": "6  Ejercicios Avanzados",
    "section": "",
    "text": "El objetivo es encontrar los valores de \\(\\beta_0\\) y \\(\\beta_1\\) que minimizan la Suma de Cuadrados del Error (SSE). Para ello, calculamos las derivadas parciales de la función \\(S(\\beta_0, \\beta_1)\\) con respecto a cada parámetro y las igualamos a cero.\n\nDerivada parcial con respecto a \\(\\beta_0\\): \\[\n\\frac{\\partial S}{\\partial \\beta_0} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-1) = -2 \\sum_{i=1}^{n} (y_i - \\beta_0 - \\beta_1 x_i)\n\\] Igualando a cero y dividiendo por -2: \\[\n\\sum_{i=1}^{n} (y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum y_i - n\\hat{\\beta}_0 - \\hat{\\beta}_1 \\sum x_i = 0\n\\] Reordenando, obtenemos la primera ecuación normal: \\[\nn\\hat{\\beta}_0 + \\hat{\\beta}_1 \\sum x_i = \\sum y_i \\quad \\text{(1)}\n\\]\nDerivada parcial con respecto a \\(\\beta_1\\): \\[\n\\frac{\\partial S}{\\partial \\beta_1} = \\sum_{i=1}^{n} 2(y_i - \\beta_0 - \\beta_1 x_i)(-x_i) = -2 \\sum_{i=1}^{n} x_i(y_i - \\beta_0 - \\beta_1 x_i)\n\\] Igualando a cero y dividiendo por -2: \\[\n\\sum_{i=1}^{n} x_i(y_i - \\hat{\\beta}_0 - \\hat{\\beta}_1 x_i) = 0 \\implies \\sum x_iy_i - \\hat{\\beta}_0 \\sum x_i - \\hat{\\beta}_1 \\sum x_i^2 = 0\n\\] Reordenando, obtenemos la segunda ecuación normal: \\[\n\\hat{\\beta}_0 \\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i \\quad \\text{(2)}\n\\]\nResolución del sistema: De la ecuación (1), dividiendo por \\(n\\), podemos despejar \\(\\hat{\\beta}_0\\): \\[\n\\hat{\\beta}_0 + \\hat{\\beta}_1 \\bar{x} = \\bar{y} \\implies \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x}\n\\] Esta es la fórmula para el intercepto, que depende de la pendiente.\nSustituimos esta expresión de \\(\\hat{\\beta}_0\\) en la ecuación (2): \\[\n(\\bar{y} - \\hat{\\beta}_1 \\bar{x})\\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i\n\\] \\[\n\\bar{y}\\sum x_i - \\hat{\\beta}_1 \\bar{x}\\sum x_i + \\hat{\\beta}_1 \\sum x_i^2 = \\sum x_iy_i\n\\] Agrupamos los términos con \\(\\hat{\\beta}_1\\): \\[\n\\hat{\\beta}_1 (\\sum x_i^2 - \\bar{x}\\sum x_i) = \\sum x_iy_i - \\bar{y}\\sum x_i\n\\] Sabiendo que \\(\\sum x_i = n\\bar{x}\\) y \\(\\sum y_i = n\\bar{y}\\): \\[\n\\hat{\\beta}_1 (\\sum x_i^2 - n\\bar{x}^2) = \\sum x_iy_i - n\\bar{x}\\bar{y}\n\\] Las expresiones entre paréntesis son las fórmulas de la suma de cuadrados de X (\\(S_{xx}\\)) y la suma de productos cruzados de X e Y (\\(S_{xy}\\)): \\[\n\\hat{\\beta}_1 S_{xx} = S_{xy}\n\\] Finalmente, despejamos el estimador de la pendiente: \\[\n\\hat{\\beta}_1 = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}\n\\] Estas son las expresiones para los estimadores de MCO.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-2-el-impacto-de-la-multicolinealidad",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-2-el-impacto-de-la-multicolinealidad",
    "title": "6  Ejercicios Avanzados",
    "section": "6.2 Ejercicio 2: El Impacto de la Multicolinealidad",
    "text": "6.2 Ejercicio 2: El Impacto de la Multicolinealidad\nEn un modelo de regresión múltiple con dos predictores estandarizados (\\(X_1, X_2\\)), la varianza del estimador \\(\\hat{\\beta}_1\\) viene dada por \\(\\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{n(1-r_{12}^2)}\\), donde \\(r_{12}\\) es la correlación entre \\(X_1\\) y \\(X_2\\).\n\nExplica matemáticamente qué le ocurre a la varianza de \\(\\hat{\\beta}_1\\) cuando la correlación entre los predictores (\\(r_{12}\\)) se aproxima a 1 (multicolinealidad perfecta).\nRelaciona esta fórmula con la del Factor de Inflación de la Varianza (VIF). ¿Cómo demuestra esta expresión que la multicolinealidad “infla” la varianza de los estimadores de los coeficientes?\n\n\n\n\na) Efecto de la correlación en la varianza: La varianza del estimador, \\(\\text{Var}(\\hat{\\beta}_1)\\), es una medida de su imprecisión. La fórmula \\(\\frac{\\sigma^2}{n(1-r_{12}^2)}\\) muestra que la varianza depende inversamente del término \\((1-r_{12}^2)\\). - Si \\(r_{12} = 0\\) (no hay correlación), la varianza es mínima: \\(\\text{Var}(\\hat{\\beta}_1) = \\sigma^2/n\\). - A medida que la correlación \\(|r_{12}|\\) aumenta y se acerca a 1 (multicolinealidad perfecta), el término \\(r_{12}^2\\) también se acerca a 1. - Consecuentemente, el denominador \\((1-r_{12}^2)\\) se aproxima a 0. - Matemáticamente, cuando el denominador de una fracción tiende a cero, el valor de la fracción tiende a infinito. Por lo tanto: \\[\n    \\lim_{|r_{12}| \\to 1} \\text{Var}(\\hat{\\beta}_1) = \\lim_{|r_{12}| \\to 1} \\frac{\\sigma^2}{n(1-r_{12}^2)} = \\infty\n    \\] Esto significa que con multicolinealidad severa, la varianza de los estimadores de los coeficientes “explota”, volviéndolos extremadamente inestables y poco fiables.\nb) Relación con el Factor de Inflación de la Varianza (VIF): El VIF para un predictor \\(X_j\\) se define como \\(VIF_j = \\frac{1}{1 - R_j^2}\\), donde \\(R_j^2\\) es el R-cuadrado de la regresión de \\(X_j\\) sobre todos los demás predictores. En el caso de solo dos predictores (\\(X_1, X_2\\)), el \\(R^2\\) de la regresión de \\(X_1\\) sobre \\(X_2\\) es simplemente el cuadrado de su coeficiente de correlación, es decir, \\(R_1^2 = r_{12}^2\\). Sustituyendo esto en la fórmula del VIF, tenemos: \\[\n  VIF_1 = \\frac{1}{1 - r_{12}^2}\n  \\] Ahora podemos reescribir la fórmula de la varianza de \\(\\hat{\\beta}_1\\) usando el VIF: \\[\n  \\text{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{n} \\cdot \\frac{1}{1-r_{12}^2} = \\frac{\\sigma^2}{n} \\cdot VIF_1\n  \\] Esta expresión demuestra que el VIF es, literalmente, el factor multiplicativo por el cual la varianza del estimador del coeficiente se “infla” en comparación con el caso base en el que no habría correlación (donde VIF = 1).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-3-interpretación-de-coeficientes-en-modelos-transformados",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-3-interpretación-de-coeficientes-en-modelos-transformados",
    "title": "6  Ejercicios Avanzados",
    "section": "6.3 Ejercicio 3: Interpretación de Coeficientes en Modelos Transformados",
    "text": "6.3 Ejercicio 3: Interpretación de Coeficientes en Modelos Transformados\nConsidera un modelo de regresión log-log: \\(\\log(Y_i) = \\beta_0 + \\beta_1 \\log(X_i) + \\varepsilon_i\\). Demuestra matemáticamente que el coeficiente \\(\\beta_1\\) puede interpretarse como una elasticidad, es decir, el cambio porcentual en \\(Y\\) ante un cambio del 1% en \\(X\\). (Pista: utiliza la derivada de \\(\\log(Y)\\) con respecto a \\(\\log(X)\\)).\n\n\n\nLa elasticidad de Y con respecto a X se define como el cambio porcentual en Y para un cambio del 1% en X. Para cambios infinitesimales, esta se expresa como: \\[\\eta = \\frac{\\% \\Delta Y}{\\% \\Delta X} = \\frac{dY/Y}{dX/X}\\] Una propiedad matemática de los logaritmos es que para cambios pequeños, \\(d(\\log(z)) \\approx \\frac{dz}{z}\\), que representa un cambio relativo o porcentual. Por lo tanto, la elasticidad puede expresarse como la derivada del logaritmo de Y con respecto al logaritmo de X: \\[\\eta = \\frac{d(\\log Y)}{d(\\log X)}\\] Partiendo de nuestro modelo poblacional (ignorando el término de error para analizar la relación sistemática): \\[\\log(Y) = \\beta_0 + \\beta_1 \\log(X)\\] Ahora, simplemente calculamos la derivada de la ecuación con respecto a \\(\\log(X)\\): \\[\\frac{d(\\log Y)}{d(\\log X)} = \\frac{d}{d(\\log X)} (\\beta_0 + \\beta_1 \\log(X))\\] El término \\(\\beta_0\\) es una constante, por lo que su derivada es 0. El término \\(\\beta_1 \\log(X)\\) tiene una derivada de \\(\\beta_1\\) con respecto a \\(\\log(X)\\). Por lo tanto: \\[\\frac{d(\\log Y)}{d(\\log X)} = \\beta_1\\] Hemos demostrado que el coeficiente \\(\\beta_1\\) es igual a la elasticidad de Y con respecto a X. Así, \\(\\beta_1\\) representa el cambio porcentual promedio en Y que se asocia con un aumento del 1% en X.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-4-fundamentos-de-la-regularización",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-4-fundamentos-de-la-regularización",
    "title": "6  Ejercicios Avanzados",
    "section": "6.4 Ejercicio 4: Fundamentos de la Regularización",
    "text": "6.4 Ejercicio 4: Fundamentos de la Regularización\nExplica desde una perspectiva geométrica por qué la regularización Lasso (penalización L1) es capaz de reducir los coeficientes exactamente a cero, realizando así selección de variables, mientras que la regularización Ridge (penalización L2) solo puede encoger los coeficientes hacia cero sin anularlos por completo. Apoya tu explicación con un dibujo o descripción de las “regiones de restricción” de ambos métodos en un espacio de dos coeficientes (\\(\\beta_1, \\beta_2\\)).\n\n\n\nLa estimación en regresión regularizada puede entenderse como un problema de optimización restringida. El objetivo es encontrar el conjunto de coeficientes (\\(\\beta_1, \\beta_2, \\dots\\)) que minimice la Suma de Cuadrados del Error (SSE), sujeto a una restricción en el tamaño de dichos coeficientes.\n\nGeometría del problema: El conjunto de todos los posibles valores de los coeficientes para un mismo valor de SSE forma una elipse (en un espacio de dos coeficientes, \\(\\beta_1, \\beta_2\\)) centrada en la solución de Mínimos Cuadrados Ordinarios (MCO). El objetivo es encontrar la elipse más pequeña posible que toque la “región de restricción”.\nRegresión Ridge (Penalización L2): La restricción es \\(\\sum \\beta_j^2 \\leq s\\). En dos dimensiones, \\(\\beta_1^2 + \\beta_2^2 \\leq s\\) es la ecuación de un círculo. Esta región es convexa y no tiene “esquinas”. Cuando las elipses del SSE se expanden desde el punto MCO, el primer punto de contacto con el círculo será un punto de tangencia. Debido a la forma suave y redondeada del círculo, es extremadamente improbable que este punto de tangencia ocurra exactamente sobre un eje (donde uno de los coeficientes sería cero). Por lo tanto, Ridge reduce la magnitud de ambos coeficientes, pero no los anula.\nRegresión Lasso (Penalización L1): La restricción es \\(\\sum |\\beta_j| \\leq s\\). En dos dimensiones, \\(|\\beta_1| + |\\beta_2| \\leq s\\) es la ecuación de un rombo (o diamante), rotado 45 grados. La característica clave de esta región son sus vértices afilados, que se encuentran sobre los ejes. Cuando las elipses del SSE se expanden, es mucho más probable que toquen la región de restricción en uno de estos vértices que en una de las aristas. Si el punto de contacto es un vértice sobre un eje (por ejemplo, el punto (0, \\(\\beta_2\\))), significa que el otro coeficiente (\\(\\beta_1\\)) es exactamente cero. Es esta propiedad geométrica, las “esquinas” de la región de penalización L1, lo que induce la escasez (sparsity) y permite a Lasso realizar selección de variables.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-5-la-familia-exponencial-y-los-glm",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-5-la-familia-exponencial-y-los-glm",
    "title": "6  Ejercicios Avanzados",
    "section": "6.5 Ejercicio 5: La Familia Exponencial y los GLM",
    "text": "6.5 Ejercicio 5: La Familia Exponencial y los GLM\nLa teoría de los Modelos Lineales Generalizados (GLM) se basa en que distribuciones como la Normal, Binomial o Poisson pertenecen a la familia exponencial. La forma canónica de esta familia establece una relación directa entre la media y la varianza a través de la función de varianza \\(V(\\mu)\\). Explica cuál es la función de varianza para un modelo de Poisson y para un modelo Binomial. ¿Qué implicaciones tiene la forma de \\(V(\\mu)\\) en cada caso sobre el comportamiento de los datos y los supuestos del modelo?\n\n\n\nLa función de varianza \\(V(\\mu)\\) es la “firma” de cada distribución dentro de la familia exponencial, ya que define la relación teórica entre la media \\(\\mu\\) y la varianza de la variable respuesta.\n\nModelo de Poisson:\n\nFunción de Varianza: \\(V(\\mu) = \\mu\\).\nImplicación: Esto implica que la varianza de la variable respuesta es teóricamente igual a su media: \\(\\text{Var}(Y) = \\mu\\). Este supuesto se conoce como equidispersión. La implicación más importante para el modelado es que, si los datos reales muestran una varianza significativamente mayor que la media (un fenómeno muy común llamado sobredispersión), el modelo de Poisson será inadecuado. Los errores estándar de los coeficientes estarán subestimados, llevando a p-valores incorrectamente bajos y a una inferencia errónea.\n\nModelo Binomial:\n\nFunción de Varianza: \\(V(\\mu) = \\mu(1-\\mu)\\).\nImplicación: En este caso, la varianza no es constante, sino que es una función cuadrática de la media (la probabilidad de éxito). La varianza es mínima cuando \\(\\mu\\) se acerca a 0 o 1, y es máxima cuando \\(\\mu = 0.5\\). Esta es la heterocedasticidad inherente a los datos de proporciones. El modelo GLM maneja esto de forma natural a través del algoritmo de estimación (IRLS), que da más peso a las observaciones con menor varianza (aquellas con probabilidades predichas cercanas a 0 o 1) y menos peso a las más inciertas (aquellas con probabilidades cercanas a 0.5).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-6-el-problema-de-la-inferencia-en-métodos-stepwise",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-6-el-problema-de-la-inferencia-en-métodos-stepwise",
    "title": "6  Ejercicios Avanzados",
    "section": "6.6 Ejercicio 6: El Problema de la Inferencia en Métodos Stepwise",
    "text": "6.6 Ejercicio 6: El Problema de la Inferencia en Métodos Stepwise\nLos apuntes advierten que los p-valores de un modelo final obtenido mediante selección por pasos (stepwise) están sesgados y son excesivamente optimistas. Explica el razonamiento estadístico detrás de esta advertencia. ¿Por qué el proceso iterativo de “buscar y seleccionar” la variable más significativa en cada paso invalida los supuestos teóricos del test t estándar?\n\n\n\nLa advertencia se debe a que los métodos stepwise violan un principio fundamental de la prueba de hipótesis: el modelo y las hipótesis deben ser especificados a priori, antes de examinar las relaciones en los datos. Los métodos stepwise hacen exactamente lo contrario.\n\nProblema de Múltiples Comparaciones: En cada paso, un algoritmo como la selección forward realiza múltiples tests (un test t para cada variable candidata a entrar) y selecciona la variable “ganadora”, que es la que tiene el p-valor más pequeño. Al elegir el valor mínimo de un conjunto de pruebas, estamos seleccionando un valor extremo de la distribución de p-valores bajo la hipótesis nula. El p-valor reportado para esa variable (p. ej., 0.03) no refleja la probabilidad de observar un resultado tan extremo en un solo intento, sino la probabilidad de que el mejor de varios intentos sea tan extremo, lo cual es una probabilidad mucho mayor.\nInvalidez de la Distribución Teórica: El p-valor de un test t se calcula asumiendo que el coeficiente sigue una distribución t de Student. Sin embargo, el coeficiente de una variable seleccionada por un algoritmo stepwise no sigue esta distribución. Sigue una distribución más compleja (una “distribución de un estadístico de orden”), porque ha sido seleccionado condicionalmente por ser el mejor.\nSesgo de Selección: El proceso está diseñado para encontrar relaciones, incluso en datos puramente aleatorios. Si tenemos muchas variables de ruido, la probabilidad de que una de ellas parezca significativa por puro azar es alta. El método stepwise seleccionará esa variable y reportará un p-valor bajo y engañoso.\n\nEn resumen, los p-valores de un modelo stepwise están sesgados a la baja (son demasiado pequeños) porque no tienen en cuenta el proceso de búsqueda y selección que los ha producido. Esto lleva a una inflación de la tasa de error de Tipo I, haciendo que concluyamos que ciertas variables son significativas cuando en realidad no lo son.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-7-propiedades-de-los-estimadores-mco",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-7-propiedades-de-los-estimadores-mco",
    "title": "6  Ejercicios Avanzados",
    "section": "6.7 Ejercicio 7: Propiedades de los Estimadores MCO",
    "text": "6.7 Ejercicio 7: Propiedades de los Estimadores MCO\nEl Teorema de Gauss-Markov establece que, bajo ciertos supuestos, los estimadores de Mínimos Cuadrados Ordinarios (MCO) son MELI (Mejores Estimadores Lineales Insesgados). Demuestra la propiedad de insesgadez para el estimador \\(\\hat{\\boldsymbol{\\beta}}\\) en notación matricial. Es decir, demuestra que \\(E[\\hat{\\boldsymbol{\\beta}}] = \\boldsymbol{\\beta}\\). Muestra todos los pasos y menciona qué supuestos del modelo estás utilizando en cada paso.\n\n\n\n\nComenzamos con la fórmula del estimador MCO en notación matricial: \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}\n\\]\nSustituimos el modelo poblacional verdadero para el vector \\(\\mathbf{y}\\), que es \\(\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\): \\[\n\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon})\n\\]\nAplicamos el operador de valor esperado \\(E[\\cdot]\\) a ambos lados. Tratamos la matriz de diseño \\(\\mathbf{X}\\) como fija (no aleatoria): \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T(\\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon})]\n\\]\nDistribuimos el término \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\) dentro del paréntesis: \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta} + (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\varepsilon}]\n\\]\nUsamos la propiedad de linealidad del valor esperado (\\(E[A+B] = E[A] + E[B]\\)): \\[\nE[\\hat{\\boldsymbol{\\beta}}] = E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\boldsymbol{\\beta}] + E[(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\boldsymbol{\\varepsilon}]\n\\]\nAnalizamos cada término por separado:\n\nEn el primer término, todo es constante excepto el operador de valor esperado, y \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{X}\\) es la matriz identidad \\(\\mathbf{I}\\). Por lo tanto, \\(E[\\mathbf{I}\\boldsymbol{\\beta}] = \\boldsymbol{\\beta}\\).\nEn el segundo término, podemos sacar las constantes del valor esperado: \\((\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T E[\\boldsymbol{\\varepsilon}]\\).\n\nAplicamos el supuesto de exogeneidad (o media del error nula), que establece que el valor esperado del término de error es cero: \\(E[\\boldsymbol{\\varepsilon}] = \\mathbf{0}\\). \\[\n(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T E[\\boldsymbol{\\varepsilon}] = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T \\mathbf{0} = \\mathbf{0}\n\\]\nUniendo los resultados, concluimos: \\[\nE[\\hat{\\boldsymbol{\\beta}}] = \\boldsymbol{\\beta} + \\mathbf{0} = \\boldsymbol{\\beta}\n\\] Esto demuestra que el estimador MCO \\(\\hat{\\boldsymbol{\\beta}}\\) es insesgado, ya que su valor esperado es el verdadero parámetro poblacional \\(\\boldsymbol{\\beta}\\).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-8-intervalos-de-confianza-vs.-predicción",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-8-intervalos-de-confianza-vs.-predicción",
    "title": "6  Ejercicios Avanzados",
    "section": "6.8 Ejercicio 8: Intervalos de Confianza vs. Predicción",
    "text": "6.8 Ejercicio 8: Intervalos de Confianza vs. Predicción\nLa fórmula para el intervalo de predicción para una nueva observación en regresión lineal simple es: \\[\\hat{y}_0 \\pm t_{\\alpha/2, n-2} \\cdot \\sqrt{\\text{MSE} \\left( 1 + \\frac{1}{n} + \\frac{(x_0 - \\bar{x})^2}{S_{xx}} \\right)}\\] Explica el origen y el significado de cada uno de los tres términos que se encuentran dentro del paréntesis bajo la raíz cuadrada. ¿Qué fuente de incertidumbre representa cada término y por qué la suma de los tres es necesaria para un intervalo de predicción?\n\n\n\nLa fórmula cuantifica la incertidumbre total de predecir una única nueva observación. Esta incertidumbre proviene de dos fuentes: la incertidumbre sobre la posición de la verdadera línea de regresión y la variabilidad inherente de un punto individual alrededor de esa línea. Los tres términos dentro del paréntesis representan estas fuentes de varianza (escaladas por MSE, que estima \\(\\sigma^2\\)):\n\nTérmino 1: Esta es la componente más importante y la que distingue al intervalo de predicción. Representa la varianza del error aleatorio de la nueva observación, \\(\\text{Var}(\\varepsilon_0) = \\sigma^2\\). Es la incertidumbre irreducible o inherente de un solo punto, que siempre se desviará de la media. Esta es la razón principal por la que un intervalo de predicción es siempre más ancho que uno de confianza.\nTérmino 1/n: Esta componente está relacionada con la incertidumbre en la estimación del intercepto \\(\\hat{\\beta}_0\\). Representa la incertidumbre sobre la “altura” general de la línea de regresión. A medida que el tamaño de la muestra (\\(n\\)) aumenta, nuestra confianza en la posición de la línea mejora, y este término de incertidumbre se hace más pequeño.\nTérmino (x_0 - \\bar{x})^2 / S_{xx}: Esta componente representa la incertidumbre debida a la estimación de la pendiente \\(\\hat{\\beta}_1\\). La incertidumbre en la pendiente tiene un mayor impacto cuanto más nos alejamos del centro de los datos (\\(\\bar{x}\\)). Si predecimos en el punto medio de nuestros datos (\\(x_0 = \\bar{x}\\)), este término se anula. A medida que \\(x_0\\) se aleja de \\(\\bar{x}\\), el efecto de un pequeño error en la estimación de la pendiente se magnifica, ensanchando el intervalo.\n\nEn resumen, los términos 1/n y (x_0 - \\bar{x})^2 / S_{xx} juntos cuantifican la incertidumbre sobre dónde está la línea de regresión verdadera (lo que cubre el intervalo de confianza). El término 1 añade la incertidumbre de un nuevo punto individual alrededor de esa línea.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-9-estimación-por-máxima-verosimilitud",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-9-estimación-por-máxima-verosimilitud",
    "title": "6  Ejercicios Avanzados",
    "section": "6.9 Ejercicio 9: Estimación por Máxima Verosimilitud",
    "text": "6.9 Ejercicio 9: Estimación por Máxima Verosimilitud\nPara un modelo de regresión logística, la función de log-verosimilitud es: \\[\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} \\left[y_i \\log(p_i) + (1-y_i) \\log(1-p_i)\\right]\\] donde \\(p_i = \\frac{1}{1 + e^{-\\mathbf{x}_i^T\\boldsymbol{\\beta}}}\\). Deriva la ecuación de puntuación (score equation) para un coeficiente \\(\\beta_j\\) (es decir, calcula \\(\\frac{\\partial \\ell}{\\partial \\beta_j}\\)) y demuestra que se iguala a cero cuando \\(\\sum_{i=1}^{n} x_{ij}(y_i - p_i) = 0\\). Interpreta el significado de esta condición final.\n\n\n\n\nLa función de log-verosimilitud para la regresión logística es: \\[\n\\ell(\\boldsymbol{\\beta}) = \\sum_{i=1}^{n} \\left[y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} - \\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\right]\n\\]\nLa ecuación de puntuación (score equation) se obtiene al calcular la primera derivada de la log-verosimilitud con respecto a un parámetro, en este caso \\(\\beta_j\\). Debemos calcular \\(\\frac{\\partial \\ell}{\\partial \\beta_j}\\) y igualarla a cero.\nLa derivada de una suma es la suma de las derivadas, por lo que podemos analizar el término dentro del sumatorio para una observación \\(i\\): \\[\n\\frac{\\partial}{\\partial \\beta_j} \\left[y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} - \\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\right]\n\\]\nLa derivada del primer término, \\(y_i \\mathbf{x}_i^T\\boldsymbol{\\beta} = y_i(\\beta_0 + \\beta_1x_{i1} + \\dots + \\beta_jx_{ij} + \\dots)\\), con respecto a \\(\\beta_j\\) es simplemente \\(y_i x_{ij}\\).\nLa derivada del segundo término, \\(\\log(1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\\), requiere la regla de la cadena. Sea \\(u = 1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}\\). \\[\n\\frac{\\partial}{\\partial \\beta_j} \\log(u) = \\frac{1}{u} \\cdot \\frac{\\partial u}{\\partial \\beta_j} = \\frac{1}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}} \\cdot \\frac{\\partial}{\\partial \\beta_j} (1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}})\n\\] \\[\n= \\frac{1}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}} \\cdot (e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}} \\cdot x_{ij}) = \\left(\\frac{e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}}{1 + e^{\\mathbf{x}_i^T\\boldsymbol{\\beta}}}\\right) x_{ij}\n\\]\nReconocemos que el término entre paréntesis es la definición de la probabilidad \\(p_i\\) en el modelo logístico (\\(p_i = \\frac{1}{1+e^{-\\mathbf{x}_i^T\\boldsymbol{\\beta}}}\\)). Por lo tanto, la derivada del segundo término es \\(p_i x_{ij}\\).\nUniendo ambos resultados, la derivada para la observación \\(i\\) es \\(y_i x_{ij} - p_i x_{ij}\\).\nLa ecuación de puntuación completa es la suma sobre todas las observaciones: \\[\n\\frac{\\partial \\ell}{\\partial \\beta_j} = \\sum_{i=1}^{n} (y_i x_{ij} - p_i x_{ij}) = \\sum_{i=1}^{n} x_{ij}(y_i - p_i)\n\\]\nLos estimadores de máxima verosimilitud se encuentran al igualar esta ecuación a cero: \\[\n\\sum_{i=1}^{n} x_{ij}(y_i - p_i) = 0\n\\]\n\nInterpretación: Esta condición final significa que los estimadores de máxima verosimilitud se encuentran cuando los residuos del modelo (\\(y_i - p_i\\), la diferencia entre lo observado y la probabilidad predicha) son ortogonales (no están correlacionados) a los predictores \\(x_{ij}\\). Esto es análogo a las ecuaciones normales de MCO y significa que el modelo ha extraído toda la información linealmente asociable a los predictores, no quedando ningún patrón relacionado con ellos en los errores.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  },
  {
    "objectID": "ejercicios_avanzados_soluciones.html#ejercicio-10-el-coeficiente-de-regresión-parcial",
    "href": "ejercicios_avanzados_soluciones.html#ejercicio-10-el-coeficiente-de-regresión-parcial",
    "title": "6  Ejercicios Avanzados",
    "section": "6.10 Ejercicio 10: El Coeficiente de Regresión Parcial",
    "text": "6.10 Ejercicio 10: El Coeficiente de Regresión Parcial\nEl texto afirma que el coeficiente \\(\\hat{\\beta}_j\\) de una regresión múltiple puede entenderse como el coeficiente de una regresión simple entre dos conjuntos de residuos. Explica con detalle este concepto de regresión parcial. ¿Qué se está “parcializando” o “eliminando” de la variable respuesta \\(Y\\) y del predictor \\(X_j\\) antes de calcular su relación? ¿Por qué este concepto es fundamental para entender la interpretación ceteris paribus?\n\n\n\nEl concepto de regresión parcial es fundamental para entender la interpretación ceteris paribus de un coeficiente en regresión múltiple. Afirma que el coeficiente \\(\\hat{\\beta}_j\\) del predictor \\(X_j\\) en un modelo múltiple es matemáticamente idéntico a la pendiente de una regresión simple entre dos conjuntos de residuos.\nEl proceso de “parcialización” consiste en eliminar la influencia de todos los demás predictores (denotados como \\(X_{-j}\\)) tanto de la variable respuesta \\(Y\\) como del predictor de interés \\(X_j\\).\n\nParcialización de Y: Se ajusta un modelo de regresión de \\(Y\\) en función de todos los demás predictores: \\(Y \\sim X_{-j}\\). Los residuos de este modelo, \\(e_{Y|X_{-j}}\\), representan la parte de la variabilidad de \\(Y\\) que no puede ser explicada por el resto de variables del modelo. Es la “información única” de Y.\nParcialización de \\(X_j\\): Se ajusta un modelo de regresión de \\(X_j\\) en función de todos los demás predictores: \\(X_j \\sim X_{-j}\\). Los residuos de este modelo, \\(e_{X_j|X_{-j}}\\), representan la parte de la variabilidad de \\(X_j\\) que es única y no está correlacionada con el resto de variables. Es la “información única” que \\(X_j\\) aporta.\nRelación entre los residuos: Si ahora ajustamos una regresión lineal simple entre estos dos conjuntos de residuos: \\[\ne_{Y|X_{-j}} \\sim e_{X_j|X_{-j}}\n\\] La pendiente de esta regresión simple es exactamente igual al coeficiente de regresión múltiple \\(\\hat{\\beta}_j\\) del modelo original completo.\n\nConclusión: Esto demuestra que \\(\\hat{\\beta}_j\\) no mide la relación “bruta” entre Y y \\(X_j\\), sino la relación entre la parte de Y que no es explicada por los otros predictores y la parte de \\(X_j\\) que es única. Es la asociación “limpia” entre Y y \\(X_j\\) después de haber controlado estadísticamente por la influencia de todas las demás variables en el modelo. Esto es, precisamente, la formalización matemática del principio ceteris paribus.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Ejercicios Avanzados</span>"
    ]
  }
]